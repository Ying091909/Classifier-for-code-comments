02/11/2023 21:26:59 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, beam_size=10, config_name='', dev_filename='final_final_dataset/java/val_data_of_deprecation.jsonl', do_eval=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=8, eval_steps=-1, gradient_accumulation_steps=1, learning_rate=5e-05, load_model_path=None, local_rank=0, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=32, model_name_or_path=None, model_type=None, no_cuda=False, num_train_epochs=120, output_dir='java_deprecation_output', seed=42, test_filename='final_final_dataset/java/test_data_of_deprecation.jsonl', tokenizer_name='', train_batch_size=8, train_filename='final_final_dataset/java/train_data_of_deprecation.jsonl', train_log_filename='java_deprecation', train_steps=-1, visible_gpu='0, 1', warmup_steps=0, weight_decay=0.0)
02/11/2023 21:26:59 - INFO - torch.distributed.distributed_c10d -   Added key: store_based_barrier_key:1 to store for rank: 0
02/11/2023 21:26:59 - INFO - torch.distributed.distributed_c10d -   Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
02/11/2023 21:26:59 - WARNING - __main__ -   Process rank: 1, device: cuda:1, n_gpu: 1, distributed training: True
02/11/2023 21:27:04 - INFO - __main__ -   model loaded!
02/11/2023 21:27:04 - INFO - __main__ -   *** Example ***
02/11/2023 21:27:04 - INFO - __main__ -   idx: 0
02/11/2023 21:27:04 - INFO - __main__ -   source_tokens: ['<s>', 'Classification', ':', '_@', 'since', '_70', '</s>']
02/11/2023 21:27:04 - INFO - __main__ -   source_ids: 1 19168 30 632 9256 16647 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/11/2023 21:27:04 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/11/2023 21:27:04 - INFO - __main__ -   target_tokens: ['<s>', 'true', '</s>']
02/11/2023 21:27:04 - INFO - __main__ -   target_ids: 1 3767 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/11/2023 21:27:04 - INFO - __main__ -   target_mask: 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/11/2023 21:27:04 - INFO - __main__ -   *** Example ***
02/11/2023 21:27:04 - INFO - __main__ -   idx: 1
02/11/2023 21:27:04 - INFO - __main__ -   source_tokens: ['<s>', 'Classification', ':', '_@', 'since', '_75', '_0', '</s>']
02/11/2023 21:27:04 - INFO - __main__ -   source_ids: 1 19168 30 632 9256 18821 374 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/11/2023 21:27:04 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/11/2023 21:27:04 - INFO - __main__ -   target_tokens: ['<s>', 'true', '</s>']
02/11/2023 21:27:04 - INFO - __main__ -   target_ids: 1 3767 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/11/2023 21:27:04 - INFO - __main__ -   target_mask: 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/11/2023 21:27:04 - INFO - __main__ -   *** Example ***
02/11/2023 21:27:04 - INFO - __main__ -   idx: 2
02/11/2023 21:27:04 - INFO - __main__ -   source_tokens: ['<s>', 'Classification', ':', '_@', 'since', '_100', '</s>']
02/11/2023 21:27:04 - INFO - __main__ -   source_ids: 1 19168 30 632 9256 2130 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/11/2023 21:27:04 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/11/2023 21:27:04 - INFO - __main__ -   target_tokens: ['<s>', 'true', '</s>']
02/11/2023 21:27:04 - INFO - __main__ -   target_ids: 1 3767 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/11/2023 21:27:04 - INFO - __main__ -   target_mask: 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/11/2023 21:27:04 - INFO - __main__ -   *** Example ***
02/11/2023 21:27:04 - INFO - __main__ -   idx: 3
02/11/2023 21:27:04 - INFO - __main__ -   source_tokens: ['<s>', 'Classification', ':', '_@', 'since', '_10', '</s>']
02/11/2023 21:27:04 - INFO - __main__ -   source_ids: 1 19168 30 632 9256 1728 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/11/2023 21:27:04 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/11/2023 21:27:04 - INFO - __main__ -   target_tokens: ['<s>', 'true', '</s>']
02/11/2023 21:27:04 - INFO - __main__ -   target_ids: 1 3767 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/11/2023 21:27:04 - INFO - __main__ -   target_mask: 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/11/2023 21:27:04 - INFO - __main__ -   *** Example ***
02/11/2023 21:27:04 - INFO - __main__ -   idx: 4
02/11/2023 21:27:04 - INFO - __main__ -   source_tokens: ['<s>', 'Classification', ':', '_@', 'since', '_76', '</s>']
02/11/2023 21:27:04 - INFO - __main__ -   source_ids: 1 19168 30 632 9256 22997 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/11/2023 21:27:04 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/11/2023 21:27:04 - INFO - __main__ -   target_tokens: ['<s>', 'true', '</s>']
02/11/2023 21:27:04 - INFO - __main__ -   target_ids: 1 3767 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/11/2023 21:27:04 - INFO - __main__ -   target_mask: 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/11/2023 21:27:04 - INFO - __main__ -   ***** Running training *****
02/11/2023 21:27:04 - INFO - __main__ -     Num examples = 1832
02/11/2023 21:27:04 - INFO - __main__ -     Batch size = 8
02/11/2023 21:27:04 - INFO - __main__ -     Num epoch = 120
02/11/2023 21:27:05 - INFO - torch.nn.parallel.distributed -   Reducer buckets have been rebuilt in this iteration.
02/11/2023 21:27:34 - INFO - __main__ -   Epoch 0, step 99, train loss 9.8235
02/11/2023 21:27:38 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 21:27:38 - INFO - __main__ -     Num examples = 99
02/11/2023 21:27:38 - INFO - __main__ -     Batch size = 8
02/11/2023 21:27:39 - INFO - __main__ -     eval_ppl = 1.37038
02/11/2023 21:27:39 - INFO - __main__ -     global_step = 116
02/11/2023 21:27:39 - INFO - __main__ -     train_loss = 9.5202
02/11/2023 21:27:39 - INFO - __main__ -     ********************
02/11/2023 21:27:40 - INFO - __main__ -     Best ppl:1.37038
02/11/2023 21:27:40 - INFO - __main__ -     ********************
02/11/2023 21:27:44 - INFO - __main__ -   Epoch 0, the accuracy is 0.0
02/11/2023 21:28:12 - INFO - __main__ -   Epoch 1, step 99, train loss 0.8354
02/11/2023 21:28:17 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 21:28:17 - INFO - __main__ -     Num examples = 99
02/11/2023 21:28:17 - INFO - __main__ -     Batch size = 8
02/11/2023 21:28:18 - INFO - __main__ -     eval_ppl = 1.00231
02/11/2023 21:28:18 - INFO - __main__ -     global_step = 231
02/11/2023 21:28:18 - INFO - __main__ -     train_loss = 0.7212
02/11/2023 21:28:18 - INFO - __main__ -     ********************
02/11/2023 21:28:19 - INFO - __main__ -     Best ppl:1.00231
02/11/2023 21:28:19 - INFO - __main__ -     ********************
02/11/2023 21:28:22 - INFO - __main__ -   Epoch 1, the accuracy is 0.9494949494949495
02/11/2023 21:28:51 - INFO - __main__ -   Epoch 2, step 99, train loss 0.0611
02/11/2023 21:28:55 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 21:28:55 - INFO - __main__ -     Num examples = 99
02/11/2023 21:28:55 - INFO - __main__ -     Batch size = 8
02/11/2023 21:28:56 - INFO - __main__ -     eval_ppl = 1.00115
02/11/2023 21:28:56 - INFO - __main__ -     global_step = 346
02/11/2023 21:28:56 - INFO - __main__ -     train_loss = 0.0599
02/11/2023 21:28:56 - INFO - __main__ -     ********************
02/11/2023 21:28:58 - INFO - __main__ -     Best ppl:1.00115
02/11/2023 21:28:58 - INFO - __main__ -     ********************
02/11/2023 21:29:00 - INFO - __main__ -   Epoch 2, the accuracy is 0.98989898989899
02/11/2023 21:29:29 - INFO - __main__ -   Epoch 3, step 99, train loss 0.0364
02/11/2023 21:29:34 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 21:29:34 - INFO - __main__ -     Num examples = 99
02/11/2023 21:29:34 - INFO - __main__ -     Batch size = 8
02/11/2023 21:29:35 - INFO - __main__ -     eval_ppl = 1.0007
02/11/2023 21:29:35 - INFO - __main__ -     global_step = 461
02/11/2023 21:29:35 - INFO - __main__ -     train_loss = 0.038
02/11/2023 21:29:35 - INFO - __main__ -     ********************
002/11/2023 21:29:36 - INFO - __main__ -     Best ppl:1.0007
02/11/2023 21:29:36 - INFO - __main__ -     ********************002/11/2023 21:29:39 - INFO - __main__ -   Epoch 3, the accuracy is 0.98989898989899002/11/2023 21:30:08 - INFO - __main__ -   Epoch 4, step 99, train loss 0.03
02/11/2023 21:30:13 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 21:30:13 - INFO - __main__ -     Num examples = 99
02/11/2023 21:30:13 - INFO - __main__ -     Batch size = 8
02/11/2023 21:30:13 - INFO - __main__ -     eval_ppl = 1.00055
02/11/2023 21:30:13 - INFO - __main__ -     global_step = 576
02/11/2023 21:30:13 - INFO - __main__ -     train_loss = 0.0268
02/11/2023 21:30:13 - INFO - __main__ -     ********************
002/11/2023 21:30:15 - INFO - __main__ -     Best ppl:1.00055
02/11/2023 21:30:15 - INFO - __main__ -     ********************02/11/2023 21:30:18 - INFO - __main__ -   Epoch 4, the accuracy is 0.98989898989899
02/11/2023 21:30:47 - INFO - __main__ -   Epoch 5, step 99, train loss 0.0239
02/11/2023 21:30:51 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 21:30:51 - INFO - __main__ -     Num examples = 99
02/11/2023 21:30:51 - INFO - __main__ -     Batch size = 8
02/11/2023 21:30:52 - INFO - __main__ -     eval_ppl = 1.00039
02/11/2023 21:30:52 - INFO - __main__ -     global_step = 691
02/11/2023 21:30:52 - INFO - __main__ -     train_loss = 0.0212
02/11/2023 21:30:52 - INFO - __main__ -     ********************
02/11/2023 21:30:54 - INFO - __main__ -     Best ppl:1.00039
02/11/2023 21:30:54 - INFO - __main__ -     ********************
02/11/2023 21:30:56 - INFO - __main__ -   Epoch 5, the accuracy is 0.98989898989899
02/11/2023 21:31:25 - INFO - __main__ -   Epoch 6, step 99, train loss 0.0215
02/11/2023 21:31:30 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 21:31:30 - INFO - __main__ -     Num examples = 99
02/11/2023 21:31:30 - INFO - __main__ -     Batch size = 8
02/11/2023 21:31:31 - INFO - __main__ -     eval_ppl = 1.00043
02/11/2023 21:31:31 - INFO - __main__ -     global_step = 806
02/11/2023 21:31:31 - INFO - __main__ -     train_loss = 0.019
02/11/2023 21:31:31 - INFO - __main__ -     ********************
02/11/2023 21:31:33 - INFO - __main__ -   Epoch 6, the accuracy is 1.0
02/11/2023 21:32:02 - INFO - __main__ -   Epoch 7, step 99, train loss 0.0182
02/11/2023 21:32:07 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 21:32:07 - INFO - __main__ -     Num examples = 99
02/11/2023 21:32:07 - INFO - __main__ -     Batch size = 8
02/11/2023 21:32:08 - INFO - __main__ -     eval_ppl = 1.00036
02/11/2023 21:32:08 - INFO - __main__ -     global_step = 921
02/11/2023 21:32:08 - INFO - __main__ -     train_loss = 0.016
02/11/2023 21:32:08 - INFO - __main__ -     ********************
02/11/2023 21:32:09 - INFO - __main__ -     Best ppl:1.00036
02/11/2023 21:32:09 - INFO - __main__ -     ********************
0202/11/2023 21:32:12 - INFO - __main__ -   Epoch 7, the accuracy is 1.02/11/2023 21:32:41 - INFO - __main__ -   Epoch 8, step 99, train loss 0.0163
0202/11/2023 21:32:45 - INFO - __main__ -   
***** Running evaluation ****0202/11/2023 21:32:45 - INFO - __main__ -     Num examples = 90202/11/2023 21:32:45 - INFO - __main__ -     Batch size = 0202/11/2023 21:32:46 - INFO - __main__ -     eval_ppl = 1.00036
02/11/2023 21:32:46 - INFO - __main__ -     global_step = 1036
02/11/2023 21:32:46 - INFO - __main__ -     train_loss = 0.0142
02/11/2023 21:32:46 - INFO - __main__ -     *******************0202/11/2023 21:32:48 - INFO - __main__ -     Best ppl:1.00036
02/11/2023 21:32:48 - INFO - __main__ -     *******************0202/11/2023 21:32:50 - INFO - __main__ -   Epoch 8, the accuracy is 1.0202/11/2023 21:33:19 - INFO - __main__ -   Epoch 9, step 99, train loss 0.0102/11/2023 21:33:23 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 21:33:23 - INFO - __main__ -     Num examples = 99
02/11/2023 21:33:23 - INFO - __main__ -     Batch size = 8
02/02/11/2023 21:33:24 - INFO - __main__ -     eval_ppl = 1.00018
02/11/2023 21:33:24 - INFO - __main__ -     global_step = 1151
02/11/2023 21:33:24 - INFO - __main__ -     train_loss = 0.011
02/11/2023 21:33:24 - INFO - __main__ -     *******************02/11/2023 21:33:26 - INFO - __main__ -     Best ppl:1.00018
02/11/2023 21:33:26 - INFO - __main__ -     ********************
02/11/2023 21:33:29 - INFO - __main__ -   Epoch 9, the accuracy is 1.0
02/11/2023 21:33:58 - INFO - __main__ -   Epoch 10, step 99, train loss 0.008
02/11/2023 21:34:02 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 21:34:02 - INFO - __main__ -     Num examples = 99
02/11/2023 21:34:02 - INFO - __main__ -     Batch size = 8
02/11/2023 21:34:03 - INFO - __main__ -     eval_ppl = 1.00024
02/11/2023 21:34:03 - INFO - __main__ -     global_step = 1266
02/11/2023 21:34:03 - INFO - __main__ -     train_loss = 0.0073
02/11/2023 21:34:03 - INFO - __main__ -     ********************
02/02/11/2023 21:34:06 - INFO - __main__ -   Epoch 10, the accuracy is 102/11/2023 21:34:34 - INFO - __main__ -   Epoch 11, step 99, train loss 0.0078
02/11/2023 21:34:39 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 21:34:39 - INFO - __main__ -     Num examples = 99
02/11/2023 21:34:39 - INFO - __main__ -     Batch size = 8
02/02/11/2023 21:34:40 - INFO - __main__ -     eval_ppl = 1.00021
02/11/2023 21:34:40 - INFO - __main__ -     global_step = 1381
02/11/2023 21:34:40 - INFO - __main__ -     train_loss = 0.0048
02/11/2023 21:34:40 - INFO - __main__ -     ******************02/11/2023 21:34:42 - INFO - __main__ -   Epoch 11, the accuracy is 0.98989898989899
02/11/2023 21:35:11 - INFO - __main__ -   Epoch 12, step 99, train loss 0.0064
02/11/2023 21:35:16 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 21:35:16 - INFO - __main__ -     Num examples = 99
02/11/2023 21:35:16 - INFO - __main__ -     Batch size = 8
02/02/11/2023 21:35:16 - INFO - __main__ -     eval_ppl = 1.001
02/11/2023 21:35:16 - INFO - __main__ -     global_step = 1496
02/11/2023 21:35:16 - INFO - __main__ -     train_loss = 0.0039
02/11/2023 21:35:16 - INFO - __main__ -     ******************02/11/2023 21:35:19 - INFO - __main__ -   Epoch 12, the accuracy is 0.98989898989899
02/11/2023 21:35:48 - INFO - __main__ -   Epoch 13, step 99, train loss 0.0044
02/11/2023 21:35:53 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 21:35:53 - INFO - __main__ -     Num examples = 99
02/11/2023 21:35:53 - INFO - __main__ -     Batch size = 8
02/11/2023 21:35:54 - INFO - __main__ -     eval_ppl = 1.00105
02/11/2023 21:35:54 - INFO - __main__ -     global_step = 1611
02/11/2023 21:35:54 - INFO - __main__ -     train_loss = 0.0038
02/11/2023 21:35:54 - INFO - __main__ -     ********************
02/11/2023 21:35:56 - INFO - __main__ -   Epoch 13, the accuracy is 0.98989898989899
02/11/2023 21:36:25 - INFO - __main__ -   Epoch 14, step 99, train loss 0.0046
02/11/2023 21:36:30 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 21:36:30 - INFO - __main__ -     Num examples = 99
02/11/2023 21:36:30 - INFO - __main__ -     Batch size = 8
02/11/2023 21:36:31 - INFO - __main__ -     eval_ppl = 1.00088
02/11/2023 21:36:31 - INFO - __main__ -     global_step = 1726
02/11/2023 21:36:31 - INFO - __main__ -     train_loss = 0.004
02/11/2023 21:36:31 - INFO - __main__ -     ********************
02/11/2023 21:36:33 - INFO - __main__ -   Epoch 14, the accuracy is 0.98989898989899
02/11/2023 21:37:02 - INFO - __main__ -   Epoch 15, step 99, train loss 0.0053
02/11/2023 21:37:07 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 21:37:07 - INFO - __main__ -     Num examples = 99
02/11/2023 21:37:07 - INFO - __main__ -     Batch size = 8
02/11/2023 21:37:08 - INFO - __main__ -     eval_ppl = 1.00098
02/11/2023 21:37:08 - INFO - __main__ -     global_step = 1841
02/11/2023 21:37:08 - INFO - __main__ -     train_loss = 0.0046
02/11/2023 21:37:08 - INFO - __main__ -     ********************
02/02/11/2023 21:37:10 - INFO - __main__ -   Epoch 15, the accuracy is 0.98989898989802/11/2023 21:37:39 - INFO - __main__ -   Epoch 16, step 99, train loss 0.0047
02/11/2023 21:37:43 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 21:37:43 - INFO - __main__ -     Num examples = 99
02/11/2023 21:37:43 - INFO - __main__ -     Batch size = 8
02/02/11/2023 21:37:44 - INFO - __main__ -     eval_ppl = 1.00031
02/11/2023 21:37:44 - INFO - __main__ -     global_step = 1956
02/11/2023 21:37:44 - INFO - __main__ -     train_loss = 0.0007
02/11/2023 21:37:44 - INFO - __main__ -     ******************02/02/11/2023 21:37:47 - INFO - __main__ -   Epoch 16, the accuracy is 0.98989898989802/11/2023 21:38:15 - INFO - __main__ -   Epoch 17, step 99, train loss 0.0083
02/11/2023 21:38:20 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 21:38:20 - INFO - __main__ -     Num examples = 99
02/11/2023 21:38:20 - INFO - __main__ -     Batch size = 8
02/02/11/2023 21:38:21 - INFO - __main__ -     eval_ppl = 1.00061
02/11/2023 21:38:21 - INFO - __main__ -     global_step = 2071
02/11/2023 21:38:21 - INFO - __main__ -     train_loss = 0.0035
02/11/2023 21:38:21 - INFO - __main__ -     ******************02/11/2023 21:38:24 - INFO - __main__ -   Epoch 17, the accuracy is 0.98989898989899
02/11/2023 21:38:52 - INFO - __main__ -   Epoch 18, step 99, train loss 0.0051
02/11/2023 21:38:57 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 21:38:57 - INFO - __main__ -     Num examples = 99
02/11/2023 21:38:57 - INFO - __main__ -     Batch size = 8
02/11/2023 21:38:58 - INFO - __main__ -     eval_ppl = 1.00073
02/11/2023 21:38:58 - INFO - __main__ -     global_step = 2186
02/11/2023 21:38:58 - INFO - __main__ -     train_loss = 0.0044
02/11/2023 21:38:58 - INFO - __main__ -     ********************
02/11/2023 21:39:01 - INFO - __main__ -   Epoch 18, the accuracy is 0.98989898989899
02/11/2023 21:39:29 - INFO - __main__ -   Epoch 19, step 99, train loss 0.007
02/11/2023 21:39:34 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 21:39:34 - INFO - __main__ -     Num examples = 99
02/11/2023 21:39:34 - INFO - __main__ -     Batch size = 8
02/11/2023 21:39:35 - INFO - __main__ -     eval_ppl = 1.00026
02/11/2023 21:39:35 - INFO - __main__ -     global_step = 2301
02/11/2023 21:39:35 - INFO - __main__ -     train_loss = 0.0062
02/11/2023 21:39:35 - INFO - __main__ -     ********************
02/11/2023 21:39:38 - INFO - __main__ -   Epoch 19, the accuracy is 0.98989898989899
02/11/2023 21:40:06 - INFO - __main__ -   Epoch 20, step 99, train loss 0.0055
02/11/2023 21:40:11 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 21:40:11 - INFO - __main__ -     Num examples = 99
02/11/2023 21:40:11 - INFO - __main__ -     Batch size = 8
02/11/2023 21:40:12 - INFO - __main__ -     eval_ppl = 1.00029
02/11/2023 21:40:12 - INFO - __main__ -     global_step = 2416
02/11/2023 21:40:12 - INFO - __main__ -     train_loss = 0.0048
02/11/2023 21:40:12 - INFO - __main__ -     ********************
02/11/2023 21:40:15 - INFO - __main__ -   Epoch 20, the accuracy is 0.98989898989899
02/11/2023 21:40:43 - INFO - __main__ -   Epoch 21, step 99, train loss 0.0055
02/11/2023 21:40:48 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 21:40:48 - INFO - __main__ -     Num examples = 99
02/11/2023 21:40:48 - INFO - __main__ -     Batch size = 8
02/11/2023 21:40:49 - INFO - __main__ -     eval_ppl = 1.00073
02/11/2023 21:40:49 - INFO - __main__ -     global_step = 2531
02/11/2023 21:40:49 - INFO - __main__ -     train_loss = 0.0048
02/11/2023 21:40:49 - INFO - __main__ -     ********************
02/02/11/2023 21:40:51 - INFO - __main__ -   Epoch 21, the accuracy is 0.98989898989802/11/2023 21:41:20 - INFO - __main__ -   Epoch 22, step 99, train loss 0.0037
02/02/11/2023 21:41:25 - INFO - __main__ -   
***** Running evaluation ***02/02/11/2023 21:41:25 - INFO - __main__ -     Num examples = 02/02/11/2023 21:41:25 - INFO - __main__ -     Batch size =02/02/11/2023 21:41:26 - INFO - __main__ -     eval_ppl = 1.00077
02/11/2023 21:41:26 - INFO - __main__ -     global_step = 2646
02/11/2023 21:41:26 - INFO - __main__ -     train_loss = 0.0007
02/11/2023 21:41:26 - INFO - __main__ -     ******************02/11/2023 21:41:28 - INFO - __main__ -   Epoch 22, the accuracy is 0.98989898989899
02/11/2023 21:41:57 - INFO - __main__ -   Epoch 23, step 99, train loss 0.0042
02/11/2023 21:42:02 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 21:42:02 - INFO - __main__ -     Num examples = 99
02/11/2023 21:42:02 - INFO - __main__ -     Batch size = 8
02/02/11/2023 21:42:03 - INFO - __main__ -     eval_ppl = 1.00085
02/11/2023 21:42:03 - INFO - __main__ -     global_step = 2761
02/11/2023 21:42:03 - INFO - __main__ -     train_loss = 0.0005
02/11/2023 21:42:03 - INFO - __main__ -     ******************02/11/2023 21:42:05 - INFO - __main__ -   Epoch 23, the accuracy is 0.98989898989899
02/11/2023 21:42:34 - INFO - __main__ -   Epoch 24, step 99, train loss 0.0044
02/11/2023 21:42:39 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 21:42:39 - INFO - __main__ -     Num examples = 99
02/11/2023 21:42:39 - INFO - __main__ -     Batch size = 8
02/11/2023 21:42:40 - INFO - __main__ -     eval_ppl = 1.00086
02/11/2023 21:42:40 - INFO - __main__ -     global_step = 2876
02/11/2023 21:42:40 - INFO - __main__ -     train_loss = 0.0038
02/11/2023 21:42:40 - INFO - __main__ -     ********************
02/02/11/2023 21:42:42 - INFO - __main__ -   Epoch 24, the accuracy is 0.98989898989802/11/2023 21:43:11 - INFO - __main__ -   Epoch 25, step 99, train loss 0.0037
02/11/2023 21:43:15 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 21:43:15 - INFO - __main__ -     Num examples = 99
02/11/2023 21:43:15 - INFO - __main__ -     Batch size = 8
02/02/11/2023 21:43:16 - INFO - __main__ -     eval_ppl = 1.00087
02/11/2023 21:43:16 - INFO - __main__ -     global_step = 2991
02/11/2023 21:43:16 - INFO - __main__ -     train_loss = 0.0004
02/11/2023 21:43:16 - INFO - __main__ -     ******************02/11/2023 21:43:19 - INFO - __main__ -   Epoch 25, the accuracy is 0.98989898989899
02/11/2023 21:43:48 - INFO - __main__ -   Epoch 26, step 99, train loss 0.0042
02/11/2023 21:43:52 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 21:43:52 - INFO - __main__ -     Num examples = 99
02/11/2023 21:43:52 - INFO - __main__ -     Batch size = 8
02/11/2023 21:43:53 - INFO - __main__ -     eval_ppl = 1.00096
02/11/2023 21:43:53 - INFO - __main__ -     global_step = 3106
02/11/2023 21:43:53 - INFO - __main__ -     train_loss = 0.0036
02/11/2023 21:43:53 - INFO - __main__ -     ********************
02/11/2023 21:43:56 - INFO - __main__ -   Epoch 26, the accuracy is 0.98989898989899
02/11/2023 21:44:25 - INFO - __main__ -   Epoch 27, step 99, train loss 0.0044
02/11/2023 21:44:29 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 21:44:29 - INFO - __main__ -     Num examples = 99
02/11/2023 21:44:29 - INFO - __main__ -     Batch size = 8
02/02/11/2023 21:44:30 - INFO - __main__ -     eval_ppl = 1.001
02/11/2023 21:44:30 - INFO - __main__ -     global_step = 3221
02/11/2023 21:44:30 - INFO - __main__ -     train_loss = 0.0004
02/11/2023 21:44:30 - INFO - __main__ -     ******************02/11/2023 21:44:33 - INFO - __main__ -   Epoch 27, the accuracy is 0.98989898989899
02/11/2023 21:45:02 - INFO - __main__ -   Epoch 28, step 99, train loss 0.0068
02/11/2023 21:45:06 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 21:45:06 - INFO - __main__ -     Num examples = 99
02/11/2023 21:45:06 - INFO - __main__ -     Batch size = 8
02/11/2023 21:45:07 - INFO - __main__ -     eval_ppl = 1.00087
02/11/2023 21:45:07 - INFO - __main__ -     global_step = 3336
02/11/2023 21:45:07 - INFO - __main__ -     train_loss = 0.0059
02/11/2023 21:45:07 - INFO - __main__ -     ********************
02/11/2023 21:45:10 - INFO - __main__ -   Epoch 28, the accuracy is 0.98989898989899
02/11/2023 21:45:39 - INFO - __main__ -   Epoch 29, step 99, train loss 0.0035
02/11/2023 21:45:43 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 21:45:43 - INFO - __main__ -     Num examples = 99
02/11/2023 21:45:43 - INFO - __main__ -     Batch size = 8
02/11/2023 21:45:44 - INFO - __main__ -     eval_ppl = 1.00105
02/11/2023 21:45:44 - INFO - __main__ -     global_step = 3451
02/11/2023 21:45:44 - INFO - __main__ -     train_loss = 0.0031
02/11/2023 21:45:44 - INFO - __main__ -     ********************
02/11/2023 21:45:47 - INFO - __main__ -   Epoch 29, the accuracy is 0.98989898989899
02/11/2023 21:46:16 - INFO - __main__ -   Epoch 30, step 99, train loss 0.0039
02/11/2023 21:46:20 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 21:46:20 - INFO - __main__ -     Num examples = 99
02/02/11/2023 21:46:20 - INFO - __main__ -     Batch size =02/11/2023 21:46:21 - INFO - __main__ -     eval_ppl = 1.00115
02/11/2023 21:46:21 - INFO - __main__ -     global_step = 3566
02/11/2023 21:46:21 - INFO - __main__ -     train_loss = 0.0034
02/11/2023 21:46:21 - INFO - __main__ -     ********************
02/11/2023 21:46:24 - INFO - __main__ -   Epoch 30, the accuracy is 0.98989898989899
02/11/2023 21:46:53 - INFO - __main__ -   Epoch 31, step 99, train loss 0.0035
02/11/2023 21:46:57 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 21:46:57 - INFO - __main__ -     Num examples = 99
02/11/2023 21:46:57 - INFO - __main__ -     Batch size = 8
02/11/2023 21:46:58 - INFO - __main__ -     eval_ppl = 1.00133
02/11/2023 21:46:58 - INFO - __main__ -     global_step = 3681
02/11/2023 21:46:58 - INFO - __main__ -     train_loss = 0.003
02/11/2023 21:46:58 - INFO - __main__ -     ********************
02/11/2023 21:47:01 - INFO - __main__ -   Epoch 31, the accuracy is 0.98989898989899
02/11/2023 21:47:30 - INFO - __main__ -   Epoch 32, step 99, train loss 0.0036
02/11/2023 21:47:34 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 21:47:34 - INFO - __main__ -     Num examples = 99
02/11/2023 21:47:34 - INFO - __main__ -     Batch size = 8
02/11/2023 21:47:35 - INFO - __main__ -     eval_ppl = 1.00089
02/11/2023 21:47:35 - INFO - __main__ -     global_step = 3796
02/11/2023 21:47:35 - INFO - __main__ -     train_loss = 0.0032
02/11/2023 21:47:35 - INFO - __main__ -     ********************
02/11/2023 21:47:38 - INFO - __main__ -   Epoch 32, the accuracy is 0.98989898989899
02/11/2023 21:48:06 - INFO - __main__ -   Epoch 33, step 99, train loss 0.0041
02/11/2023 21:48:11 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 21:48:11 - INFO - __main__ -     Num examples = 99
02/11/2023 21:48:11 - INFO - __main__ -     Batch size = 8
02/102/11/2023 21:48:12 - INFO - __main__ -     eval_ppl = 1.00158
02/11/2023 21:48:12 - INFO - __main__ -     global_step = 3911
02/11/2023 21:48:12 - INFO - __main__ -     train_loss = 0.0007
02/11/2023 21:48:12 - INFO - __main__ -     *****************02/11/2023 21:48:15 - INFO - __main__ -   Epoch 33, the accuracy is 0.98989898989899
02/11/2023 21:48:43 - INFO - __main__ -   Epoch 34, step 99, train loss 0.0037
02/11/2023 21:48:48 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 21:48:48 - INFO - __main__ -     Num examples = 99
02/11/2023 21:48:48 - INFO - __main__ -     Batch size = 8
02/11/2023 21:48:49 - INFO - __main__ -     eval_ppl = 1.00137
02/11/2023 21:48:49 - INFO - __main__ -     global_step = 4026
02/11/2023 21:48:49 - INFO - __main__ -     train_loss = 0.0032
02/11/2023 21:48:49 - INFO - __main__ -     ********************
02/11/2023 21:48:51 - INFO - __main__ -   Epoch 34, the accuracy is 0.98989898989899
02/11/2023 21:49:20 - INFO - __main__ -   Epoch 35, step 99, train loss 0.0036
02/11/2023 21:49:25 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 21:49:25 - INFO - __main__ -     Num examples = 99
02/11/2023 21:49:25 - INFO - __main__ -     Batch size = 8
02/102/11/2023 21:49:26 - INFO - __main__ -     eval_ppl = 1.00139
02/11/2023 21:49:26 - INFO - __main__ -     global_step = 4141
02/11/2023 21:49:26 - INFO - __main__ -     train_loss = 0.0004
02/11/2023 21:49:26 - INFO - __main__ -     *****************02/11/2023 21:49:28 - INFO - __main__ -   Epoch 35, the accuracy is 0.98989898989899
02/11/2023 21:49:57 - INFO - __main__ -   Epoch 36, step 99, train loss 0.0037
02/11/2023 21:50:02 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 21:50:02 - INFO - __main__ -     Num examples = 99
02/11/2023 21:50:02 - INFO - __main__ -     Batch size = 8
02/102/11/2023 21:50:02 - INFO - __main__ -     eval_ppl = 1.00143
02/11/2023 21:50:02 - INFO - __main__ -     global_step = 4256
02/11/2023 21:50:02 - INFO - __main__ -     train_loss = 0.0003
02/11/2023 21:50:02 - INFO - __main__ -     *****************02/11/2023 21:50:05 - INFO - __main__ -   Epoch 36, the accuracy is 0.98989898989899
02/11/2023 21:50:34 - INFO - __main__ -   Epoch 37, step 99, train loss 0.0038
02/11/2023 21:50:38 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 21:50:38 - INFO - __main__ -     Num examples = 99
02/11/2023 21:50:38 - INFO - __main__ -     Batch size = 8
02/11/2023 21:50:39 - INFO - __main__ -     eval_ppl = 1.00141
02/11/2023 21:50:39 - INFO - __main__ -     global_step = 4371
02/11/2023 21:50:39 - INFO - __main__ -     train_loss = 0.0033
02/11/2023 21:50:39 - INFO - __main__ -     ********************
02/102/11/2023 21:50:42 - INFO - __main__ -   Epoch 37, the accuracy is 0.9898989898902/11/2023 21:51:10 - INFO - __main__ -   Epoch 38, step 99, train loss 0.0044
02/11/2023 21:51:15 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 21:51:15 - INFO - __main__ -     Num examples = 99
02/11/2023 21:51:15 - INFO - __main__ -     Batch size = 8
02/102/11/2023 21:51:16 - INFO - __main__ -     eval_ppl = 1.00137
02/11/2023 21:51:16 - INFO - __main__ -     global_step = 4486
02/11/2023 21:51:16 - INFO - __main__ -     train_loss = 0.0033
02/11/2023 21:51:16 - INFO - __main__ -     *****************02/11/2023 21:51:19 - INFO - __main__ -   Epoch 38, the accuracy is 0.98989898989899
02/11/2023 21:51:47 - INFO - __main__ -   Epoch 39, step 99, train loss 0.0037
02/11/2023 21:51:52 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 21:51:52 - INFO - __main__ -     Num examples = 99
02/11/2023 21:51:52 - INFO - __main__ -     Batch size = 8
02/11/2023 21:51:53 - INFO - __main__ -     eval_ppl = 1.00151
02/11/2023 21:51:53 - INFO - __main__ -     global_step = 4601
02/11/2023 21:51:53 - INFO - __main__ -     train_loss = 0.0032
02/11/2023 21:51:53 - INFO - __main__ -     ********************
02/102/11/2023 21:51:55 - INFO - __main__ -   Epoch 39, the accuracy is 0.9898989898902/102/11/2023 21:52:24 - INFO - __main__ -   Epoch 40, step 99, train loss 0.002/11/2023 21:52:29 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 21:52:29 - INFO - __main__ -     Num examples = 99
02/11/2023 21:52:29 - INFO - __main__ -     Batch size = 8
02/102/11/2023 21:52:29 - INFO - __main__ -     eval_ppl = 1.00156
02/11/2023 21:52:29 - INFO - __main__ -     global_step = 4716
02/11/2023 21:52:29 - INFO - __main__ -     train_loss = 0.0004
02/11/2023 21:52:29 - INFO - __main__ -     *****************02/102/11/2023 21:52:32 - INFO - __main__ -   Epoch 40, the accuracy is 0.9898989898902/11/2023 21:53:00 - INFO - __main__ -   Epoch 41, step 99, train loss 0.0038
02/11/2023 21:53:05 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 21:53:05 - INFO - __main__ -     Num examples = 99
02/11/2023 21:53:05 - INFO - __main__ -     Batch size = 8
02/102/11/2023 21:53:06 - INFO - __main__ -     eval_ppl = 1.00156
02/11/2023 21:53:06 - INFO - __main__ -     global_step = 4831
02/11/2023 21:53:06 - INFO - __main__ -     train_loss = 0.0004
02/11/2023 21:53:06 - INFO - __main__ -     *****************02/11/2023 21:53:09 - INFO - __main__ -   Epoch 41, the accuracy is 0.98989898989899
02/11/2023 21:53:37 - INFO - __main__ -   Epoch 42, step 99, train loss 0.0038
02/11/2023 21:53:42 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 21:53:42 - INFO - __main__ -     Num examples = 99
02/11/2023 21:53:42 - INFO - __main__ -     Batch size = 8
02/102/11/2023 21:53:43 - INFO - __main__ -     eval_ppl = 1.00153
02/11/2023 21:53:43 - INFO - __main__ -     global_step = 4946
02/11/2023 21:53:43 - INFO - __main__ -     train_loss = 0.0004
02/11/2023 21:53:43 - INFO - __main__ -     *****************02/11/2023 21:53:45 - INFO - __main__ -   Epoch 42, the accuracy is 0.98989898989899
02/11/2023 21:54:14 - INFO - __main__ -   Epoch 43, step 99, train loss 0.004
02/11/2023 21:54:19 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 21:54:19 - INFO - __main__ -     Num examples = 99
02/11/2023 21:54:19 - INFO - __main__ -     Batch size = 8
02/11/2023 21:54:20 - INFO - __main__ -     eval_ppl = 1.00157
02/11/2023 21:54:20 - INFO - __main__ -     global_step = 5061
02/11/2023 21:54:20 - INFO - __main__ -     train_loss = 0.0035
02/11/2023 21:54:20 - INFO - __main__ -     ********************
02/11/2023 21:54:22 - INFO - __main__ -   Epoch 43, the accuracy is 0.98989898989899
02/11/2023 21:54:51 - INFO - __main__ -   Epoch 44, step 99, train loss 0.0034
02/11/2023 21:54:56 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 21:54:56 - INFO - __main__ -     Num examples = 99
02/11/2023 21:54:56 - INFO - __main__ -     Batch size = 8
02/11/2023 21:54:57 - INFO - __main__ -     eval_ppl = 1.00167
02/11/2023 21:54:57 - INFO - __main__ -     global_step = 5176
02/11/2023 21:54:57 - INFO - __main__ -     train_loss = 0.003
02/11/2023 21:54:57 - INFO - __main__ -     ********************
02/11/2023 21:54:59 - INFO - __main__ -   Epoch 44, the accuracy is 0.98989898989899
02/11/2023 21:55:28 - INFO - __main__ -   Epoch 45, step 99, train loss 0.0106
02/11/2023 21:55:33 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 21:55:33 - INFO - __main__ -     Num examples = 99
02/11/2023 21:55:33 - INFO - __main__ -     Batch size = 8
02/11/2023 21:55:34 - INFO - __main__ -     eval_ppl = 1.00154
02/11/2023 21:55:34 - INFO - __main__ -     global_step = 5291
02/11/2023 21:55:34 - INFO - __main__ -     train_loss = 0.0094
02/11/2023 21:55:34 - INFO - __main__ -     ********************
02/11/2023 21:55:36 - INFO - __main__ -   Epoch 45, the accuracy is 0.98989898989899
02/11/2023 21:56:05 - INFO - __main__ -   Epoch 46, step 99, train loss 0.0045
02/11/2023 21:56:10 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 21:56:10 - INFO - __main__ -     Num examples = 99
02/11/2023 21:56:10 - INFO - __main__ -     Batch size = 8
02/11/2023 21:56:11 - INFO - __main__ -     eval_ppl = 1.00174
02/11/2023 21:56:11 - INFO - __main__ -     global_step = 5406
02/11/2023 21:56:11 - INFO - __main__ -     train_loss = 0.004
02/11/2023 21:56:11 - INFO - __main__ -     ********************
02/11/2023 21:56:13 - INFO - __main__ -   Epoch 46, the accuracy is 0.98989898989899
02/11/2023 21:56:42 - INFO - __main__ -   Epoch 47, step 99, train loss 0.0041
02/11/2023 21:56:47 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 21:56:47 - INFO - __main__ -     Num examples = 99
02/11/2023 21:56:47 - INFO - __main__ -     Batch size = 8
02/11/2023 21:56:48 - INFO - __main__ -     eval_ppl = 1.0018
02/11/2023 21:56:48 - INFO - __main__ -     global_step = 5521
02/11/2023 21:56:48 - INFO - __main__ -     train_loss = 0.0035
02/11/2023 21:56:48 - INFO - __main__ -     ********************
02/11/02/11/2023 21:56:50 - INFO - __main__ -   Epoch 47, the accuracy is 0.98989898902/11/02/11/2023 21:57:19 - INFO - __main__ -   Epoch 48, step 99, train loss 002/11/2023 21:57:23 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 21:57:23 - INFO - __main__ -     Num examples = 99
02/11/2023 21:57:23 - INFO - __main__ -     Batch size = 8
02/11/02/11/2023 21:57:24 - INFO - __main__ -     eval_ppl = 1.00173
02/11/2023 21:57:24 - INFO - __main__ -     global_step = 5636
02/11/2023 21:57:24 - INFO - __main__ -     train_loss = 0.0004
02/11/2023 21:57:24 - INFO - __main__ -     ***************02/11/02/11/2023 21:57:27 - INFO - __main__ -   Epoch 48, the accuracy is 0.98989898902/11/2023 21:57:55 - INFO - __main__ -   Epoch 49, step 99, train loss 0.0041
02/11/2023 21:58:00 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 21:58:00 - INFO - __main__ -     Num examples = 99
02/11/2023 21:58:00 - INFO - __main__ -     Batch size = 8
02/11/02/11/2023 21:58:01 - INFO - __main__ -     eval_ppl = 1.00182
02/11/2023 21:58:01 - INFO - __main__ -     global_step = 5751
02/11/2023 21:58:01 - INFO - __main__ -     train_loss = 0.0005
02/11/2023 21:58:01 - INFO - __main__ -     ***************02/11/02/11/2023 21:58:03 - INFO - __main__ -   Epoch 49, the accuracy is 0.98989898902/11/2023 21:58:32 - INFO - __main__ -   Epoch 50, step 99, train loss 0.0035
02/11/2023 21:58:36 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 21:58:36 - INFO - __main__ -     Num examples = 99
02/11/2023 21:58:36 - INFO - __main__ -     Batch size = 8
02/11/02/11/2023 21:58:37 - INFO - __main__ -     eval_ppl = 1.00154
02/11/2023 21:58:37 - INFO - __main__ -     global_step = 5866
02/11/2023 21:58:37 - INFO - __main__ -     train_loss = 0.0005
02/11/2023 21:58:37 - INFO - __main__ -     ***************02/11/02/11/2023 21:58:40 - INFO - __main__ -   Epoch 50, the accuracy is 0.98989898902/11/2023 21:59:08 - INFO - __main__ -   Epoch 51, step 99, train loss 0.0033
02/11/2023 21:59:13 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 21:59:13 - INFO - __main__ -     Num examples = 99
02/11/2023 21:59:13 - INFO - __main__ -     Batch size = 8
02/11/02/11/2023 21:59:14 - INFO - __main__ -     eval_ppl = 1.00157
02/11/2023 21:59:14 - INFO - __main__ -     global_step = 5981
02/11/2023 21:59:14 - INFO - __main__ -     train_loss = 0.0003
02/11/2023 21:59:14 - INFO - __main__ -     ***************02/11/2023 21:59:16 - INFO - __main__ -   Epoch 51, the accuracy is 0.98989898989899
02/11/02/11/2023 21:59:45 - INFO - __main__ -   Epoch 52, step 99, train loss 002/11/2023 21:59:50 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 21:59:50 - INFO - __main__ -     Num examples = 99
02/11/2023 21:59:50 - INFO - __main__ -     Batch size = 8
02/11/02/11/2023 21:59:51 - INFO - __main__ -     eval_ppl = 1.00158
02/11/2023 21:59:51 - INFO - __main__ -     global_step = 6096
02/11/2023 21:59:51 - INFO - __main__ -     train_loss = 0.0004
02/11/2023 21:59:51 - INFO - __main__ -     ***************02/11/02/11/2023 21:59:53 - INFO - __main__ -   Epoch 52, the accuracy is 0.98989898902/11/2023 22:00:22 - INFO - __main__ -   Epoch 53, step 99, train loss 0.0031
02/11/2023 22:00:27 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:00:27 - INFO - __main__ -     Num examples = 99
02/11/2023 22:00:27 - INFO - __main__ -     Batch size = 8
02/11/2023 22:00:28 - INFO - __main__ -     eval_ppl = 1.00165
02/11/2023 22:00:28 - INFO - __main__ -     global_step = 6211
02/11/2023 22:00:28 - INFO - __main__ -     train_loss = 0.0028
02/11/2023 22:00:28 - INFO - __main__ -     ********************
02/11/2023 22:00:30 - INFO - __main__ -   Epoch 53, the accuracy is 0.98989898989899
02/11/2023 22:00:59 - INFO - __main__ -   Epoch 54, step 99, train loss 0.003
02/11/2023 22:01:04 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:01:04 - INFO - __main__ -     Num examples = 99
02/11/2023 22:01:04 - INFO - __main__ -     Batch size = 8
02/11/2023 22:01:05 - INFO - __main__ -     eval_ppl = 1.00169
02/11/2023 22:01:05 - INFO - __main__ -     global_step = 6326
02/11/2023 22:01:05 - INFO - __main__ -     train_loss = 0.0026
02/11/2023 22:01:05 - INFO - __main__ -     ********************
02/11/2023 22:01:07 - INFO - __main__ -   Epoch 54, the accuracy is 0.98989898989899
02/11/202/11/2023 22:01:36 - INFO - __main__ -   Epoch 55, step 99, train loss 02/11/2023 22:01:40 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:01:40 - INFO - __main__ -     Num examples = 99
02/11/2023 22:01:40 - INFO - __main__ -     Batch size = 8
02/11/202/11/2023 22:01:41 - INFO - __main__ -     eval_ppl = 1.00166
02/11/2023 22:01:41 - INFO - __main__ -     global_step = 6441
02/11/2023 22:01:41 - INFO - __main__ -     train_loss = 0.0004
02/11/2023 22:01:41 - INFO - __main__ -     **************02/11/202/11/2023 22:01:44 - INFO - __main__ -   Epoch 55, the accuracy is 0.9898989802/11/2023 22:02:12 - INFO - __main__ -   Epoch 56, step 99, train loss 0.0031
02/11/2023 22:02:17 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:02:17 - INFO - __main__ -     Num examples = 99
02/11/2023 22:02:17 - INFO - __main__ -     Batch size = 8
02/11/202/11/2023 22:02:18 - INFO - __main__ -     eval_ppl = 1.00177
02/11/2023 22:02:18 - INFO - __main__ -     global_step = 6556
02/11/2023 22:02:18 - INFO - __main__ -     train_loss = 0.0004
02/11/2023 22:02:18 - INFO - __main__ -     **************02/11/2023 22:02:20 - INFO - __main__ -   Epoch 56, the accuracy is 0.98989898989899
02/11/2023 22:02:49 - INFO - __main__ -   Epoch 57, step 99, train loss 0.0033
02/11/2023 22:02:54 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:02:54 - INFO - __main__ -     Num examples = 99
02/11/2023 22:02:54 - INFO - __main__ -     Batch size = 8
02/11/2023 22:02:55 - INFO - __main__ -     eval_ppl = 1.00181
02/11/2023 22:02:55 - INFO - __main__ -     global_step = 6671
02/11/2023 22:02:55 - INFO - __main__ -     train_loss = 0.0029
02/11/2023 22:02:55 - INFO - __main__ -     ********************
02/11/2023 22:02:57 - INFO - __main__ -   Epoch 57, the accuracy is 0.98989898989899
02/11/2023 22:03:26 - INFO - __main__ -   Epoch 58, step 99, train loss 0.0038
02/11/2023 22:03:31 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:03:31 - INFO - __main__ -     Num examples = 99
02/11/2023 22:03:31 - INFO - __main__ -     Batch size = 8
02/11/2023 22:03:32 - INFO - __main__ -     eval_ppl = 1.0017
02/11/2023 22:03:32 - INFO - __main__ -     global_step = 6786
02/11/2023 22:03:32 - INFO - __main__ -     train_loss = 0.0034
02/11/2023 22:03:32 - INFO - __main__ -     ********************
02/11/2023 22:03:34 - INFO - __main__ -   Epoch 58, the accuracy is 0.98989898989899
02/11/2023 22:04:03 - INFO - __main__ -   Epoch 59, step 99, train loss 0.0033
02/11/2023 22:04:08 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:04:08 - INFO - __main__ -     Num examples = 99
02/11/2023 22:04:08 - INFO - __main__ -     Batch size = 8
02/11/2023 22:04:09 - INFO - __main__ -     eval_ppl = 1.0017
02/11/2023 22:04:09 - INFO - __main__ -     global_step = 6901
02/11/2023 22:04:09 - INFO - __main__ -     train_loss = 0.0029
02/11/2023 22:04:09 - INFO - __main__ -     ********************
02/11/2023 22:04:11 - INFO - __main__ -   Epoch 59, the accuracy is 0.98989898989899
02/11/2023 22:04:40 - INFO - __main__ -   Epoch 60, step 99, train loss 0.0032
02/11/2023 22:04:45 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:04:45 - INFO - __main__ -     Num examples = 99
02/11/2023 22:04:45 - INFO - __main__ -     Batch size = 8
02/11/2023 22:04:46 - INFO - __main__ -     eval_ppl = 1.0017
02/11/2023 22:04:46 - INFO - __main__ -     global_step = 7016
02/11/2023 22:04:46 - INFO - __main__ -     train_loss = 0.0028
02/11/2023 22:04:46 - INFO - __main__ -     ********************
02/11/2023 22:04:48 - INFO - __main__ -   Epoch 60, the accuracy is 0.98989898989899
02/11/202/11/2023 22:05:17 - INFO - __main__ -   Epoch 61, step 99, train loss 02/11/2023 22:05:22 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:05:22 - INFO - __main__ -     Num examples = 99
02/11/2023 22:05:22 - INFO - __main__ -     Batch size = 8
02/11/202/11/2023 22:05:22 - INFO - __main__ -     eval_ppl = 1.00174
02/11/2023 22:05:22 - INFO - __main__ -     global_step = 7131
02/11/2023 22:05:22 - INFO - __main__ -     train_loss = 0.0004
02/11/2023 22:05:22 - INFO - __main__ -     **************02/11/2023 22:05:25 - INFO - __main__ -   Epoch 61, the accuracy is 0.98989898989899
02/11/2023 22:05:54 - INFO - __main__ -   Epoch 62, step 99, train loss 0.003
02/11/2023 22:05:58 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:05:58 - INFO - __main__ -     Num examples = 99
02/11/2023 22:05:58 - INFO - __main__ -     Batch size = 8
02/11/2002/11/2023 22:05:59 - INFO - __main__ -     eval_ppl = 1.00182
02/11/2023 22:05:59 - INFO - __main__ -     global_step = 7246
02/11/2023 22:05:59 - INFO - __main__ -     train_loss = 0.0004
02/11/2023 22:05:59 - INFO - __main__ -     *************02/11/2002/11/2023 22:06:02 - INFO - __main__ -   Epoch 62, the accuracy is 0.989898902/11/2023 22:06:30 - INFO - __main__ -   Epoch 63, step 99, train loss 0.0036
02/11/2023 22:06:35 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:06:35 - INFO - __main__ -     Num examples = 99
02/11/2023 22:06:35 - INFO - __main__ -     Batch size = 8
02/11/2002/11/2023 22:06:36 - INFO - __main__ -     eval_ppl = 1.00181
02/11/2023 22:06:36 - INFO - __main__ -     global_step = 7361
02/11/2023 22:06:36 - INFO - __main__ -     train_loss = 0.0003
02/11/2023 22:06:36 - INFO - __main__ -     *************02/11/2023 22:06:38 - INFO - __main__ -   Epoch 63, the accuracy is 0.98989898989899
02/11/2002/11/2023 22:07:07 - INFO - __main__ -   Epoch 64, step 99, train loss02/11/2023 22:07:12 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:07:12 - INFO - __main__ -     Num examples = 99
02/11/2023 22:07:12 - INFO - __main__ -     Batch size = 8
02/11/2002/11/2023 22:07:12 - INFO - __main__ -     eval_ppl = 1.00181
02/11/2023 22:07:12 - INFO - __main__ -     global_step = 7476
02/11/2023 22:07:12 - INFO - __main__ -     train_loss = 0.0004
02/11/2023 22:07:12 - INFO - __main__ -     *************02/11/2023 22:07:15 - INFO - __main__ -   Epoch 64, the accuracy is 0.98989898989899
02/11/2023 22:07:44 - INFO - __main__ -   Epoch 65, step 99, train loss 0.0033
02/11/2023 22:07:48 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:07:48 - INFO - __main__ -     Num examples = 99
02/11/2023 22:07:48 - INFO - __main__ -     Batch size = 8
02/11/2002/11/2023 22:07:49 - INFO - __main__ -     eval_ppl = 1.00181
02/11/2023 22:07:49 - INFO - __main__ -     global_step = 7591
02/11/2023 22:07:49 - INFO - __main__ -     train_loss = 0.0003
02/11/2023 22:07:49 - INFO - __main__ -     *************02/11/2002/11/2023 22:07:52 - INFO - __main__ -   Epoch 65, the accuracy is 0.989898902/11/2002/11/2023 22:08:20 - INFO - __main__ -   Epoch 66, step 99, train loss02/11/2023 22:08:25 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:08:25 - INFO - __main__ -     Num examples = 99
02/11/2023 22:08:25 - INFO - __main__ -     Batch size = 8
02/11/2002/11/2023 22:08:26 - INFO - __main__ -     eval_ppl = 1.00186
02/11/2023 22:08:26 - INFO - __main__ -     global_step = 7706
02/11/2023 22:08:26 - INFO - __main__ -     train_loss = 0.0004
02/11/2023 22:08:26 - INFO - __main__ -     *************02/11/2002/11/2023 22:08:28 - INFO - __main__ -   Epoch 66, the accuracy is 0.989898902/11/2002/11/2023 22:08:57 - INFO - __main__ -   Epoch 67, step 99, train loss02/11/2002/11/2023 22:09:01 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:09:01 - INFO - __main__ -     Num examples = 99
02/11/2023 22:09:01 - INFO - __main__ -     Batch s02/11/2002/11/2023 22:09:02 - INFO - __main__ -     eval_ppl = 1.00177
02/11/2023 22:09:02 - INFO - __main__ -     global_step = 7821
02/11/2023 22:09:02 - INFO - __main__ -     train_loss = 0.0004
02/11/2023 22:09:02 - INFO - __main__ -     *************02/11/2002/11/2023 22:09:05 - INFO - __main__ -   Epoch 67, the accuracy is 0.989898902/11/2002/11/2023 22:09:33 - INFO - __main__ -   Epoch 68, step 99, train loss02/11/2023 22:09:38 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:09:38 - INFO - __main__ -     Num examples = 99
02/11/2023 22:09:38 - INFO - __main__ -     Batch size = 8
02/11/2002/11/2023 22:09:39 - INFO - __main__ -     eval_ppl = 1.00182
02/11/2023 22:09:39 - INFO - __main__ -     global_step = 7936
02/11/2023 22:09:39 - INFO - __main__ -     train_loss = 0.0004
02/11/2023 22:09:39 - INFO - __main__ -     *************02/11/2002/11/2023 22:09:41 - INFO - __main__ -   Epoch 68, the accuracy is 0.989898902/11/2023 22:10:10 - INFO - __main__ -   Epoch 69, step 99, train loss 0.0037
02/11/2023 22:10:14 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:10:14 - INFO - __main__ -     Num examples = 99
02/11/2023 22:10:14 - INFO - __main__ -     Batch size = 8
02/11/2002/11/2023 22:10:15 - INFO - __main__ -     eval_ppl = 1.00169
02/11/2023 22:10:15 - INFO - __main__ -     global_step = 8051
02/11/2023 22:10:15 - INFO - __main__ -     train_loss = 0.0004
02/11/2023 22:10:15 - INFO - __main__ -     *************02/11/2002/11/2023 22:10:18 - INFO - __main__ -   Epoch 69, the accuracy is 0.989898902/11/2002/11/2023 22:10:46 - INFO - __main__ -   Epoch 70, step 99, train loss02/11/2023 22:10:51 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:10:51 - INFO - __main__ -     Num examples = 99
02/11/2023 22:10:51 - INFO - __main__ -     Batch size = 8
02/11/2002/11/2023 22:10:52 - INFO - __main__ -     eval_ppl = 1.00175
02/11/2023 22:10:52 - INFO - __main__ -     global_step = 8166
02/11/2023 22:10:52 - INFO - __main__ -     train_loss = 0.0003
02/11/2023 22:10:52 - INFO - __main__ -     *************02/11/2002/11/2023 22:10:54 - INFO - __main__ -   Epoch 70, the accuracy is 0.989898902/11/2002/11/2023 22:11:23 - INFO - __main__ -   Epoch 71, step 99, train loss02/11/2023 22:11:27 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:11:27 - INFO - __main__ -     Num examples = 99
02/11/2023 22:11:27 - INFO - __main__ -     Batch size = 8
02/11/2002/11/2023 22:11:28 - INFO - __main__ -     eval_ppl = 1.00172
02/11/2023 22:11:28 - INFO - __main__ -     global_step = 8281
02/11/2023 22:11:28 - INFO - __main__ -     train_loss = 0.0004
02/11/2023 22:11:28 - INFO - __main__ -     *************02/11/2023 22:11:31 - INFO - __main__ -   Epoch 71, the accuracy is 0.98989898989899
02/11/2023 22:12:00 - INFO - __main__ -   Epoch 72, step 99, train loss 0.0035
02/11/2023 22:12:04 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:12:04 - INFO - __main__ -     Num examples = 99
02/11/2023 22:12:04 - INFO - __main__ -     Batch size = 8
02/11/2023 22:12:05 - INFO - __main__ -     eval_ppl = 1.00173
02/11/2023 22:12:05 - INFO - __main__ -     global_step = 8396
02/11/2023 22:12:05 - INFO - __main__ -     train_loss = 0.0031
02/11/2023 22:12:05 - INFO - __main__ -     ********************
02/11/2023 22:12:08 - INFO - __main__ -   Epoch 72, the accuracy is 0.98989898989899
02/11/2023 22:12:37 - INFO - __main__ -   Epoch 73, step 99, train loss 0.0033
02/11/2023 22:12:41 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:12:41 - INFO - __main__ -     Num examples = 99
02/11/2023 22:12:41 - INFO - __main__ -     Batch size = 8
02/11/2002/11/2023 22:12:42 - INFO - __main__ -     eval_ppl = 1.00165
02/11/2023 22:12:42 - INFO - __main__ -     global_step = 8511
02/11/2023 22:12:42 - INFO - __main__ -     train_loss = 0.0003
02/11/2023 22:12:42 - INFO - __main__ -     *************02/11/2023 22:12:45 - INFO - __main__ -   Epoch 73, the accuracy is 0.98989898989899
02/11/2023 22:13:13 - INFO - __main__ -   Epoch 74, step 99, train loss 0.0031
02/11/2023 22:13:18 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:13:18 - INFO - __main__ -     Num examples = 99
02/11/2023 22:13:18 - INFO - __main__ -     Batch size = 8
02/11/2002/11/2023 22:13:19 - INFO - __main__ -     eval_ppl = 1.00175
02/11/2023 22:13:19 - INFO - __main__ -     global_step = 8626
02/11/2023 22:13:19 - INFO - __main__ -     train_loss = 0.0003
02/11/2023 22:13:19 - INFO - __main__ -     *************02/11/2023 22:13:22 - INFO - __main__ -   Epoch 74, the accuracy is 0.98989898989899
02/11/2023 22:13:50 - INFO - __main__ -   Epoch 75, step 99, train loss 0.0036
02/11/2023 22:13:55 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:13:55 - INFO - __main__ -     Num examples = 99
02/11/2023 22:13:55 - INFO - __main__ -     Batch size = 8
02/11/2023 22:13:56 - INFO - __main__ -     eval_ppl = 1.00165
02/11/2023 22:13:56 - INFO - __main__ -     global_step = 8741
02/11/2023 22:13:56 - INFO - __main__ -     train_loss = 0.0032
02/11/2023 22:13:56 - INFO - __main__ -     ********************
02/11/2002/11/2023 22:13:58 - INFO - __main__ -   Epoch 75, the accuracy is 0.989898902/11/2002/11/2023 22:14:27 - INFO - __main__ -   Epoch 76, step 99, train loss02/11/2023 22:14:32 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:14:32 - INFO - __main__ -     Num examples = 99
02/11/2023 22:14:32 - INFO - __main__ -     Batch size = 8
02/11/2002/11/2023 22:14:33 - INFO - __main__ -     eval_ppl = 1.00176
02/11/2023 22:14:33 - INFO - __main__ -     global_step = 8856
02/11/2023 22:14:33 - INFO - __main__ -     train_loss = 0.0003
02/11/2023 22:14:33 - INFO - __main__ -     *************02/11/2023 22:14:35 - INFO - __main__ -   Epoch 76, the accuracy is 0.98989898989899
02/11/2023 22:15:04 - INFO - __main__ -   Epoch 77, step 99, train loss 0.0031
02/11/2023 22:15:09 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:15:09 - INFO - __main__ -     Num examples = 99
02/11/2023 22:15:09 - INFO - __main__ -     Batch size = 8
02/11/2023 22:15:10 - INFO - __main__ -     eval_ppl = 1.00176
02/11/2023 22:15:10 - INFO - __main__ -     global_step = 8971
02/11/2023 22:15:10 - INFO - __main__ -     train_loss = 0.0028
02/11/2023 22:15:10 - INFO - __main__ -     ********************
02/11/2023 22:15:12 - INFO - __main__ -   Epoch 77, the accuracy is 0.98989898989899
02/11/2023 22:15:41 - INFO - __main__ -   Epoch 78, step 99, train loss 0.0034
02/11/2023 22:15:46 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:15:46 - INFO - __main__ -     Num examples = 99
02/11/2023 22:15:46 - INFO - __main__ -     Batch size = 8
02/11/2023 22:15:47 - INFO - __main__ -     eval_ppl = 1.00167
02/11/2023 22:15:47 - INFO - __main__ -     global_step = 9086
02/11/2023 22:15:47 - INFO - __main__ -     train_loss = 0.003
02/11/2023 22:15:47 - INFO - __main__ -     ********************
02/11/2023 22:15:49 - INFO - __main__ -   Epoch 78, the accuracy is 0.98989898989899
02/11/2023 22:16:18 - INFO - __main__ -   Epoch 79, step 99, train loss 0.0031
02/11/2023 22:16:22 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:16:22 - INFO - __main__ -     Num examples = 99
02/11/2023 22:16:22 - INFO - __main__ -     Batch size = 8
02/11/20202/11/2023 22:16:23 - INFO - __main__ -     eval_ppl = 1.00167
02/11/2023 22:16:23 - INFO - __main__ -     global_step = 9201
02/11/2023 22:16:23 - INFO - __main__ -     train_loss = 0.0003
02/11/2023 22:16:23 - INFO - __main__ -     ************02/11/20202/11/2023 22:16:26 - INFO - __main__ -   Epoch 79, the accuracy is 0.98989802/11/2023 22:16:54 - INFO - __main__ -   Epoch 80, step 99, train loss 0.0029
02/11/2023 22:16:59 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:16:59 - INFO - __main__ -     Num examples = 99
02/11/2023 22:16:59 - INFO - __main__ -     Batch size = 8
02/11/20202/11/2023 22:17:00 - INFO - __main__ -     eval_ppl = 1.00171
02/11/2023 22:17:00 - INFO - __main__ -     global_step = 9316
02/11/2023 22:17:00 - INFO - __main__ -     train_loss = 0.0003
02/11/2023 22:17:00 - INFO - __main__ -     ************02/11/2023 22:17:03 - INFO - __main__ -   Epoch 80, the accuracy is 0.98989898989899
02/11/2023 22:17:31 - INFO - __main__ -   Epoch 81, step 99, train loss 0.0029
02/11/2023 22:17:36 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:17:36 - INFO - __main__ -     Num examples = 99
02/11/2023 22:17:36 - INFO - __main__ -     Batch size = 8
02/11/2023 22:17:37 - INFO - __main__ -     eval_ppl = 1.00173
02/11/2023 22:17:37 - INFO - __main__ -     global_step = 9431
02/11/2023 22:17:37 - INFO - __main__ -     train_loss = 0.0025
02/11/2023 22:17:37 - INFO - __main__ -     ********************
02/11/2023 22:17:40 - INFO - __main__ -   Epoch 81, the accuracy is 0.98989898989899
02/11/2023 22:18:08 - INFO - __main__ -   Epoch 82, step 99, train loss 0.0031
02/11/2023 22:18:13 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:18:13 - INFO - __main__ -     Num examples = 99
02/11/2023 22:18:13 - INFO - __main__ -     Batch size = 8
02/11/2023 22:18:14 - INFO - __main__ -     eval_ppl = 1.00177
02/11/2023 22:18:14 - INFO - __main__ -     global_step = 9546
02/11/2023 22:18:14 - INFO - __main__ -     train_loss = 0.0027
02/11/2023 22:18:14 - INFO - __main__ -     ********************
02/11/2023 22:18:17 - INFO - __main__ -   Epoch 82, the accuracy is 0.98989898989899
02/11/2023 22:18:45 - INFO - __main__ -   Epoch 83, step 99, train loss 0.0031
02/11/2023 22:18:50 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:18:50 - INFO - __main__ -     Num examples = 99
02/11/2023 22:18:50 - INFO - __main__ -     Batch size = 8
02/11/2023 22:18:51 - INFO - __main__ -     eval_ppl = 1.00179
02/11/2023 22:18:51 - INFO - __main__ -     global_step = 9661
02/11/2023 22:18:51 - INFO - __main__ -     train_loss = 0.0028
02/11/2023 22:18:51 - INFO - __main__ -     ********************
02/11/2023 22:18:54 - INFO - __main__ -   Epoch 83, the accuracy is 0.98989898989899
02/11/2023 22:19:23 - INFO - __main__ -   Epoch 84, step 99, train loss 0.0031
02/11/2023 22:19:27 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:19:27 - INFO - __main__ -     Num examples = 99
02/11/20202/11/2023 22:19:27 - INFO - __main__ -     Batch 02/11/20202/11/2023 22:19:28 - INFO - __main__ -     eval_ppl = 1.00178
02/11/2023 22:19:28 - INFO - __main__ -     global_step = 9776
02/11/2023 22:19:28 - INFO - __main__ -     train_loss = 0.0003
02/11/2023 22:19:28 - INFO - __main__ -     ************02/11/20202/11/2023 22:19:31 - INFO - __main__ -   Epoch 84, the accuracy is 0.98989802/11/2023 22:19:59 - INFO - __main__ -   Epoch 85, step 99, train loss 0.0036
02/11/2023 22:20:04 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:20:04 - INFO - __main__ -     Num examples = 99
02/11/2023 22:20:04 - INFO - __main__ -     Batch size = 8
02/11/20202/11/2023 22:20:05 - INFO - __main__ -     eval_ppl = 1.00186
02/11/2023 22:20:05 - INFO - __main__ -     global_step = 9891
02/11/2023 22:20:05 - INFO - __main__ -     train_loss = 0.0004
02/11/2023 22:20:05 - INFO - __main__ -     ************02/11/2023 22:20:07 - INFO - __main__ -   Epoch 85, the accuracy is 0.98989898989899
02/11/2023 22:20:36 - INFO - __main__ -   Epoch 86, step 99, train loss 0.0032
02/11/2023 22:20:41 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:20:41 - INFO - __main__ -     Num examples = 99
02/11/2023 22:20:41 - INFO - __main__ -     Batch size = 8
02/11/20202/11/2023 22:20:42 - INFO - __main__ -     eval_ppl = 1.00186
02/11/2023 22:20:42 - INFO - __main__ -     global_step = 10006
02/11/2023 22:20:42 - INFO - __main__ -     train_loss = 0.0004
02/11/2023 22:20:42 - INFO - __main__ -     ************02/11/20202/11/2023 22:20:44 - INFO - __main__ -   Epoch 86, the accuracy is 0.98989802/11/2023 22:21:13 - INFO - __main__ -   Epoch 87, step 99, train loss 0.0032
02/11/2023 22:21:17 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:21:17 - INFO - __main__ -     Num examples = 99
02/11/2023 22:21:17 - INFO - __main__ -     Batch size = 8
02/11/20202/11/2023 22:21:18 - INFO - __main__ -     eval_ppl = 1.00188
02/11/2023 22:21:18 - INFO - __main__ -     global_step = 10121
02/11/2023 22:21:18 - INFO - __main__ -     train_loss = 0.0004
02/11/2023 22:21:18 - INFO - __main__ -     ************02/11/2023 22:21:21 - INFO - __main__ -   Epoch 87, the accuracy is 0.98989898989899
02/11/2023 22:21:50 - INFO - __main__ -   Epoch 88, step 99, train loss 0.0036
02/11/2023 22:21:54 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:21:54 - INFO - __main__ -     Num examples = 99
02/11/2023 22:21:54 - INFO - __main__ -     Batch size = 8
02/11/2023 22:21:55 - INFO - __main__ -     eval_ppl = 1.00179
02/11/2023 22:21:55 - INFO - __main__ -     global_step = 10236
02/11/2023 22:21:55 - INFO - __main__ -     train_loss = 0.0032
02/11/2023 22:21:55 - INFO - __main__ -     ********************
02/11/2023 22:21:58 - INFO - __main__ -   Epoch 88, the accuracy is 0.98989898989899
02/11/2023 22:22:27 - INFO - __main__ -   Epoch 89, step 99, train loss 0.0031
02/11/2023 22:22:31 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:22:31 - INFO - __main__ -     Num examples = 99
02/11/2023 22:22:31 - INFO - __main__ -     Batch size = 8
02/11/2023 22:22:32 - INFO - __main__ -     eval_ppl = 1.00179
02/11/2023 22:22:32 - INFO - __main__ -     global_step = 10351
02/11/2023 22:22:32 - INFO - __main__ -     train_loss = 0.0027
02/11/2023 22:22:32 - INFO - __main__ -     ********************
02/11/2023 22:22:35 - INFO - __main__ -   Epoch 89, the accuracy is 0.98989898989899
02/11/2023 22:23:04 - INFO - __main__ -   Epoch 90, step 99, train loss 0.0034
02/11/2023 22:23:08 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:23:08 - INFO - __main__ -     Num examples = 99
02/11/2023 22:23:08 - INFO - __main__ -     Batch size = 8
02/11/2023 22:23:09 - INFO - __main__ -     eval_ppl = 1.00193
02/11/2023 22:23:09 - INFO - __main__ -     global_step = 10466
02/11/2023 22:23:09 - INFO - __main__ -     train_loss = 0.003
02/11/2023 22:23:09 - INFO - __main__ -     ********************
02/11/2023 22:23:12 - INFO - __main__ -   Epoch 90, the accuracy is 0.98989898989899
02/11/202302/11/2023 22:23:40 - INFO - __main__ -   Epoch 91, step 99, train lo02/11/2023 22:23:45 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:23:45 - INFO - __main__ -     Num examples = 99
02/11/2023 22:23:45 - INFO - __main__ -     Batch size = 8
02/11/202302/11/2023 22:23:46 - INFO - __main__ -     eval_ppl = 1.00189
02/11/2023 22:23:46 - INFO - __main__ -     global_step = 10581
02/11/2023 22:23:46 - INFO - __main__ -     train_loss = 0.0004
02/11/2023 22:23:46 - INFO - __main__ -     ***********02/11/202302/11/2023 22:23:48 - INFO - __main__ -   Epoch 91, the accuracy is 0.9898902/11/2023 22:24:17 - INFO - __main__ -   Epoch 92, step 99, train loss 0.0031
02/11/2023 22:24:21 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:24:21 - INFO - __main__ -     Num examples = 99
02/11/2023 22:24:21 - INFO - __main__ -     Batch size = 8
02/11/202302/11/2023 22:24:22 - INFO - __main__ -     eval_ppl = 1.00191
02/11/2023 22:24:22 - INFO - __main__ -     global_step = 10696
02/11/2023 22:24:22 - INFO - __main__ -     train_loss = 0.0003
02/11/2023 22:24:22 - INFO - __main__ -     ***********02/11/2023 22:24:25 - INFO - __main__ -   Epoch 92, the accuracy is 0.98989898989899
02/11/2023 22:24:54 - INFO - __main__ -   Epoch 93, step 99, train loss 0.0033
02/11/2023 22:24:58 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:24:58 - INFO - __main__ -     Num examples = 99
02/11/2023 22:24:58 - INFO - __main__ -     Batch size = 8
02/11/2023 22:24:59 - INFO - __main__ -     eval_ppl = 1.00193
02/11/2023 22:24:59 - INFO - __main__ -     global_step = 10811
02/11/2023 22:24:59 - INFO - __main__ -     train_loss = 0.0029
02/11/2023 22:24:59 - INFO - __main__ -     ********************
02/11/2023 22:25:02 - INFO - __main__ -   Epoch 93, the accuracy is 0.98989898989899
02/11/2023 22:25:31 - INFO - __main__ -   Epoch 94, step 99, train loss 0.0029
02/11/2023 22:25:35 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:25:35 - INFO - __main__ -     Num examples = 99
02/11/202302/11/2023 22:25:35 - INFO - __main__ -     Batch02/11/2023 22:25:36 - INFO - __main__ -     eval_ppl = 1.0019
02/11/2023 22:25:36 - INFO - __main__ -     global_step = 10926
02/11/2023 22:25:36 - INFO - __main__ -     train_loss = 0.0026
02/11/2023 22:25:36 - INFO - __main__ -     ********************
02/11/202302/11/2023 22:25:39 - INFO - __main__ -   Epoch 94, the accuracy is 0.9898902/11/2023 22:26:07 - INFO - __main__ -   Epoch 95, step 99, train loss 0.0029
02/11/2023 22:26:12 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:26:12 - INFO - __main__ -     Num examples = 99
02/11/2023 22:26:12 - INFO - __main__ -     Batch size = 8
02/11/202302/11/2023 22:26:13 - INFO - __main__ -     eval_ppl = 1.00194
02/11/2023 22:26:13 - INFO - __main__ -     global_step = 11041
02/11/2023 22:26:13 - INFO - __main__ -     train_loss = 0.0003
02/11/2023 22:26:13 - INFO - __main__ -     ***********02/11/2023 22:26:16 - INFO - __main__ -   Epoch 95, the accuracy is 0.98989898989899
02/11/2023 22:26:44 - INFO - __main__ -   Epoch 96, step 99, train loss 0.0033
02/11/2023 22:26:49 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:26:49 - INFO - __main__ -     Num examples = 99
02/11/2023 22:26:49 - INFO - __main__ -     Batch size = 8
02/11/202302/11/2023 22:26:50 - INFO - __main__ -     eval_ppl = 1.00195
02/11/2023 22:26:50 - INFO - __main__ -     global_step = 11156
02/11/2023 22:26:50 - INFO - __main__ -     train_loss = 0.0003
02/11/2023 22:26:50 - INFO - __main__ -     ***********02/11/2023 22:26:52 - INFO - __main__ -   Epoch 96, the accuracy is 0.98989898989899
02/11/2023 22:27:21 - INFO - __main__ -   Epoch 97, step 99, train loss 0.0034
02/11/2023 22:27:25 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:27:25 - INFO - __main__ -     Num examples = 99
02/11/2023 22:27:25 - INFO - __main__ -     Batch size = 8
02/11/202302/11/2023 22:27:26 - INFO - __main__ -     eval_ppl = 1.00192
02/11/2023 22:27:26 - INFO - __main__ -     global_step = 11271
02/11/2023 22:27:26 - INFO - __main__ -     train_loss = 0.0004
02/11/2023 22:27:26 - INFO - __main__ -     **********02/11/2023 22:27:29 - INFO - __main__ -   Epoch 97, the accuracy is 0.98989898989899
02/11/2023 22:27:58 - INFO - __main__ -   Epoch 98, step 99, train loss 0.0031
02/11/2023 22:28:02 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:28:02 - INFO - __main__ -     Num examples = 99
02/11/2023 22:28:02 - INFO - __main__ -     Batch size = 8
02/11/2023 22:28:03 - INFO - __main__ -     eval_ppl = 1.00191
02/11/2023 22:28:03 - INFO - __main__ -     global_step = 11386
02/11/2023 22:28:03 - INFO - __main__ -     train_loss = 0.0028
02/11/2023 22:28:03 - INFO - __main__ -     ********************
02/11/2023 22:28:06 - INFO - __main__ -   Epoch 98, the accuracy is 0.98989898989899
02/11/2023 22:28:35 - INFO - __main__ -   Epoch 99, step 99, train loss 0.0028
02/11/2023 22:28:40 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:28:40 - INFO - __main__ -     Num examples = 99
02/11/2023 22:28:40 - INFO - __main__ -     Batch size = 8
02/11/2023 22:28:40 - INFO - __main__ -     eval_ppl = 1.00169
02/11/2023 22:28:40 - INFO - __main__ -     global_step = 11501
02/11/2023 22:28:40 - INFO - __main__ -     train_loss = 0.0025
02/11/2023 22:28:40 - INFO - __main__ -     ********************
02/11/2023 22:28:43 - INFO - __main__ -   Epoch 99, the accuracy is 0.98989898989899
02/11/2023 22:29:12 - INFO - __main__ -   Epoch 100, step 99, train loss 0.0029
02/11/2023 22:29:17 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:29:17 - INFO - __main__ -     Num examples = 99
02/11/2023 22:29:17 - INFO - __main__ -     Batch size = 8
02/11/2023 22:29:17 - INFO - __main__ -     eval_ppl = 1.00192
02/11/2023 22:29:17 - INFO - __main__ -     global_step = 11616
02/11/2023 22:29:17 - INFO - __main__ -     train_loss = 0.0026
02/11/2023 22:29:17 - INFO - __main__ -     ********************
02/11/2023 22:29:20 - INFO - __main__ -   Epoch 100, the accuracy is 0.98989898989899
02/11/2023 22:29:49 - INFO - __main__ -   Epoch 101, step 99, train loss 0.0032
02/11/2023 22:29:54 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:29:54 - INFO - __main__ -     Num examples = 99
02/11/2023 22:29:54 - INFO - __main__ -     Batch size = 8
02/11/2023 22:29:54 - INFO - __main__ -     eval_ppl = 1.00185
02/11/2023 22:29:54 - INFO - __main__ -     global_step = 11731
02/11/2023 22:29:54 - INFO - __main__ -     train_loss = 0.0029
02/11/2023 22:29:54 - INFO - __main__ -     ********************
02/11/2023 22:29:57 - INFO - __main__ -   Epoch 101, the accuracy is 0.98989898989899
02/11/2023 22:30:26 - INFO - __main__ -   Epoch 102, step 99, train loss 0.0029
02/11/2023 22:30:31 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:30:31 - INFO - __main__ -     Num examples = 99
02/11/2023 22:30:31 - INFO - __main__ -     Batch size = 8
02/11/2023 22:30:31 - INFO - __main__ -     eval_ppl = 1.00184
02/11/2023 22:30:31 - INFO - __main__ -     global_step = 11846
02/11/2023 22:30:31 - INFO - __main__ -     train_loss = 0.0026
02/11/2023 22:30:31 - INFO - __main__ -     ********************
02/11/2023 22:30:34 - INFO - __main__ -   Epoch 102, the accuracy is 0.98989898989899
02/11/2023 22:31:03 - INFO - __main__ -   Epoch 103, step 99, train loss 0.003
02/11/2023 22:31:08 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:31:08 - INFO - __main__ -     Num examples = 99
02/11/2023 22:31:08 - INFO - __main__ -     Batch size = 8
02/11/2023 22:31:08 - INFO - __main__ -     eval_ppl = 1.00179
02/11/2023 22:31:08 - INFO - __main__ -     global_step = 11961
02/11/2023 22:31:08 - INFO - __main__ -     train_loss = 0.0026
02/11/2023 22:31:08 - INFO - __main__ -     ********************
02/11/2023 22:31:11 - INFO - __main__ -   Epoch 103, the accuracy is 0.98989898989899
02/11/2023 22:31:40 - INFO - __main__ -   Epoch 104, step 99, train loss 0.0033
02/11/2023 22:31:45 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:31:45 - INFO - __main__ -     Num examples = 99
02/11/2023 22:31:45 - INFO - __main__ -     Batch size = 8
02/11/2023 22:31:46 - INFO - __main__ -     eval_ppl = 1.00181
02/11/2023 22:31:46 - INFO - __main__ -     global_step = 12076
02/11/2023 22:31:46 - INFO - __main__ -     train_loss = 0.003
02/11/2023 22:31:46 - INFO - __main__ -     ********************
02/11/2023 22:31:48 - INFO - __main__ -   Epoch 104, the accuracy is 0.98989898989899
02/11/2023 22:32:17 - INFO - __main__ -   Epoch 105, step 99, train loss 0.0032
02/11/2023 22:32:22 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:32:22 - INFO - __main__ -     Num examples = 99
02/11/2023 22:32:22 - INFO - __main__ -     Batch size = 8
02/11/2023 22:32:23 - INFO - __main__ -     eval_ppl = 1.0018
02/11/2023 22:32:23 - INFO - __main__ -     global_step = 12191
02/11/2023 22:32:23 - INFO - __main__ -     train_loss = 0.0029
02/11/2023 22:32:23 - INFO - __main__ -     ********************
02/11/2023 2202/11/2023 22:32:25 - INFO - __main__ -   Epoch 105, the accuracy is 0.9802/11/2023 22:32:54 - INFO - __main__ -   Epoch 106, step 99, train loss 0.0033
02/11/2023 22:32:58 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:32:58 - INFO - __main__ -     Num examples = 99
02/11/2023 22:32:58 - INFO - __main__ -     Batch size = 8
02/11/2023 2202/11/2023 22:32:59 - INFO - __main__ -     eval_ppl = 1.00183
02/11/2023 22:32:59 - INFO - __main__ -     global_step = 12306
02/11/2023 22:32:59 - INFO - __main__ -     train_loss = 0.0003
02/11/2023 22:32:59 - INFO - __main__ -     *******02/11/2023 22:02/11/2023 22:33:02 - INFO - __main__ -   Epoch 106, the accuracy is 0.902/11/2023 22:33:30 - INFO - __main__ -   Epoch 107, step 99, train loss 0.0027
02/11/2023 22:02/11/2023 22:33:35 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:33:35 - INFO - __main__ -     Num examples = 99
02/11/2023 22:33:35 - INFO - __main__ -     B02/11/2023 22:02/11/2023 22:33:36 - INFO - __main__ -     eval_ppl = 1.00186
02/11/2023 22:33:36 - INFO - __main__ -     global_step = 12421
02/11/2023 22:33:36 - INFO - __main__ -     train_loss = 0.0003
02/11/2023 22:33:36 - INFO - __main__ -     *******02/11/2023 22:33:38 - INFO - __main__ -   Epoch 107, the accuracy is 0.98989898989899
02/11/2023 22:02/11/2023 22:34:07 - INFO - __main__ -   Epoch 108, step 99, trai02/11/2023 22:34:12 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:34:12 - INFO - __main__ -     Num examples = 99
02/11/2023 22:34:12 - INFO - __main__ -     Batch size = 8
02/11/2023 22:02/11/2023 22:34:12 - INFO - __main__ -     eval_ppl = 1.00186
02/11/2023 22:34:12 - INFO - __main__ -     global_step = 12536
02/11/2023 22:34:12 - INFO - __main__ -     train_loss = 0.0004
02/11/2023 22:34:12 - INFO - __main__ -     *******02/11/2023 22:02/11/2023 22:34:15 - INFO - __main__ -   Epoch 108, the accuracy is 0.902/11/2023 22:34:44 - INFO - __main__ -   Epoch 109, step 99, train loss 0.003
02/11/2023 22:34:48 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:34:48 - INFO - __main__ -     Num examples = 99
02/11/2023 22:34:48 - INFO - __main__ -     Batch size = 8
02/11/2023 22:302/11/2023 22:34:49 - INFO - __main__ -     eval_ppl = 1.00191
02/11/2023 22:34:49 - INFO - __main__ -     global_step = 12651
02/11/2023 22:34:49 - INFO - __main__ -     train_loss = 0.0004
02/11/2023 22:34:49 - INFO - __main__ -     ******02/11/2023 22:302/11/2023 22:34:52 - INFO - __main__ -   Epoch 109, the accuracy is 0.02/11/2023 22:35:20 - INFO - __main__ -   Epoch 110, step 99, train loss 0.0026
02/11/2023 22:35:25 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:35:25 - INFO - __main__ -     Num examples = 99
02/11/2023 22:35:25 - INFO - __main__ -     Batch size = 8
02/11/2023 22:302/11/2023 22:35:26 - INFO - __main__ -     eval_ppl = 1.00195
02/11/2023 22:35:26 - INFO - __main__ -     global_step = 12766
02/11/2023 22:35:26 - INFO - __main__ -     train_loss = 0.0003
02/11/2023 22:35:26 - INFO - __main__ -     ******02/11/2023 22:35:28 - INFO - __main__ -   Epoch 110, the accuracy is 0.98989898989899
02/11/2023 22:35:57 - INFO - __main__ -   Epoch 111, step 99, train loss 0.0034
02/11/2023 22:36:02 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:36:02 - INFO - __main__ -     Num examples = 99
02/11/2023 22:36:02 - INFO - __main__ -     Batch size = 8
02/11/2023 22:36:03 - INFO - __main__ -     eval_ppl = 1.00196
02/11/2023 22:36:03 - INFO - __main__ -     global_step = 12881
02/11/2023 22:36:03 - INFO - __main__ -     train_loss = 0.003
02/11/2023 22:36:03 - INFO - __main__ -     ********************
02/11/2023 22:36:05 - INFO - __main__ -   Epoch 111, the accuracy is 0.98989898989899
02/11/2023 22:36:34 - INFO - __main__ -   Epoch 112, step 99, train loss 0.0031
02/11/2023 22:36:39 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:36:39 - INFO - __main__ -     Num examples = 99
02/11/2023 22:36:39 - INFO - __main__ -     Batch size = 8
02/11/2023 22:3602/11/2023 22:36:39 - INFO - __main__ -     eval_ppl = 1.00196
02/11/2023 22:36:39 - INFO - __main__ -     global_step = 12996
02/11/2023 22:36:39 - INFO - __main__ -     train_loss = 0.0003
02/11/2023 22:36:39 - INFO - __main__ -     *****02/11/2023 22:36:42 - INFO - __main__ -   Epoch 112, the accuracy is 0.98989898989899
02/11/2023 22:37:11 - INFO - __main__ -   Epoch 113, step 99, train loss 0.0031
02/11/2023 22:37:16 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:37:16 - INFO - __main__ -     Num examples = 99
02/11/2023 22:37:16 - INFO - __main__ -     Batch size = 8
02/11/2023 22:37:16 - INFO - __main__ -     eval_ppl = 1.00197
02/11/2023 22:37:16 - INFO - __main__ -     global_step = 13111
02/11/2023 22:37:16 - INFO - __main__ -     train_loss = 0.0027
02/11/2023 22:37:16 - INFO - __main__ -     ********************
02/11/2023 22:37:19 - INFO - __main__ -   Epoch 113, the accuracy is 0.98989898989899
02/11/2023 22:37:48 - INFO - __main__ -   Epoch 114, step 99, train loss 0.003
02/11/2023 22:37:53 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:37:53 - INFO - __main__ -     Num examples = 99
02/11/2023 22:37:53 - INFO - __main__ -     Batch size = 8
02/11/2023 22:37:54 - INFO - __main__ -     eval_ppl = 1.00199
02/11/2023 22:37:54 - INFO - __main__ -     global_step = 13226
02/11/2023 22:37:54 - INFO - __main__ -     train_loss = 0.0027
02/11/2023 22:37:54 - INFO - __main__ -     ********************
02/11/2023 22:37:56 - INFO - __main__ -   Epoch 114, the accuracy is 0.98989898989899
02/11/2023 22:38:25 - INFO - __main__ -   Epoch 115, step 99, train loss 0.0035
02/11/2023 22:38:30 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:38:30 - INFO - __main__ -     Num examples = 99
02/11/2023 22:38:30 - INFO - __main__ -     Batch size = 8
02/11/2023 22:38:31 - INFO - __main__ -     eval_ppl = 1.00196
02/11/2023 22:38:31 - INFO - __main__ -     global_step = 13341
02/11/2023 22:38:31 - INFO - __main__ -     train_loss = 0.0032
02/11/2023 22:38:31 - INFO - __main__ -     ********************
02/11/2023 22:38:33 - INFO - __main__ -   Epoch 115, the accuracy is 0.98989898989899
02/11/2023 22:39:02 - INFO - __main__ -   Epoch 116, step 99, train loss 0.003
02/11/2023 22:39:07 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:39:07 - INFO - __main__ -     Num examples = 99
02/11/2023 22:39:07 - INFO - __main__ -     Batch size = 8
02/11/2023 22:39:08 - INFO - __main__ -     eval_ppl = 1.00195
02/11/2023 22:39:08 - INFO - __main__ -     global_step = 13456
02/11/2023 22:39:08 - INFO - __main__ -     train_loss = 0.0027
02/11/2023 22:39:08 - INFO - __main__ -     ********************
02/11/2023 22:39:10 - INFO - __main__ -   Epoch 116, the accuracy is 0.98989898989899
02/11/2023 22:39:39 - INFO - __main__ -   Epoch 117, step 99, train loss 0.003
02/11/2023 22:39:44 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:39:44 - INFO - __main__ -     Num examples = 99
02/11/2023 22:39:44 - INFO - __main__ -     Batch size = 8
02/11/2023 22:39:4502/11/2023 22:39:45 - INFO - __main__ -     eval_ppl = 1.00195
02/11/2023 22:39:45 - INFO - __main__ -     global_step = 13571
02/11/2023 22:39:45 - INFO - __main__ -     train_loss = 0.0003
02/11/2023 22:39:45 - INFO - __main__ -     **02/11/2023 22:39:47 - INFO - __main__ -   Epoch 117, the accuracy is 0.98989898989899
02/11/2023 22:40:16 - INFO - __main__ -   Epoch 118, step 99, train loss 0.0027
02/11/2023 22:40:21 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:40:21 - INFO - __main__ -     Num examples = 99
02/11/2023 22:40:21 - INFO - __main__ -     Batch size = 8
02/11/2023 22:40:22 - INFO - __main__ -     eval_ppl = 1.00195
02/11/2023 22:40:22 - INFO - __main__ -     global_step = 13686
02/11/2023 22:40:22 - INFO - __main__ -     train_loss = 0.0024
02/11/2023 22:40:22 - INFO - __main__ -     ********************
02/11/2023 22:40:24 - INFO - __main__ -   Epoch 118, the accuracy is 0.98989898989899
02/11/2023 22:40:5302/11/2023 22:40:53 - INFO - __main__ -   Epoch 119, step 99,02/11/2023 22:40:58 - INFO - __main__ -   
***** Running evaluation *****
02/11/2023 22:40:58 - INFO - __main__ -     Num examples = 99
02/11/2023 22:40:58 - INFO - __main__ -     Batch size = 8
02/11/2023 22:40:5802/11/2023 22:40:58 - INFO - __main__ -     eval_ppl = 1.00195
02/11/2023 22:40:58 - INFO - __main__ -     global_step = 13801
02/11/2023 22:40:58 - INFO - __main__ -     train_loss = 0.0003
02/11/2023 22:40:58 - INFO - __main__ -     **02/11/2023 22:41:0102/11/2023 22:41:01 - INFO - __main__ -   Epoch 119, the accuracy is 0.98989898989899
02/11/2023 22:41:01 - INFO - __main__ -   Test file: final_final_dataset/java/val_data_of02/11/2023 22:41:0202/11/2023 22:41:02 - INFO - __main__ -   gold_info:{'all_count': 99, 'Positive': 5, 'Negative': 94}
02/11/2023 22:41:02 - INFO - __main__ -   pre_info:{'TP': 4, 'FP': 0, 'TN': 94, 'FN': 1}
02/11/2023 22:41:02 - INFO - __main__ -   Epoch 119, the accuracy is 0.98989898989899, the precision is 1.0, the recall is 0.8, the fscore is 0.888888888888889
02/11/2023 22:41:02 - INFO - __main__ -   Test file: final_final_dataset/java/test_data_of02/11/2023 22:41:0702/11/2023 22:41:07 - INFO - __main__ -   gold_info:{'all_count': 487, 'Positive': 27, 'Negative': 460}
02/11/2023 22:41:07 - INFO - __main__ -   pre_info:{'TP': 19, 'FP': 2, 'TN': 458, 'FN': 8}
02/11/2023 22:41:07 - INFO - __main__ -   Epoch 119, the accuracy is 0.9794661190965093, the precision is 0.9047619047619048, the recall is 0.7037037037037037, the fscore is 0.7916666666666667
