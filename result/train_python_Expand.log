02/12/2023 14:28:41 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, beam_size=10, config_name='', dev_filename='final_final_dataset/python/val_data_of_Expand.jsonl', do_eval=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=8, eval_steps=-1, gradient_accumulation_steps=1, learning_rate=5e-05, load_model_path=None, local_rank=0, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=32, model_name_or_path=None, model_type=None, no_cuda=False, num_train_epochs=120, output_dir='python_Expand_output', seed=42, test_filename='final_final_dataset/python/test_data_of_Expand.jsonl', tokenizer_name='', train_batch_size=8, train_filename='final_final_dataset/python/train_data_of_Expand.jsonl', train_log_filename='python_Expand', train_steps=-1, visible_gpu='0, 1', warmup_steps=0, weight_decay=0.0)
02/12/2023 14:28:41 - INFO - torch.distributed.distributed_c10d -   Added key: store_based_barrier_key:1 to store for rank: 0
02/12/2023 14:28:41 - INFO - torch.distributed.distributed_c10d -   Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
02/12/2023 14:28:41 - WARNING - __main__ -   Process rank: 1, device: cuda:1, n_gpu: 1, distributed training: True
02/12/2023 14:28:46 - INFO - __main__ -   model loaded!
02/12/2023 14:28:46 - INFO - __main__ -   *** Example ***
02/12/2023 14:28:46 - INFO - __main__ -   idx: 0
02/12/2023 14:28:46 - INFO - __main__ -   source_tokens: ['<s>', 'Classification', ':', '_given', '_a', '_file', '_like', '_object', '_as', '_the', '</s>']
02/12/2023 14:28:46 - INFO - __main__ -   source_ids: 1 19168 30 864 279 585 3007 733 487 326 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/12/2023 14:28:46 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/12/2023 14:28:46 - INFO - __main__ -   target_tokens: ['<s>', 'true', '</s>']
02/12/2023 14:28:46 - INFO - __main__ -   target_ids: 1 3767 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/12/2023 14:28:46 - INFO - __main__ -   target_mask: 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/12/2023 14:28:46 - INFO - __main__ -   *** Example ***
02/12/2023 14:28:46 - INFO - __main__ -   idx: 1
02/12/2023 14:28:46 - INFO - __main__ -   source_tokens: ['<s>', 'Classification', ':', '_none', '</s>']
02/12/2023 14:28:46 - INFO - __main__ -   source_ids: 1 19168 30 6555 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/12/2023 14:28:46 - INFO - __main__ -   source_mask: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/12/2023 14:28:46 - INFO - __main__ -   target_tokens: ['<s>', 'true', '</s>']
02/12/2023 14:28:46 - INFO - __main__ -   target_ids: 1 3767 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/12/2023 14:28:46 - INFO - __main__ -   target_mask: 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/12/2023 14:28:46 - INFO - __main__ -   *** Example ***
02/12/2023 14:28:46 - INFO - __main__ -   idx: 2
02/12/2023 14:28:46 - INFO - __main__ -   source_tokens: ['<s>', 'Classification', ':', '_will', '_be', '_swap', 'ped', '_to', '_nn', 'q', '_quant', 'ize', '_which', '_does', '_actual', '_quant', 'ization', '</s>']
02/12/2023 14:28:46 - INFO - __main__ -   source_ids: 1 19168 30 903 506 7720 1845 358 7761 85 10251 554 1492 1552 3214 10251 1588 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/12/2023 14:28:46 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/12/2023 14:28:46 - INFO - __main__ -   target_tokens: ['<s>', 'true', '</s>']
02/12/2023 14:28:46 - INFO - __main__ -   target_ids: 1 3767 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/12/2023 14:28:46 - INFO - __main__ -   target_mask: 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/12/2023 14:28:46 - INFO - __main__ -   *** Example ***
02/12/2023 14:28:46 - INFO - __main__ -   idx: 3
02/12/2023 14:28:46 - INFO - __main__ -   source_tokens: ['<s>', 'Classification', ':', '_methods', '</s>']
02/12/2023 14:28:46 - INFO - __main__ -   source_ids: 1 19168 30 2590 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/12/2023 14:28:46 - INFO - __main__ -   source_mask: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/12/2023 14:28:46 - INFO - __main__ -   target_tokens: ['<s>', 'true', '</s>']
02/12/2023 14:28:46 - INFO - __main__ -   target_ids: 1 3767 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/12/2023 14:28:46 - INFO - __main__ -   target_mask: 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/12/2023 14:28:46 - INFO - __main__ -   *** Example ***
02/12/2023 14:28:46 - INFO - __main__ -   idx: 4
02/12/2023 14:28:46 - INFO - __main__ -   source_tokens: ['<s>', 'Classification', ':', '_does', '_not', '_match', '_at', '_the', '_current', '_position', '</s>']
02/12/2023 14:28:46 - INFO - __main__ -   source_ids: 1 19168 30 1552 486 845 622 326 783 1754 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/12/2023 14:28:46 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/12/2023 14:28:46 - INFO - __main__ -   target_tokens: ['<s>', 'true', '</s>']
02/12/2023 14:28:46 - INFO - __main__ -   target_ids: 1 3767 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/12/2023 14:28:46 - INFO - __main__ -   target_mask: 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/12/2023 14:28:47 - INFO - __main__ -   ***** Running training *****
02/12/2023 14:28:47 - INFO - __main__ -     Num examples = 1638
02/12/2023 14:28:47 - INFO - __main__ -     Batch size = 8
02/12/2023 14:28:47 - INFO - __main__ -     Num epoch = 120
02/12/2023 14:28:48 - INFO - torch.nn.parallel.distributed -   Reducer buckets have been rebuilt in this iteration.
02/12/2023 14:29:17 - INFO - __main__ -   Epoch 0, step 99, train loss 9.6488
02/12/2023 14:29:19 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 14:29:19 - INFO - __main__ -     Num examples = 401
02/12/2023 14:29:19 - INFO - __main__ -     Batch size = 8
02/12/2023 14:29:22 - INFO - __main__ -     eval_ppl = 1.33282
02/12/2023 14:29:22 - INFO - __main__ -     global_step = 104
02/12/2023 14:29:22 - INFO - __main__ -     train_loss = 9.5633
02/12/2023 14:29:22 - INFO - __main__ -     ********************
02/12/2023 14:29:23 - INFO - __main__ -     Best ppl:1.33282
02/12/2023 14:29:23 - INFO - __main__ -     ********************
02/12/2023 14:29:33 - INFO - __main__ -   Epoch 0, the accuracy is 0.022443890274314215
02/12/2023 14:30:02 - INFO - __main__ -   Epoch 1, step 99, train loss 0.825202/12/2023 14:30:03 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 14:30:03 - INFO - __main__ -     Num examples = 401
02/12/2023 14:30:03 - INFO - __main__ -     Batch size = 8
02/12/2023 14:30:07 - INFO - __main__ -     eval_ppl = 1.00714
02/12/2023 14:30:07 - INFO - __main__ -     global_step = 207
02/12/2023 14:30:07 - INFO - __main__ -     train_loss = 0.7521
02/12/2023 14:30:07 - INFO - __main__ -     ********************
02/12/2023 14:30:08 - INFO - __main__ -     Best ppl:1.00714
02/12/2023 14:30:08 - INFO - __main__ -     ********************
02/12/2023 14:30:15 - INFO - __main__ -   Epoch 1, the accuracy is 0.8054862842892768
02/12/2023 14:30:44 - INFO - __main__ -   Epoch 2, step 99, train loss 0.1672
02/12/2023 14:30:45 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 14:30:45 - INFO - __main__ -     Num examples = 401
02/12/2023 14:30:45 - INFO - __main__ -     Batch size = 8
02/12/2023 14:30:49 - INFO - __main__ -     eval_ppl = 1.00672
02/12/2023 14:30:49 - INFO - __main__ -     global_step = 310
02/12/2023 14:30:49 - INFO - __main__ -     train_loss = 0.1655
02/12/2023 14:30:49 - INFO - __main__ -     ********************
02/12/2023 14:30:50 - INFO - __main__ -     Best ppl:1.00672
02/12/2023 14:30:50 - INFO - __main__ -     ********************
02/12/2023 14:30:57 - INFO - __main__ -   Epoch 2, the accuracy is 0.8079800498753117
002/12/2023 14:31:26 - INFO - __main__ -   Epoch 3, step 99, train loss 0.170402/12/2023 14:31:28 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 14:31:28 - INFO - __main__ -     Num examples = 401
02/12/2023 14:31:28 - INFO - __main__ -     Batch size = 8
02/12/2023 14:31:31 - INFO - __main__ -     eval_ppl = 1.00635
02/12/2023 14:31:31 - INFO - __main__ -     global_step = 413
02/12/2023 14:31:31 - INFO - __main__ -     train_loss = 0.1466
02/12/2023 14:31:31 - INFO - __main__ -     ********************
02/12/2023 14:31:32 - INFO - __main__ -     Best ppl:1.00635
02/12/2023 14:31:32 - INFO - __main__ -     ********************
02/12/2023 14:31:38 - INFO - __main__ -   Epoch 3, the accuracy is 0.8129675810473815
02/12/2023 14:32:08 - INFO - __main__ -   Epoch 4, step 99, train loss 0.1468
02/12/2023 14:32:09 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 14:32:09 - INFO - __main__ -     Num examples = 401
02/12/2023 14:32:09 - INFO - __main__ -     Batch size = 8
02/12/2023 14:32:13 - INFO - __main__ -     eval_ppl = 1.00589
02/12/2023 14:32:13 - INFO - __main__ -     global_step = 516
02/12/2023 14:32:13 - INFO - __main__ -     train_loss = 0.1457
02/12/2023 14:32:13 - INFO - __main__ -     ********************
02/12/2023 14:32:14 - INFO - __main__ -     Best ppl:1.00589
02/12/2023 14:32:14 - INFO - __main__ -     ********************
02/12/2023 14:32:20 - INFO - __main__ -   Epoch 4, the accuracy is 0.8129675810473815
02/12/2023 14:32:50 - INFO - __main__ -   Epoch 5, step 99, train loss 0.1388
02/12/2023 14:32:51 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 14:32:51 - INFO - __main__ -     Num examples = 401
02/12/2023 14:32:51 - INFO - __main__ -     Batch size = 8
02/12/2023 14:32:55 - INFO - __main__ -     eval_ppl = 1.00529
02/12/2023 14:32:55 - INFO - __main__ -     global_step = 619
02/12/2023 14:32:55 - INFO - __main__ -     train_loss = 0.1386
02/12/2023 14:32:55 - INFO - __main__ -     ********************
02/12/2023 14:32:56 - INFO - __main__ -     Best ppl:1.00529
02/12/2023 14:32:56 - INFO - __main__ -     ********************
02/12/2023 14:33:03 - INFO - __main__ -   Epoch 5, the accuracy is 0.830423940149626
02/12/2023 14:33:32 - INFO - __main__ -   Epoch 6, step 99, train loss 0.1177
02/12/2023 14:33:33 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 14:33:33 - INFO - __main__ -     Num examples = 401
02/12/2023 14:33:33 - INFO - __main__ -     Batch size = 8
02/12/2023 14:33:37 - INFO - __main__ -     eval_ppl = 1.00488
02/12/2023 14:33:37 - INFO - __main__ -     global_step = 722
02/12/2023 14:33:37 - INFO - __main__ -     train_loss = 0.1182
02/12/2023 14:33:37 - INFO - __main__ -     ********************
02/12/2023 14:33:38 - INFO - __main__ -     Best ppl:1.00488
02/12/2023 14:33:38 - INFO - __main__ -     ********************
02/12/2023 14:33:44 - INFO - __main__ -   Epoch 6, the accuracy is 0.8453865336658354
02/12/2023 14:34:14 - INFO - __main__ -   Epoch 7, step 99, train loss 0.1058
02/12/2023 14:34:15 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 14:34:15 - INFO - __main__ -     Num examples = 401
02/12/2023 14:34:15 - INFO - __main__ -     Batch size = 8
02/12/2023 14:34:19 - INFO - __main__ -     eval_ppl = 1.00453
02/12/2023 14:34:19 - INFO - __main__ -     global_step = 825
02/12/2023 14:34:19 - INFO - __main__ -     train_loss = 0.1047
02/12/2023 14:34:19 - INFO - __main__ -     ********************
02/12/2023 14:34:20 - INFO - __main__ -     Best ppl:1.00453
02/12/2023 14:34:20 - INFO - __main__ -     ********************
02/12/2023 14:34:26 - INFO - __main__ -   Epoch 7, the accuracy is 0.8603491271820449
02/12/2023 14:34:56 - INFO - __main__ -   Epoch 8, step 99, train loss 0.0887
02/12/2023 14:34:57 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 14:34:57 - INFO - __main__ -     Num examples = 401
02/12/2023 14:34:57 - INFO - __main__ -     Batch size = 8
02/12/2023 14:35:00 - INFO - __main__ -     eval_ppl = 1.00513
02/12/2023 14:35:00 - INFO - __main__ -     global_step = 928
02/12/2023 14:35:00 - INFO - __main__ -     train_loss = 0.0892
02/12/2023 14:35:00 - INFO - __main__ -     ********************002/12/2023 14:35:07 - INFO - __main__ -   Epoch 8, the accuracy is 0.8478802992518704002/12/2023 14:35:36 - INFO - __main__ -   Epoch 9, step 99, train loss 0.0749002/12/2023 14:35:37 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 14:35:37 - INFO - __main__ -     Num examples = 401
02/12/2023 14:35:37 - INFO - __main__ -     Batch size = 8002/12/2023 14:35:41 - INFO - __main__ -     eval_ppl = 1.00523
02/12/2023 14:35:41 - INFO - __main__ -     global_step = 1031
02/12/2023 14:35:41 - INFO - __main__ -     train_loss = 0.0744
02/12/2023 14:35:41 - INFO - __main__ -     ********************002/12/2023 14:35:47 - INFO - __main__ -   Epoch 9, the accuracy is 0.845386533665835402/12/2023 14:36:17 - INFO - __main__ -   Epoch 10, step 99, train loss 0.0575
02/12/2023 14:36:18 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 14:36:18 - INFO - __main__ -     Num examples = 401
02/12/2023 14:36:18 - INFO - __main__ -     Batch size = 8
02/12/2023 14:36:21 - INFO - __main__ -     eval_ppl = 1.00663
02/12/2023 14:36:21 - INFO - __main__ -     global_step = 1134
02/12/2023 14:36:21 - INFO - __main__ -     train_loss = 0.0539
02/12/2023 14:36:21 - INFO - __main__ -     ********************
02/12/2023 14:36:27 - INFO - __main__ -   Epoch 10, the accuracy is 0.85785536159601
02/12/2023 14:36:57 - INFO - __main__ -   Epoch 11, step 99, train loss 0.0357
02/12/2023 14:36:58 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 14:36:58 - INFO - __main__ -     Num examples = 401
02/12/2023 14:36:58 - INFO - __main__ -     Batch size = 8
02/12/2023 14:37:02 - INFO - __main__ -     eval_ppl = 1.00706
02/12/2023 14:37:02 - INFO - __main__ -     global_step = 1237
02/12/2023 14:37:02 - INFO - __main__ -     train_loss = 0.0358
02/12/2023 14:37:02 - INFO - __main__ -     ********************
02/12/2023 14:37:08 - INFO - __main__ -   Epoch 11, the accuracy is 0.8403990024937655
02/12/2023 14:37:37 - INFO - __main__ -   Epoch 12, step 99, train loss 0.0299
02/12/2023 14:37:38 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 14:37:38 - INFO - __main__ -     Num examples = 401
02/12/2023 14:37:38 - INFO - __main__ -     Batch size = 8
02/12/2023 14:37:42 - INFO - __main__ -     eval_ppl = 1.00751
02/12/2023 14:37:42 - INFO - __main__ -     global_step = 1340
02/12/2023 14:37:42 - INFO - __main__ -     train_loss = 0.0293
02/12/2023 14:37:42 - INFO - __main__ -     ********************
02/12/2023 14:37:48 - INFO - __main__ -   Epoch 12, the accuracy is 0.8678304239401496
02/12/2023 14:38:18 - INFO - __main__ -   Epoch 13, step 99, train loss 0.0226
02/12/2023 14:38:19 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 14:38:19 - INFO - __main__ -     Num examples = 401
02/12/2023 14:38:19 - INFO - __main__ -     Batch size = 8
02/12/2023 14:38:23 - INFO - __main__ -     eval_ppl = 1.00875
02/12/2023 14:38:23 - INFO - __main__ -     global_step = 1443
02/12/2023 14:38:23 - INFO - __main__ -     train_loss = 0.0222
02/12/2023 14:38:23 - INFO - __main__ -     ********************
02/12/2023 14:38:28 - INFO - __main__ -   Epoch 13, the accuracy is 0.8428927680798005
02/12/2023 14:38:58 - INFO - __main__ -   Epoch 14, step 99, train loss 0.0184
02/12/2023 14:38:59 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 14:38:59 - INFO - __main__ -     Num examples = 401
02/12/2023 14:38:59 - INFO - __main__ -     Batch size = 8
02/12/2023 14:39:03 - INFO - __main__ -     eval_ppl = 1.00959
02/12/2023 14:39:03 - INFO - __main__ -     global_step = 1546
02/12/2023 14:39:03 - INFO - __main__ -     train_loss = 0.0178
02/12/2023 14:39:03 - INFO - __main__ -     ********************
02/12/2023 14:39:09 - INFO - __main__ -   Epoch 14, the accuracy is 0.8354114713216958
02/12/2023 14:39:38 - INFO - __main__ -   Epoch 15, step 99, train loss 0.0154
02/12/2023 14:39:40 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 14:39:40 - INFO - __main__ -     Num examples = 401
02/12/2023 14:39:40 - INFO - __main__ -     Batch size = 8
02/12/2023 14:39:43 - INFO - __main__ -     eval_ppl = 1.00974
02/12/2023 14:39:43 - INFO - __main__ -     global_step = 1649
02/12/2023 14:39:43 - INFO - __main__ -     train_loss = 0.015
02/12/2023 14:39:43 - INFO - __main__ -     ********************
02/12/2023 14:39:49 - INFO - __main__ -   Epoch 15, the accuracy is 0.8254364089775561
02/12/2023 14:40:19 - INFO - __main__ -   Epoch 16, step 99, train loss 0.0083
02/12/2023 14:40:20 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 14:40:20 - INFO - __main__ -     Num examples = 401
02/12/2023 14:40:20 - INFO - __main__ -     Batch size = 8
02/12/2023 14:40:24 - INFO - __main__ -     eval_ppl = 1.01039
02/12/2023 14:40:24 - INFO - __main__ -     global_step = 1752
02/12/2023 14:40:24 - INFO - __main__ -     train_loss = 0.0081
02/12/2023 14:40:24 - INFO - __main__ -     ********************
02/12/2023 14:40:30 - INFO - __main__ -   Epoch 16, the accuracy is 0.8553615960099751
02/12/2023 14:40:59 - INFO - __main__ -   Epoch 17, step 99, train loss 0.0091
02/12/2023 14:41:01 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 14:41:01 - INFO - __main__ -     Num examples = 401
02/12/2023 14:41:01 - INFO - __main__ -     Batch size = 8
02/12/2023 14:41:04 - INFO - __main__ -     eval_ppl = 1.00893
02/12/2023 14:41:04 - INFO - __main__ -     global_step = 1855
02/12/2023 14:41:04 - INFO - __main__ -     train_loss = 0.0088
02/12/2023 14:41:04 - INFO - __main__ -     ********************
02/12/2023 14:41:10 - INFO - __main__ -   Epoch 17, the accuracy is 0.8503740648379052
002/12/2023 14:41:40 - INFO - __main__ -   Epoch 18, step 99, train loss 0.0081002/12/2023 14:41:41 - INFO - __main__ -   
***** Running evaluation *****002/12/2023 14:41:41 - INFO - __main__ -     Num examples = 401002/12/2023 14:41:41 - INFO - __main__ -     Batch size = 802/12/2023 14:41:44 - INFO - __main__ -     eval_ppl = 1.00997
02/12/2023 14:41:44 - INFO - __main__ -     global_step = 1958
02/12/2023 14:41:44 - INFO - __main__ -     train_loss = 0.0071
02/12/2023 14:41:44 - INFO - __main__ -     ********************
02/12/2023 14:41:50 - INFO - __main__ -   Epoch 18, the accuracy is 0.830423940149626
02/12/2023 14:42:20 - INFO - __main__ -   Epoch 19, step 99, train loss 0.0071
02/12/2023 14:42:21 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 14:42:21 - INFO - __main__ -     Num examples = 401
02/12/2023 14:42:21 - INFO - __main__ -     Batch size = 8
02/12/2023 14:42:25 - INFO - __main__ -     eval_ppl = 1.01056
02/12/2023 14:42:25 - INFO - __main__ -     global_step = 2061
02/12/2023 14:42:25 - INFO - __main__ -     train_loss = 0.0068
02/12/2023 14:42:25 - INFO - __main__ -     ********************
02/12/2023 14:42:30 - INFO - __main__ -   Epoch 19, the accuracy is 0.8379052369077307
002/12/2023 14:43:00 - INFO - __main__ -   Epoch 20, step 99, train loss 0.004202/12/2023 14:43:01 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 14:43:01 - INFO - __main__ -     Num examples = 401
02/12/2023 14:43:01 - INFO - __main__ -     Batch size = 8
02/12/2023 14:43:05 - INFO - __main__ -     eval_ppl = 1.01045
02/12/2023 14:43:05 - INFO - __main__ -     global_step = 2164
02/12/2023 14:43:05 - INFO - __main__ -     train_loss = 0.0072
02/12/2023 14:43:05 - INFO - __main__ -     ********************
02/12/2023 14:43:11 - INFO - __main__ -   Epoch 20, the accuracy is 0.8379052369077307
002/12/2023 14:43:41 - INFO - __main__ -   Epoch 21, step 99, train loss 0.0074002/12/2023 14:43:42 - INFO - __main__ -   
***** Running evaluation *****002/12/2023 14:43:42 - INFO - __main__ -     Num examples = 401
02/12/2023 14:43:42 - INFO - __main__ -     Batch size = 802/12/2023 14:43:45 - INFO - __main__ -     eval_ppl = 1.01021
02/12/2023 14:43:45 - INFO - __main__ -     global_step = 2267
02/12/2023 14:43:45 - INFO - __main__ -     train_loss = 0.006
02/12/2023 14:43:45 - INFO - __main__ -     ********************
02/12/2023 14:43:51 - INFO - __main__ -   Epoch 21, the accuracy is 0.8603491271820449
02/12/2023 14:44:21 - INFO - __main__ -   Epoch 22, step 99, train loss 0.0047
02/12/2023 14:44:22 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 14:44:22 - INFO - __main__ -     Num examples = 401
02/12/2023 14:44:22 - INFO - __main__ -     Batch size = 8
0202/12/2023 14:44:26 - INFO - __main__ -     eval_ppl = 1.01086
02/12/2023 14:44:26 - INFO - __main__ -     global_step = 2370
02/12/2023 14:44:26 - INFO - __main__ -     train_loss = 0.0047
02/12/2023 14:44:26 - INFO - __main__ -     *******************0202/12/2023 14:44:32 - INFO - __main__ -   Epoch 22, the accuracy is 0.8653366583541140202/12/2023 14:45:01 - INFO - __main__ -   Epoch 23, step 99, train loss 0.00202/12/2023 14:45:03 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 14:45:03 - INFO - __main__ -     Num examples = 401
02/12/2023 14:45:03 - INFO - __main__ -     Batch size = 8
0202/12/2023 14:45:06 - INFO - __main__ -     eval_ppl = 1.01178
02/12/2023 14:45:06 - INFO - __main__ -     global_step = 2473
02/12/2023 14:45:06 - INFO - __main__ -     train_loss = 0.003
02/12/2023 14:45:06 - INFO - __main__ -     ********************002/12/2023 14:45:12 - INFO - __main__ -   Epoch 23, the accuracy is 0.860349127182044902/12/2023 14:45:42 - INFO - __main__ -   Epoch 24, step 99, train loss 0.0052
02/12/2023 14:45:43 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 14:45:43 - INFO - __main__ -     Num examples = 401
02/12/2023 14:45:43 - INFO - __main__ -     Batch size = 8
002/12/2023 14:45:47 - INFO - __main__ -     eval_ppl = 1.01168
02/12/2023 14:45:47 - INFO - __main__ -     global_step = 2576
02/12/2023 14:45:47 - INFO - __main__ -     train_loss = 0.004
02/12/2023 14:45:47 - INFO - __main__ -     ********************002/12/2023 14:45:53 - INFO - __main__ -   Epoch 24, the accuracy is 0.850374064837905202/12/2023 14:46:23 - INFO - __main__ -   Epoch 25, step 99, train loss 0.0044
02/12/2023 14:46:24 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 14:46:24 - INFO - __main__ -     Num examples = 401
02/12/2023 14:46:24 - INFO - __main__ -     Batch size = 8
02/12/2023 14:46:27 - INFO - __main__ -     eval_ppl = 1.0121
02/12/2023 14:46:27 - INFO - __main__ -     global_step = 2679
02/12/2023 14:46:27 - INFO - __main__ -     train_loss = 0.0032
02/12/2023 14:46:27 - INFO - __main__ -     ********************
02/12/2023 14:46:33 - INFO - __main__ -   Epoch 25, the accuracy is 0.8653366583541147
02/12/2023 14:47:03 - INFO - __main__ -   Epoch 26, step 99, train loss 0.002302/12/2023 14:47:04 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 14:47:04 - INFO - __main__ -     Num examples = 401
02/12/2023 14:47:04 - INFO - __main__ -     Batch size = 8
02/12/2023 14:47:08 - INFO - __main__ -     eval_ppl = 1.01268
02/12/2023 14:47:08 - INFO - __main__ -     global_step = 2782
02/12/2023 14:47:08 - INFO - __main__ -     train_loss = 0.0029
02/12/2023 14:47:08 - INFO - __main__ -     ********************
02/12/2023 14:47:14 - INFO - __main__ -   Epoch 26, the accuracy is 0.8628428927680798
002/12/2023 14:47:44 - INFO - __main__ -   Epoch 27, step 99, train loss 0.00302/12/2023 14:47:45 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 14:47:45 - INFO - __main__ -     Num examples = 401
02/12/2023 14:47:45 - INFO - __main__ -     Batch size = 8
02/12/2023 14:47:48 - INFO - __main__ -     eval_ppl = 1.01312
02/12/2023 14:47:48 - INFO - __main__ -     global_step = 2885
02/12/2023 14:47:48 - INFO - __main__ -     train_loss = 0.0038
02/12/2023 14:47:48 - INFO - __main__ -     ********************
0202/12/2023 14:47:55 - INFO - __main__ -   Epoch 27, the accuracy is 0.86034912718204402/12/2023 14:48:24 - INFO - __main__ -   Epoch 28, step 99, train loss 0.0059
02/12/2023 14:48:25 - INFO - __main__ -   
***** Running evaluation *****
0202/12/2023 14:48:25 - INFO - __main__ -     Num examples = 400202/12/2023 14:48:25 - INFO - __main__ -     Batch size = 0202/12/2023 14:48:29 - INFO - __main__ -     eval_ppl = 1.01458
02/12/2023 14:48:29 - INFO - __main__ -     global_step = 2988
02/12/2023 14:48:29 - INFO - __main__ -     train_loss = 0.0036
02/12/2023 14:48:29 - INFO - __main__ -     *******************0202/12/2023 14:48:35 - INFO - __main__ -   Epoch 28, the accuracy is 0.83291770573566002/12/2023 14:49:05 - INFO - __main__ -   Epoch 29, step 99, train loss 0.0083
0202/12/2023 14:49:06 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 14:49:06 - INFO - __main__ -     Num examples = 401
02/12/2023 14:49:06 - INFO - __main__ -     Batch size = 0202/12/2023 14:49:09 - INFO - __main__ -     eval_ppl = 1.01069
02/12/2023 14:49:09 - INFO - __main__ -     global_step = 3091
02/12/2023 14:49:09 - INFO - __main__ -     train_loss = 0.0119
02/12/2023 14:49:09 - INFO - __main__ -     *******************0202/12/2023 14:49:16 - INFO - __main__ -   Epoch 29, the accuracy is 0.8553615960099750202/12/2023 14:49:45 - INFO - __main__ -   Epoch 30, step 99, train loss 0.00302/12/2023 14:49:46 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 14:49:46 - INFO - __main__ -     Num examples = 401
02/12/2023 14:49:46 - INFO - __main__ -     Batch size = 8
02/12/2023 14:49:50 - INFO - __main__ -     eval_ppl = 1.01202
02/12/2023 14:49:50 - INFO - __main__ -     global_step = 3194
02/12/2023 14:49:50 - INFO - __main__ -     train_loss = 0.0055
02/12/2023 14:49:50 - INFO - __main__ -     ********************
0202/12/2023 14:49:56 - INFO - __main__ -   Epoch 30, the accuracy is 0.8528678304239400202/12/2023 14:50:26 - INFO - __main__ -   Epoch 31, step 99, train loss 0.00302/12/2023 14:50:27 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 14:50:27 - INFO - __main__ -     Num examples = 401
02/12/2023 14:50:27 - INFO - __main__ -     Batch size = 8
0202/12/2023 14:50:30 - INFO - __main__ -     eval_ppl = 1.01299
02/12/2023 14:50:30 - INFO - __main__ -     global_step = 3297
02/12/2023 14:50:30 - INFO - __main__ -     train_loss = 0.0037
02/12/2023 14:50:30 - INFO - __main__ -     *******************02/12/2023 14:50:36 - INFO - __main__ -   Epoch 31, the accuracy is 0.8379052369077307
02/12/2023 14:51:05 - INFO - __main__ -   Epoch 32, step 99, train loss 0.0045
02/12/2023 14:51:07 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 14:51:07 - INFO - __main__ -     Num examples = 401
02/12/2023 14:51:07 - INFO - __main__ -     Batch size = 8
0202/12/2023 14:51:10 - INFO - __main__ -     eval_ppl = 1.01269
02/12/2023 14:51:10 - INFO - __main__ -     global_step = 3400
02/12/2023 14:51:10 - INFO - __main__ -     train_loss = 0.003
02/12/2023 14:51:10 - INFO - __main__ -     ********************02/12/2023 14:51:16 - INFO - __main__ -   Epoch 32, the accuracy is 0.8453865336658354
02/12/2023 14:51:46 - INFO - __main__ -   Epoch 33, step 99, train loss 0.0073
02/12/2023 14:51:47 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 14:51:47 - INFO - __main__ -     Num examples = 401
02/12/2023 14:51:47 - INFO - __main__ -     Batch size = 8
02/12/2023 14:51:50 - INFO - __main__ -     eval_ppl = 1.01335
02/12/2023 14:51:50 - INFO - __main__ -     global_step = 3503
02/12/2023 14:51:50 - INFO - __main__ -     train_loss = 0.007
02/12/2023 14:51:50 - INFO - __main__ -     ********************
02/12/2023 14:51:56 - INFO - __main__ -   Epoch 33, the accuracy is 0.8728179551122195
0202/12/2023 14:52:26 - INFO - __main__ -   Epoch 34, step 99, train loss 0.00502/12/2023 14:52:27 - INFO - __main__ -   
***** Running evaluation *****
0202/12/2023 14:52:27 - INFO - __main__ -     Num examples = 400202/12/2023 14:52:27 - INFO - __main__ -     Batch size = 02/12/2023 14:52:30 - INFO - __main__ -     eval_ppl = 1.01094
02/12/2023 14:52:30 - INFO - __main__ -     global_step = 3606
02/12/2023 14:52:30 - INFO - __main__ -     train_loss = 0.0059
02/12/2023 14:52:30 - INFO - __main__ -     ********************
0202/12/2023 14:52:36 - INFO - __main__ -   Epoch 34, the accuracy is 0.8279301745635902/12/2023 14:53:06 - INFO - __main__ -   Epoch 35, step 99, train loss 0.0054
02/12/2023 14:53:07 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 14:53:07 - INFO - __main__ -     Num examples = 401
02/12/2023 14:53:07 - INFO - __main__ -     Batch size = 8
02/12/2023 14:53:11 - INFO - __main__ -     eval_ppl = 1.01224
02/12/2023 14:53:11 - INFO - __main__ -     global_step = 3709
02/12/2023 14:53:11 - INFO - __main__ -     train_loss = 0.0069
02/12/2023 14:53:11 - INFO - __main__ -     ********************
0202/12/2023 14:53:17 - INFO - __main__ -   Epoch 35, the accuracy is 0.83291770573566002/12/2023 14:53:46 - INFO - __main__ -   Epoch 36, step 99, train loss 0.0069
0202/12/2023 14:53:47 - INFO - __main__ -   
***** Running evaluation ****0202/12/2023 14:53:47 - INFO - __main__ -     Num examples = 400202/12/2023 14:53:47 - INFO - __main__ -     Batch size = 02/12/2023 14:53:51 - INFO - __main__ -     eval_ppl = 1.01124
02/12/2023 14:53:51 - INFO - __main__ -     global_step = 3812
02/12/2023 14:53:51 - INFO - __main__ -     train_loss = 0.0067
02/12/2023 14:53:51 - INFO - __main__ -     ********************
02/12/2023 14:53:57 - INFO - __main__ -   Epoch 36, the accuracy is 0.8778054862842892
02/12/2023 14:54:26 - INFO - __main__ -   Epoch 37, step 99, train loss 0.0074
02/12/2023 14:54:27 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 14:54:27 - INFO - __main__ -     Num examples = 401
02/12/2023 14:54:27 - INFO - __main__ -     Batch size = 8
02/12/2023 14:54:31 - INFO - __main__ -     eval_ppl = 1.0116
02/12/2023 14:54:31 - INFO - __main__ -     global_step = 3915
02/12/2023 14:54:31 - INFO - __main__ -     train_loss = 0.0071
02/12/2023 14:54:31 - INFO - __main__ -     ********************
02/12/2023 14:54:37 - INFO - __main__ -   Epoch 37, the accuracy is 0.8428927680798005
02/12/2023 14:55:07 - INFO - __main__ -   Epoch 38, step 99, train loss 0.0088
02/12/2023 14:55:08 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 14:55:08 - INFO - __main__ -     Num examples = 401
02/12/2023 14:55:08 - INFO - __main__ -     Batch size = 8
02/12/2023 14:55:11 - INFO - __main__ -     eval_ppl = 1.01109
02/12/2023 14:55:11 - INFO - __main__ -     global_step = 4018
02/12/2023 14:55:11 - INFO - __main__ -     train_loss = 0.0085
02/12/2023 14:55:11 - INFO - __main__ -     ********************
02/12/2023 14:55:17 - INFO - __main__ -   Epoch 38, the accuracy is 0.8628428927680798
002/12/2023 14:55:47 - INFO - __main__ -   Epoch 39, step 99, train loss 0.004802/12/2023 14:55:48 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 14:55:48 - INFO - __main__ -     Num examples = 401
02/12/2023 14:55:48 - INFO - __main__ -     Batch size = 8
002/12/2023 14:55:51 - INFO - __main__ -     eval_ppl = 1.0102
02/12/2023 14:55:51 - INFO - __main__ -     global_step = 4121
02/12/2023 14:55:51 - INFO - __main__ -     train_loss = 0.0089
02/12/2023 14:55:51 - INFO - __main__ -     ********************002/12/2023 14:55:58 - INFO - __main__ -   Epoch 39, the accuracy is 0.855361596009975102/12/2023 14:56:27 - INFO - __main__ -   Epoch 40, step 99, train loss 0.0057
02/12/2023 14:56:28 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 14:56:28 - INFO - __main__ -     Num examples = 401
02/12/2023 14:56:28 - INFO - __main__ -     Batch size = 8
02/12/2023 14:56:32 - INFO - __main__ -     eval_ppl = 1.00984
02/12/2023 14:56:32 - INFO - __main__ -     global_step = 4224
02/12/2023 14:56:32 - INFO - __main__ -     train_loss = 0.0058
02/12/2023 14:56:32 - INFO - __main__ -     ********************
02/12/2023 14:56:38 - INFO - __main__ -   Epoch 40, the accuracy is 0.8428927680798005
02/12/2023 14:57:07 - INFO - __main__ -   Epoch 41, step 99, train loss 0.0029
02/12/2023 14:57:08 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 14:57:08 - INFO - __main__ -     Num examples = 401
02/12/2023 14:57:08 - INFO - __main__ -     Batch size = 8
02/12/2023 14:57:12 - INFO - __main__ -     eval_ppl = 1.01118
02/12/2023 14:57:12 - INFO - __main__ -     global_step = 4327
02/12/2023 14:57:12 - INFO - __main__ -     train_loss = 0.0028
02/12/2023 14:57:12 - INFO - __main__ -     ********************
02/12/2023 14:57:18 - INFO - __main__ -   Epoch 41, the accuracy is 0.8728179551122195
002/12/2023 14:57:48 - INFO - __main__ -   Epoch 42, step 99, train loss 0.002802/12/2023 14:57:49 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 14:57:49 - INFO - __main__ -     Num examples = 401
02/12/2023 14:57:49 - INFO - __main__ -     Batch size = 8
02/12/2023 14:57:53 - INFO - __main__ -     eval_ppl = 1.01116
02/12/2023 14:57:53 - INFO - __main__ -     global_step = 4430
02/12/2023 14:57:53 - INFO - __main__ -     train_loss = 0.0032
02/12/2023 14:57:53 - INFO - __main__ -     ********************
02/12/2023 14:57:58 - INFO - __main__ -   Epoch 42, the accuracy is 0.8703241895261845
02/12/2023 14:58:28 - INFO - __main__ -   Epoch 43, step 99, train loss 0.0032
02/12/2023 14:58:29 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 14:58:29 - INFO - __main__ -     Num examples = 401
02/12/2023 14:58:29 - INFO - __main__ -     Batch size = 8
02/12/2023 14:58:33 - INFO - __main__ -     eval_ppl = 1.01204
02/12/2023 14:58:33 - INFO - __main__ -     global_step = 4533
02/12/2023 14:58:33 - INFO - __main__ -     train_loss = 0.0031
02/12/2023 14:58:33 - INFO - __main__ -     ********************
02/12/2023 14:58:39 - INFO - __main__ -   Epoch 43, the accuracy is 0.8778054862842892
02/12/2023 14:59:09 - INFO - __main__ -   Epoch 44, step 99, train loss 0.0033
02/12/2023 14:59:10 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 14:59:10 - INFO - __main__ -     Num examples = 401
02/12/2023 14:59:10 - INFO - __main__ -     Batch size = 8
02/12/2023 14:59:13 - INFO - __main__ -     eval_ppl = 1.0116
02/12/2023 14:59:13 - INFO - __main__ -     global_step = 4636
02/12/2023 14:59:13 - INFO - __main__ -     train_loss = 0.0029
02/12/2023 14:59:13 - INFO - __main__ -     ********************
02/12/2023 14:59:19 - INFO - __main__ -   Epoch 44, the accuracy is 0.8728179551122195
02/12/2023 14:59:49 - INFO - __main__ -   Epoch 45, step 99, train loss 0.0026
02/12/2023 14:59:50 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 14:59:50 - INFO - __main__ -     Num examples = 401
02/12/2023 14:59:50 - INFO - __main__ -     Batch size = 8
02/12/2023 14:59:54 - INFO - __main__ -     eval_ppl = 1.01195
02/12/2023 14:59:54 - INFO - __main__ -     global_step = 4739
02/12/2023 14:59:54 - INFO - __main__ -     train_loss = 0.0025
02/12/2023 14:59:54 - INFO - __main__ -     ********************
02/12/2023 15:00:00 - INFO - __main__ -   Epoch 45, the accuracy is 0.8703241895261845
02/12/2023 15:00:29 - INFO - __main__ -   Epoch 46, step 99, train loss 0.0019
02/12/2023 15:00:31 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 15:00:31 - INFO - __main__ -     Num examples = 401
02/12/2023 15:00:31 - INFO - __main__ -     Batch size = 8
02/12/2023 15:00:34 - INFO - __main__ -     eval_ppl = 1.0122
02/12/2023 15:00:34 - INFO - __main__ -     global_step = 4842
02/12/2023 15:00:34 - INFO - __main__ -     train_loss = 0.002
02/12/2023 15:00:34 - INFO - __main__ -     ********************
02/12/2023 15:00:40 - INFO - __main__ -   Epoch 46, the accuracy is 0.8703241895261845
002/12/2023 15:01:10 - INFO - __main__ -   Epoch 47, step 99, train loss 0.0026002/12/2023 15:01:11 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 15:01:11 - INFO - __main__ -     Num examples = 401
02/12/2023 15:01:11 - INFO - __main__ -     Batch size = 8002/12/2023 15:01:14 - INFO - __main__ -     eval_ppl = 1.01262
02/12/2023 15:01:14 - INFO - __main__ -     global_step = 4945
02/12/2023 15:01:14 - INFO - __main__ -     train_loss = 0.0025
02/12/2023 15:01:14 - INFO - __main__ -     ********************02/12/2023 15:01:20 - INFO - __main__ -   Epoch 47, the accuracy is 0.8728179551122195
002/12/2023 15:01:50 - INFO - __main__ -   Epoch 48, step 99, train loss 0.0031002/12/2023 15:01:51 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 15:01:51 - INFO - __main__ -     Num examples = 401
02/12/2023 15:01:51 - INFO - __main__ -     Batch size = 802/12/2023 15:01:55 - INFO - __main__ -     eval_ppl = 1.01269
02/12/2023 15:01:55 - INFO - __main__ -     global_step = 5048
02/12/2023 15:01:55 - INFO - __main__ -     train_loss = 0.0022
02/12/2023 15:01:55 - INFO - __main__ -     ********************
02/12/2023 15:02:01 - INFO - __main__ -   Epoch 48, the accuracy is 0.8678304239401496
002/12/2023 15:02:30 - INFO - __main__ -   Epoch 49, step 99, train loss 0.0024002/12/2023 15:02:32 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 15:02:32 - INFO - __main__ -     Num examples = 401
02/12/2023 15:02:32 - INFO - __main__ -     Batch size = 8002/12/2023 15:02:35 - INFO - __main__ -     eval_ppl = 1.01282
02/12/2023 15:02:35 - INFO - __main__ -     global_step = 5151
02/12/2023 15:02:35 - INFO - __main__ -     train_loss = 0.0024
02/12/2023 15:02:35 - INFO - __main__ -     ********************002/12/2023 15:02:41 - INFO - __main__ -   Epoch 49, the accuracy is 0.867830423940149602/12/2023 15:03:11 - INFO - __main__ -   Epoch 50, step 99, train loss 0.0026
002/12/2023 15:03:12 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 15:03:12 - INFO - __main__ -     Num examples = 401
02/12/2023 15:03:12 - INFO - __main__ -     Batch size = 802/12/2023 15:03:16 - INFO - __main__ -     eval_ppl = 1.01472
02/12/2023 15:03:16 - INFO - __main__ -     global_step = 5254
02/12/2023 15:03:16 - INFO - __main__ -     train_loss = 0.0028
02/12/2023 15:03:16 - INFO - __main__ -     ********************
002/12/2023 15:03:22 - INFO - __main__ -   Epoch 50, the accuracy is 0.8827930174563591002/12/2023 15:03:52 - INFO - __main__ -   Epoch 51, step 99, train loss 0.0064002/12/2023 15:03:53 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 15:03:53 - INFO - __main__ -     Num examples = 401
02/12/2023 15:03:53 - INFO - __main__ -     Batch size = 802/12/2023 15:03:56 - INFO - __main__ -     eval_ppl = 1.01316
02/12/2023 15:03:56 - INFO - __main__ -     global_step = 5357
02/12/2023 15:03:56 - INFO - __main__ -     train_loss = 0.0055
02/12/2023 15:03:56 - INFO - __main__ -     ********************
02/12/2023 15:04:02 - INFO - __main__ -   Epoch 51, the accuracy is 0.8753117206982544
002/12/2023 15:04:32 - INFO - __main__ -   Epoch 52, step 99, train loss 0.005
02/12/2023 15:04:33 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 15:04:33 - INFO - __main__ -     Num examples = 401
02/12/2023 15:04:33 - INFO - __main__ -     Batch size = 8
02/12/2023 15:04:37 - INFO - __main__ -     eval_ppl = 1.01196
02/12/2023 15:04:37 - INFO - __main__ -     global_step = 5460
02/12/2023 15:04:37 - INFO - __main__ -     train_loss = 0.0048
02/12/2023 15:04:37 - INFO - __main__ -     ********************
02/12/2023 15:04:43 - INFO - __main__ -   Epoch 52, the accuracy is 0.8877805486284289
02/12/2023 15:05:12 - INFO - __main__ -   Epoch 53, step 99, train loss 0.0031
02/12/2023 15:05:13 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 15:05:13 - INFO - __main__ -     Num examples = 401
02/12/2023 15:05:13 - INFO - __main__ -     Batch size = 8
02/12/2023 15:05:17 - INFO - __main__ -     eval_ppl = 1.01209
02/12/2023 15:05:17 - INFO - __main__ -     global_step = 5563
02/12/2023 15:05:17 - INFO - __main__ -     train_loss = 0.0024
02/12/2023 15:05:17 - INFO - __main__ -     ********************02/12/2023 15:05:23 - INFO - __main__ -   Epoch 53, the accuracy is 0.8703241895261845
02/12/2023 15:05:52 - INFO - __main__ -   Epoch 54, step 99, train loss 0.0024
02/12/2023 15:05:53 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 15:05:53 - INFO - __main__ -     Num examples = 401
02/12/2023 15:05:53 - INFO - __main__ -     Batch size = 8
02/12/2023 15:05:57 - INFO - __main__ -     eval_ppl = 1.01283
02/12/2023 15:05:57 - INFO - __main__ -     global_step = 5666
02/12/2023 15:05:57 - INFO - __main__ -     train_loss = 0.0023
02/12/2023 15:05:57 - INFO - __main__ -     ********************
02/12/2023 15:06:03 - INFO - __main__ -   Epoch 54, the accuracy is 0.885286783042394
02/12/2023 15:06:32 - INFO - __main__ -   Epoch 55, step 99, train loss 0.0028
02/12/2023 15:06:34 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 15:06:34 - INFO - __main__ -     Num examples = 401
02/12/2023 15:06:34 - INFO - __main__ -     Batch size = 8
02/12/2023 15:06:37 - INFO - __main__ -     eval_ppl = 1.01284
02/12/2023 15:06:37 - INFO - __main__ -     global_step = 5769
02/12/2023 15:06:37 - INFO - __main__ -     train_loss = 0.0027
02/12/2023 15:06:37 - INFO - __main__ -     ********************
02/12/2023 15:06:43 - INFO - __main__ -   Epoch 55, the accuracy is 0.8802992518703242
02/12/2023 15:07:13 - INFO - __main__ -   Epoch 56, step 99, train loss 0.0027
02/12/2023 15:07:14 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 15:07:14 - INFO - __main__ -     Num examples = 401
02/12/2023 15:07:14 - INFO - __main__ -     Batch size = 8
02/12/2023 15:07:18 - INFO - __main__ -     eval_ppl = 1.01467
02/12/2023 15:07:18 - INFO - __main__ -     global_step = 5872
02/12/2023 15:07:18 - INFO - __main__ -     train_loss = 0.0031
02/12/2023 15:07:18 - INFO - __main__ -     ********************
02/12/2023 15:07:24 - INFO - __main__ -   Epoch 56, the accuracy is 0.8802992518703242
02/12/2023 15:07:53 - INFO - __main__ -   Epoch 57, step 99, train loss 0.0048
02/12/2023 15:07:55 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 15:07:55 - INFO - __main__ -     Num examples = 401
02/12/2023 15:07:55 - INFO - __main__ -     Batch size = 8
02/12/2023 15:07:58 - INFO - __main__ -     eval_ppl = 1.01304
02/12/2023 15:07:58 - INFO - __main__ -     global_step = 5975
02/12/2023 15:07:58 - INFO - __main__ -     train_loss = 0.0049
02/12/2023 15:07:58 - INFO - __main__ -     ********************
02/12/2023 15:08:04 - INFO - __main__ -   Epoch 57, the accuracy is 0.8802992518703242
02/12/2023 15:08:34 - INFO - __main__ -   Epoch 58, step 99, train loss 0.0041
02/12/2023 15:08:35 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 15:08:35 - INFO - __main__ -     Num examples = 401
02/12/2023 15:08:35 - INFO - __main__ -     Batch size = 8
02/12/2023 15:08:39 - INFO - __main__ -     eval_ppl = 1.01345
02/12/2023 15:08:39 - INFO - __main__ -     global_step = 6078
02/12/2023 15:08:39 - INFO - __main__ -     train_loss = 0.004
02/12/2023 15:08:39 - INFO - __main__ -     ********************
02/12/2023 15:08:45 - INFO - __main__ -   Epoch 58, the accuracy is 0.885286783042394
02/12/2023 15:09:14 - INFO - __main__ -   Epoch 59, step 99, train loss 0.0051
002/12/2023 15:09:16 - INFO - __main__ -   
***** Running evaluation *****002/12/2023 15:09:16 - INFO - __main__ -     Num examples = 401002/12/2023 15:09:16 - INFO - __main__ -     Batch size = 802/12/2023 15:09:19 - INFO - __main__ -     eval_ppl = 1.01284
02/12/2023 15:09:19 - INFO - __main__ -     global_step = 6181
02/12/2023 15:09:19 - INFO - __main__ -     train_loss = 0.0049
02/12/2023 15:09:19 - INFO - __main__ -     ********************
02/12/2023 15:09:25 - INFO - __main__ -   Epoch 59, the accuracy is 0.8453865336658354
002/12/2023 15:09:55 - INFO - __main__ -   Epoch 60, step 99, train loss 0.00202/12/2023 15:09:56 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 15:09:56 - INFO - __main__ -     Num examples = 401
02/12/2023 15:09:56 - INFO - __main__ -     Batch size = 8
002/12/2023 15:10:00 - INFO - __main__ -     eval_ppl = 1.01286
02/12/2023 15:10:00 - INFO - __main__ -     global_step = 6284
02/12/2023 15:10:00 - INFO - __main__ -     train_loss = 0.0022
02/12/2023 15:10:00 - INFO - __main__ -     ********************02/12/2023 15:10:06 - INFO - __main__ -   Epoch 60, the accuracy is 0.8728179551122195
02/12/2023 15:10:36 - INFO - __main__ -   Epoch 61, step 99, train loss 0.0032
02/12/2023 15:10:37 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 15:10:37 - INFO - __main__ -     Num examples = 401
02/12/2023 15:10:37 - INFO - __main__ -     Batch size = 8
02/12/2023 15:10:40 - INFO - __main__ -     eval_ppl = 1.01461
02/12/2023 15:10:40 - INFO - __main__ -     global_step = 6387
02/12/2023 15:10:40 - INFO - __main__ -     train_loss = 0.0031
02/12/2023 15:10:40 - INFO - __main__ -     ********************
02/12/2023 15:10:46 - INFO - __main__ -   Epoch 61, the accuracy is 0.8877805486284289
002/12/2023 15:11:16 - INFO - __main__ -   Epoch 62, step 99, train loss 0.0055002/12/2023 15:11:17 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 15:11:17 - INFO - __main__ -     Num examples = 401
02/12/2023 15:11:17 - INFO - __main__ -     Batch size = 8002/12/2023 15:11:21 - INFO - __main__ -     eval_ppl = 1.01307
02/12/2023 15:11:21 - INFO - __main__ -     global_step = 6490
02/12/2023 15:11:21 - INFO - __main__ -     train_loss = 0.0055
02/12/2023 15:11:21 - INFO - __main__ -     ********************02/12/2023 15:11:27 - INFO - __main__ -   Epoch 62, the accuracy is 0.8728179551122195
002/12/2023 15:11:56 - INFO - __main__ -   Epoch 63, step 99, train loss 0.00202/12/2023 15:11:58 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 15:11:58 - INFO - __main__ -     Num examples = 401
02/12/2023 15:11:58 - INFO - __main__ -     Batch size = 8
0202/12/2023 15:12:01 - INFO - __main__ -     eval_ppl = 1.01483
02/12/2023 15:12:01 - INFO - __main__ -     global_step = 6593
02/12/2023 15:12:01 - INFO - __main__ -     train_loss = 0.0026
02/12/2023 15:12:01 - INFO - __main__ -     *******************0202/12/2023 15:12:07 - INFO - __main__ -   Epoch 63, the accuracy is 0.8802992518703240202/12/2023 15:12:37 - INFO - __main__ -   Epoch 64, step 99, train loss 0.00202/12/2023 15:12:38 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 15:12:38 - INFO - __main__ -     Num examples = 401
02/12/2023 15:12:38 - INFO - __main__ -     Batch size = 8
02/12/2023 15:12:42 - INFO - __main__ -     eval_ppl = 1.01406
02/12/2023 15:12:42 - INFO - __main__ -     global_step = 6696
02/12/2023 15:12:42 - INFO - __main__ -     train_loss = 0.0037
02/12/2023 15:12:42 - INFO - __main__ -     ********************
02/12/2023 15:12:48 - INFO - __main__ -   Epoch 64, the accuracy is 0.8528678304239401
02/12/2023 15:13:17 - INFO - __main__ -   Epoch 65, step 99, train loss 0.003
02/12/2023 15:13:18 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 15:13:18 - INFO - __main__ -     Num examples = 401
02/12/2023 15:13:18 - INFO - __main__ -     Batch size = 8
02/12/2023 15:13:22 - INFO - __main__ -     eval_ppl = 1.01457
02/12/2023 15:13:22 - INFO - __main__ -     global_step = 6799
02/12/2023 15:13:22 - INFO - __main__ -     train_loss = 0.0029
02/12/2023 15:13:22 - INFO - __main__ -     ********************
02/12/2023 15:13:28 - INFO - __main__ -   Epoch 65, the accuracy is 0.8653366583541147
002/12/2023 15:13:58 - INFO - __main__ -   Epoch 66, step 99, train loss 0.007302/12/2023 15:13:59 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 15:13:59 - INFO - __main__ -     Num examples = 401
02/12/2023 15:13:59 - INFO - __main__ -     Batch size = 8
002/12/2023 15:14:03 - INFO - __main__ -     eval_ppl = 1.01479
02/12/2023 15:14:03 - INFO - __main__ -     global_step = 6902
02/12/2023 15:14:03 - INFO - __main__ -     train_loss = 0.0073
02/12/2023 15:14:03 - INFO - __main__ -     ********************002/12/2023 15:14:09 - INFO - __main__ -   Epoch 66, the accuracy is 0.847880299251870402/12/2023 15:14:38 - INFO - __main__ -   Epoch 67, step 99, train loss 0.0028
002/12/2023 15:14:40 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 15:14:40 - INFO - __main__ -     Num examples = 401
02/12/2023 15:14:40 - INFO - __main__ -     Batch size = 8002/12/2023 15:14:43 - INFO - __main__ -     eval_ppl = 1.01476
02/12/2023 15:14:43 - INFO - __main__ -     global_step = 7005
02/12/2023 15:14:43 - INFO - __main__ -     train_loss = 0.0024
02/12/2023 15:14:43 - INFO - __main__ -     ********************002/12/2023 15:14:49 - INFO - __main__ -   Epoch 67, the accuracy is 0.8578553615960102/12/2023 15:15:19 - INFO - __main__ -   Epoch 68, step 99, train loss 0.0024
02/12/2023 15:15:20 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 15:15:20 - INFO - __main__ -     Num examples = 401
02/12/2023 15:15:20 - INFO - __main__ -     Batch size = 8
02/12/2023 15:15:24 - INFO - __main__ -     eval_ppl = 1.01503
02/12/2023 15:15:24 - INFO - __main__ -     global_step = 7108
02/12/2023 15:15:24 - INFO - __main__ -     train_loss = 0.0023
02/12/2023 15:15:24 - INFO - __main__ -     ********************
02/12/2023 15:15:30 - INFO - __main__ -   Epoch 68, the accuracy is 0.8528678304239401
02/12/2023 15:16:00 - INFO - __main__ -   Epoch 69, step 99, train loss 0.0024
02/12/2023 15:16:01 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 15:16:01 - INFO - __main__ -     Num examples = 401
02/12/2023 15:16:01 - INFO - __main__ -     Batch size = 8
02/12/2023 15:16:04 - INFO - __main__ -     eval_ppl = 1.01504
02/12/2023 15:16:04 - INFO - __main__ -     global_step = 7211
02/12/2023 15:16:04 - INFO - __main__ -     train_loss = 0.0023
02/12/2023 15:16:04 - INFO - __main__ -     ********************
02/12/2023 15:16:11 - INFO - __main__ -   Epoch 69, the accuracy is 0.8603491271820449
02/12/2023 15:16:40 - INFO - __main__ -   Epoch 70, step 99, train loss 0.003
002/12/2023 15:16:42 - INFO - __main__ -   
***** Running evaluation *****002/12/2023 15:16:42 - INFO - __main__ -     Num examples = 401002/12/2023 15:16:42 - INFO - __main__ -     Batch size = 8002/12/2023 15:16:45 - INFO - __main__ -     eval_ppl = 1.01535
02/12/2023 15:16:45 - INFO - __main__ -     global_step = 7314
02/12/2023 15:16:45 - INFO - __main__ -     train_loss = 0.0018
02/12/2023 15:16:45 - INFO - __main__ -     ********************002/12/2023 15:16:51 - INFO - __main__ -   Epoch 70, the accuracy is 0.850374064837905202/12/2023 15:17:21 - INFO - __main__ -   Epoch 71, step 99, train loss 0.0024
02/12/2023 15:17:22 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 15:17:22 - INFO - __main__ -     Num examples = 401
02/12/2023 15:17:22 - INFO - __main__ -     Batch size = 8
002/12/2023 15:17:25 - INFO - __main__ -     eval_ppl = 1.01556
02/12/2023 15:17:25 - INFO - __main__ -     global_step = 7417
02/12/2023 15:17:25 - INFO - __main__ -     train_loss = 0.0022
02/12/2023 15:17:25 - INFO - __main__ -     ********************002/12/2023 15:17:31 - INFO - __main__ -   Epoch 71, the accuracy is 0.855361596009975102/12/2023 15:18:01 - INFO - __main__ -   Epoch 72, step 99, train loss 0.003
02/12/2023 15:18:02 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 15:18:02 - INFO - __main__ -     Num examples = 401
02/12/2023 15:18:02 - INFO - __main__ -     Batch size = 8
02/12/2023 15:18:06 - INFO - __main__ -     eval_ppl = 1.01563
02/12/2023 15:18:06 - INFO - __main__ -     global_step = 7520
02/12/2023 15:18:06 - INFO - __main__ -     train_loss = 0.0029
02/12/2023 15:18:06 - INFO - __main__ -     ********************
02/12/2023 15:18:12 - INFO - __main__ -   Epoch 72, the accuracy is 0.8528678304239401
02/12/2023 15:18:42 - INFO - __main__ -   Epoch 73, step 99, train loss 0.0026
02/12/2023 15:18:43 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 15:18:43 - INFO - __main__ -     Num examples = 401
02/12/2023 15:18:43 - INFO - __main__ -     Batch size = 8
02/12/2023 15:18:46 - INFO - __main__ -     eval_ppl = 1.01589
02/12/2023 15:18:46 - INFO - __main__ -     global_step = 7623
02/12/2023 15:18:46 - INFO - __main__ -     train_loss = 0.0025
02/12/2023 15:18:46 - INFO - __main__ -     ********************
02/12/2023 15:18:52 - INFO - __main__ -   Epoch 73, the accuracy is 0.85785536159601
0202/12/2023 15:19:22 - INFO - __main__ -   Epoch 74, step 99, train loss 0.00102/12/2023 15:19:23 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 15:19:23 - INFO - __main__ -     Num examples = 401
02/12/2023 15:19:23 - INFO - __main__ -     Batch size = 8
0202/12/2023 15:19:27 - INFO - __main__ -     eval_ppl = 1.0158
02/12/2023 15:19:27 - INFO - __main__ -     global_step = 7726
02/12/2023 15:19:27 - INFO - __main__ -     train_loss = 0.0019
02/12/2023 15:19:27 - INFO - __main__ -     *******************02/12/2023 15:19:32 - INFO - __main__ -   Epoch 74, the accuracy is 0.8528678304239401
0202/12/2023 15:20:02 - INFO - __main__ -   Epoch 75, step 99, train loss 0.00102/12/2023 15:20:03 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 15:20:03 - INFO - __main__ -     Num examples = 401
02/12/2023 15:20:03 - INFO - __main__ -     Batch size = 8
0202/12/2023 15:20:07 - INFO - __main__ -     eval_ppl = 1.01591
02/12/2023 15:20:07 - INFO - __main__ -     global_step = 7829
02/12/2023 15:20:07 - INFO - __main__ -     train_loss = 0.0019
02/12/2023 15:20:07 - INFO - __main__ -     *******************02/12/2023 15:20:13 - INFO - __main__ -   Epoch 75, the accuracy is 0.8553615960099751
02/12/2023 15:20:43 - INFO - __main__ -   Epoch 76, step 99, train loss 0.0024
02/12/2023 15:20:44 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 15:20:44 - INFO - __main__ -     Num examples = 401
02/12/2023 15:20:44 - INFO - __main__ -     Batch size = 8
02/12/2023 15:20:47 - INFO - __main__ -     eval_ppl = 1.01619
02/12/2023 15:20:47 - INFO - __main__ -     global_step = 7932
02/12/2023 15:20:47 - INFO - __main__ -     train_loss = 0.0023
02/12/2023 15:20:47 - INFO - __main__ -     ********************
02/12/2023 15:20:54 - INFO - __main__ -   Epoch 76, the accuracy is 0.85785536159601
02/12/2023 15:21:23 - INFO - __main__ -   Epoch 77, step 99, train loss 0.0025
02/12/2023 15:21:24 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 15:21:24 - INFO - __main__ -     Num examples = 401
02/12/2023 15:21:24 - INFO - __main__ -     Batch size = 8
02/12/2023 15:21:28 - INFO - __main__ -     eval_ppl = 1.01647
02/12/2023 15:21:28 - INFO - __main__ -     global_step = 8035
02/12/2023 15:21:28 - INFO - __main__ -     train_loss = 0.0024
02/12/2023 15:21:28 - INFO - __main__ -     ********************
02/12/2023 15:21:34 - INFO - __main__ -   Epoch 77, the accuracy is 0.8603491271820449
0202/12/2023 15:22:04 - INFO - __main__ -   Epoch 78, step 99, train loss 0.00202/12/2023 15:22:05 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 15:22:05 - INFO - __main__ -     Num examples = 401
02/12/2023 15:22:05 - INFO - __main__ -     Batch size = 8
02/12/2023 15:22:09 - INFO - __main__ -     eval_ppl = 1.01653
02/12/2023 15:22:09 - INFO - __main__ -     global_step = 8138
02/12/2023 15:22:09 - INFO - __main__ -     train_loss = 0.0023
02/12/2023 15:22:09 - INFO - __main__ -     ********************
02/12/2023 15:22:14 - INFO - __main__ -   Epoch 78, the accuracy is 0.8603491271820449
02/12/2023 15:22:44 - INFO - __main__ -   Epoch 79, step 99, train loss 0.0023
02/12/2023 15:22:45 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 15:22:45 - INFO - __main__ -     Num examples = 401
02/12/2023 15:22:45 - INFO - __main__ -     Batch size = 8
02/12/2023 15:22:49 - INFO - __main__ -     eval_ppl = 1.01675
02/12/2023 15:22:49 - INFO - __main__ -     global_step = 8241
02/12/2023 15:22:49 - INFO - __main__ -     train_loss = 0.0022
02/12/2023 15:22:49 - INFO - __main__ -     ********************
0202/12/2023 15:22:55 - INFO - __main__ -   Epoch 79, the accuracy is 0.85536159600997502/12/2023 15:23:24 - INFO - __main__ -   Epoch 80, step 99, train loss 0.0023
02/12/2023 15:23:25 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 15:23:25 - INFO - __main__ -     Num examples = 401
02/12/2023 15:23:25 - INFO - __main__ -     Batch size = 8
0202/12/2023 15:23:29 - INFO - __main__ -     eval_ppl = 1.01677
02/12/2023 15:23:29 - INFO - __main__ -     global_step = 8344
02/12/2023 15:23:29 - INFO - __main__ -     train_loss = 0.0021
02/12/2023 15:23:29 - INFO - __main__ -     *******************02/12/2023 15:23:35 - INFO - __main__ -   Epoch 80, the accuracy is 0.8528678304239401
02/12/2023 15:24:05 - INFO - __main__ -   Epoch 81, step 99, train loss 0.0025
02/12/2023 15:24:06 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 15:24:06 - INFO - __main__ -     Num examples = 401
02/12/2023 15:24:06 - INFO - __main__ -     Batch size = 8
02/12/2023 15:24:09 - INFO - __main__ -     eval_ppl = 1.01695
02/12/2023 15:24:09 - INFO - __main__ -     global_step = 8447
02/12/2023 15:24:09 - INFO - __main__ -     train_loss = 0.0024
02/12/2023 15:24:09 - INFO - __main__ -     ********************
002/12/2023 15:24:15 - INFO - __main__ -   Epoch 81, the accuracy is 0.855361596009975102/12/2023 15:24:45 - INFO - __main__ -   Epoch 82, step 99, train loss 0.0026
02/12/2023 15:24:46 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 15:24:46 - INFO - __main__ -     Num examples = 401
02/12/2023 15:24:46 - INFO - __main__ -     Batch size = 8
002/12/2023 15:24:49 - INFO - __main__ -     eval_ppl = 1.01715
02/12/2023 15:24:49 - INFO - __main__ -     global_step = 8550
02/12/2023 15:24:49 - INFO - __main__ -     train_loss = 0.0021
02/12/2023 15:24:49 - INFO - __main__ -     ********************002/12/2023 15:24:55 - INFO - __main__ -   Epoch 82, the accuracy is 0.855361596009975102/12/2023 15:25:25 - INFO - __main__ -   Epoch 83, step 99, train loss 0.0024
02/12/2023 15:25:26 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 15:25:26 - INFO - __main__ -     Num examples = 401
02/12/2023 15:25:26 - INFO - __main__ -     Batch size = 8
02/12/2023 15:25:30 - INFO - __main__ -     eval_ppl = 1.01728
02/12/2023 15:25:30 - INFO - __main__ -     global_step = 8653
02/12/2023 15:25:30 - INFO - __main__ -     train_loss = 0.0023
02/12/2023 15:25:30 - INFO - __main__ -     ********************
02/12/2023 15:25:35 - INFO - __main__ -   Epoch 83, the accuracy is 0.8603491271820449
02/12/2023 15:26:05 - INFO - __main__ -   Epoch 84, step 99, train loss 0.0026
02/12/2023 15:26:06 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 15:26:06 - INFO - __main__ -     Num examples = 401
02/12/2023 15:26:06 - INFO - __main__ -     Batch size = 8
02/12/2023 15:26:10 - INFO - __main__ -     eval_ppl = 1.01717
02/12/2023 15:26:10 - INFO - __main__ -     global_step = 8756
02/12/2023 15:26:10 - INFO - __main__ -     train_loss = 0.0025
02/12/2023 15:26:10 - INFO - __main__ -     ********************
02/12/2023 15:26:16 - INFO - __main__ -   Epoch 84, the accuracy is 0.8603491271820449
02/12/2023 15:26:46 - INFO - __main__ -   Epoch 85, step 99, train loss 0.002
002/12/2023 15:26:47 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 15:26:47 - INFO - __main__ -     Num examples = 401
02/12/2023 15:26:47 - INFO - __main__ -     Batch size = 8002/12/2023 15:26:50 - INFO - __main__ -     eval_ppl = 1.01706
02/12/2023 15:26:50 - INFO - __main__ -     global_step = 8859
02/12/2023 15:26:50 - INFO - __main__ -     train_loss = 0.0024
02/12/2023 15:26:50 - INFO - __main__ -     ********************02/12/2023 15:26:56 - INFO - __main__ -   Epoch 85, the accuracy is 0.8603491271820449
02/12/2023 15:27:26 - INFO - __main__ -   Epoch 86, step 99, train loss 0.0021
02/12/2023 15:27:27 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 15:27:27 - INFO - __main__ -     Num examples = 401
02/12/2023 15:27:27 - INFO - __main__ -     Batch size = 8
002/12/2023 15:27:31 - INFO - __main__ -     eval_ppl = 1.01697
02/12/2023 15:27:31 - INFO - __main__ -     global_step = 8962
02/12/2023 15:27:31 - INFO - __main__ -     train_loss = 0.0023
02/12/2023 15:27:31 - INFO - __main__ -     ********************002/12/2023 15:27:36 - INFO - __main__ -   Epoch 86, the accuracy is 0.8578553615960102/12/2023 15:28:06 - INFO - __main__ -   Epoch 87, step 99, train loss 0.0017
002/12/2023 15:28:07 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 15:28:07 - INFO - __main__ -     Num examples = 401
02/12/2023 15:28:07 - INFO - __main__ -     Batch size = 8002/12/2023 15:28:11 - INFO - __main__ -     eval_ppl = 1.01712
02/12/2023 15:28:11 - INFO - __main__ -     global_step = 9065
02/12/2023 15:28:11 - INFO - __main__ -     train_loss = 0.0022
02/12/2023 15:28:11 - INFO - __main__ -     ********************02/12/2023 15:28:16 - INFO - __main__ -   Epoch 87, the accuracy is 0.85785536159601
02/12/2023 15:28:46 - INFO - __main__ -   Epoch 88, step 99, train loss 0.0016
002/12/2023 15:28:47 - INFO - __main__ -   
***** Running evaluation *****002/12/2023 15:28:47 - INFO - __main__ -     Num examples = 401002/12/2023 15:28:47 - INFO - __main__ -     Batch size = 8002/12/2023 15:28:51 - INFO - __main__ -     eval_ppl = 1.01735
02/12/2023 15:28:51 - INFO - __main__ -     global_step = 9168
02/12/2023 15:28:51 - INFO - __main__ -     train_loss = 0.0024
02/12/2023 15:28:51 - INFO - __main__ -     ********************02/12/2023 15:28:57 - INFO - __main__ -   Epoch 88, the accuracy is 0.85785536159601
02/12/2023 15:29:27 - INFO - __main__ -   Epoch 89, step 99, train loss 0.0017
002/12/2023 15:29:28 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 15:29:28 - INFO - __main__ -     Num examples = 401
02/12/2023 15:29:28 - INFO - __main__ -     Batch size = 8002/12/2023 15:29:31 - INFO - __main__ -     eval_ppl = 1.01739
02/12/2023 15:29:31 - INFO - __main__ -     global_step = 9271
02/12/2023 15:29:31 - INFO - __main__ -     train_loss = 0.0027
02/12/2023 15:29:31 - INFO - __main__ -     ********************002/12/2023 15:29:38 - INFO - __main__ -   Epoch 89, the accuracy is 0.8603491271820449002/12/2023 15:30:07 - INFO - __main__ -   Epoch 90, step 99, train loss 0.0027002/12/2023 15:30:08 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 15:30:08 - INFO - __main__ -     Num examples = 401
02/12/2023 15:30:08 - INFO - __main__ -     Batch size = 8002/12/2023 15:30:12 - INFO - __main__ -     eval_ppl = 1.01735
02/12/2023 15:30:12 - INFO - __main__ -     global_step = 9374
02/12/2023 15:30:12 - INFO - __main__ -     train_loss = 0.0026
02/12/2023 15:30:12 - INFO - __main__ -     ********************02/12/2023 15:30:18 - INFO - __main__ -   Epoch 90, the accuracy is 0.8603491271820449
02/12/2023 15:30:48 - INFO - __main__ -   Epoch 91, step 99, train loss 0.0016
002/12/2023 15:30:49 - INFO - __main__ -   
***** Running evaluation *****002/12/2023 15:30:49 - INFO - __main__ -     Num examples = 401
02/12/2023 15:30:49 - INFO - __main__ -     Batch size = 8002/12/2023 15:30:52 - INFO - __main__ -     eval_ppl = 1.01751
02/12/2023 15:30:52 - INFO - __main__ -     global_step = 9477
02/12/2023 15:30:52 - INFO - __main__ -     train_loss = 0.0022
02/12/2023 15:30:52 - INFO - __main__ -     ********************02/12/2023 15:30:59 - INFO - __main__ -   Epoch 91, the accuracy is 0.8553615960099751
002/12/2023 15:31:28 - INFO - __main__ -   Epoch 92, step 99, train loss 0.0027002/12/2023 15:31:29 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 15:31:29 - INFO - __main__ -     Num examples = 401
02/12/2023 15:31:29 - INFO - __main__ -     Batch size = 802/12/2023 15:31:33 - INFO - __main__ -     eval_ppl = 1.01734
02/12/2023 15:31:33 - INFO - __main__ -     global_step = 9580
02/12/2023 15:31:33 - INFO - __main__ -     train_loss = 0.0021
02/12/2023 15:31:33 - INFO - __main__ -     ********************
02/12/2023 15:31:39 - INFO - __main__ -   Epoch 92, the accuracy is 0.85785536159601
02/12/2023 15:32:09 - INFO - __main__ -   Epoch 93, step 99, train loss 0.0017
002/12/2023 15:32:10 - INFO - __main__ -   
***** Running evaluation *****002/12/2023 15:32:10 - INFO - __main__ -     Num examples = 401002/12/2023 15:32:10 - INFO - __main__ -     Batch size = 8002/12/2023 15:32:13 - INFO - __main__ -     eval_ppl = 1.01739
02/12/2023 15:32:13 - INFO - __main__ -     global_step = 9683
02/12/2023 15:32:13 - INFO - __main__ -     train_loss = 0.0027
02/12/2023 15:32:13 - INFO - __main__ -     ********************002/12/2023 15:32:19 - INFO - __main__ -   Epoch 93, the accuracy is 0.855361596009975102/12/2023 15:32:49 - INFO - __main__ -   Epoch 94, step 99, train loss 0.0019
02/12/2023 15:32:50 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 15:32:50 - INFO - __main__ -     Num examples = 401
02/12/2023 15:32:50 - INFO - __main__ -     Batch size = 8
002/12/2023 15:32:54 - INFO - __main__ -     eval_ppl = 1.01757
02/12/2023 15:32:54 - INFO - __main__ -     global_step = 9786
02/12/2023 15:32:54 - INFO - __main__ -     train_loss = 0.0022
02/12/2023 15:32:54 - INFO - __main__ -     ********************002/12/2023 15:32:59 - INFO - __main__ -   Epoch 94, the accuracy is 0.85785536159601002/12/2023 15:33:29 - INFO - __main__ -   Epoch 95, step 99, train loss 0.0025002/12/2023 15:33:30 - INFO - __main__ -   
***** Running evaluation *****002/12/2023 15:33:30 - INFO - __main__ -     Num examples = 401002/12/2023 15:33:30 - INFO - __main__ -     Batch size = 8002/12/2023 15:33:34 - INFO - __main__ -     eval_ppl = 1.01743
02/12/2023 15:33:34 - INFO - __main__ -     global_step = 9889
02/12/2023 15:33:34 - INFO - __main__ -     train_loss = 0.0024
02/12/2023 15:33:34 - INFO - __main__ -     *******************02/12/2023 15:33:40 - INFO - __main__ -   Epoch 95, the accuracy is 0.85785536159601
0202/12/2023 15:34:09 - INFO - __main__ -   Epoch 96, step 99, train loss 0.0020202/12/2023 15:34:11 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 15:34:11 - INFO - __main__ -     Num examples = 401
02/12/2023 15:34:11 - INFO - __main__ -     Batch size = 02/12/2023 15:34:14 - INFO - __main__ -     eval_ppl = 1.01751
02/12/2023 15:34:14 - INFO - __main__ -     global_step = 9992
02/12/2023 15:34:14 - INFO - __main__ -     train_loss = 0.002
02/12/2023 15:34:14 - INFO - __main__ -     ********************
02/02/12/2023 15:34:20 - INFO - __main__ -   Epoch 96, the accuracy is 0.8603491271820402/02/12/2023 15:34:50 - INFO - __main__ -   Epoch 97, step 99, train loss 0.0002/02/12/2023 15:34:51 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 15:34:51 - INFO - __main__ -     Num examples = 401
02/12/2023 15:34:51 - INFO - __main__ -     Batch size =02/02/12/2023 15:34:55 - INFO - __main__ -     eval_ppl = 1.01729
02/12/2023 15:34:55 - INFO - __main__ -     global_step = 10095
02/12/2023 15:34:55 - INFO - __main__ -     train_loss = 0.0027
02/12/2023 15:34:55 - INFO - __main__ -     ******************02/12/2023 15:35:01 - INFO - __main__ -   Epoch 97, the accuracy is 0.8628428927680798
02/12/2023 15:35:30 - INFO - __main__ -   Epoch 98, step 99, train loss 0.0016
02/02/12/2023 15:35:32 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 15:35:32 - INFO - __main__ -     Num examples = 401
02/12/2023 15:35:32 - INFO - __main__ -     Batch size =02/12/2023 15:35:35 - INFO - __main__ -     eval_ppl = 1.01739
02/12/2023 15:35:35 - INFO - __main__ -     global_step = 10198
02/12/2023 15:35:35 - INFO - __main__ -     train_loss = 0.0018
02/12/2023 15:35:35 - INFO - __main__ -     ********************
02/02/12/2023 15:35:41 - INFO - __main__ -   Epoch 98, the accuracy is 0.8603491271820402/02/12/2023 15:36:10 - INFO - __main__ -   Epoch 99, step 99, train loss 0.0002/02/12/2023 15:36:12 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 15:36:12 - INFO - __main__ -     Num examples = 401
02/12/2023 15:36:12 - INFO - __main__ -     Batch size =02/02/12/2023 15:36:15 - INFO - __main__ -     eval_ppl = 1.0173
02/12/2023 15:36:15 - INFO - __main__ -     global_step = 10301
02/12/2023 15:36:15 - INFO - __main__ -     train_loss = 0.0026
02/12/2023 15:36:15 - INFO - __main__ -     ******************02/12/2023 15:36:21 - INFO - __main__ -   Epoch 99, the accuracy is 0.8603491271820449
02/02/12/2023 15:36:51 - INFO - __main__ -   Epoch 100, step 99, train loss 0.0002/02/12/2023 15:36:52 - INFO - __main__ -   
***** Running evaluation ***02/02/12/2023 15:36:52 - INFO - __main__ -     Num examples = 401
02/12/2023 15:36:52 - INFO - __main__ -     Batch size =02/12/2023 15:36:55 - INFO - __main__ -     eval_ppl = 1.01742
02/12/2023 15:36:55 - INFO - __main__ -     global_step = 10404
02/12/2023 15:36:55 - INFO - __main__ -     train_loss = 0.0018
02/12/2023 15:36:55 - INFO - __main__ -     ********************
02/12/2023 15:37:01 - INFO - __main__ -   Epoch 100, the accuracy is 0.8603491271820449
02/12/2023 15:37:31 - INFO - __main__ -   Epoch 101, step 99, train loss 0.0018
02/02/12/2023 15:37:32 - INFO - __main__ -   
***** Running evaluation ***02/02/12/2023 15:37:32 - INFO - __main__ -     Num examples = 402/02/12/2023 15:37:32 - INFO - __main__ -     Batch size =02/12/2023 15:37:35 - INFO - __main__ -     eval_ppl = 1.01759
02/12/2023 15:37:35 - INFO - __main__ -     global_step = 10507
02/12/2023 15:37:35 - INFO - __main__ -     train_loss = 0.002
02/12/2023 15:37:35 - INFO - __main__ -     ********************
02/12/2023 15:37:42 - INFO - __main__ -   Epoch 101, the accuracy is 0.8603491271820449
02/102/12/2023 15:38:11 - INFO - __main__ -   Epoch 102, step 99, train loss 0.002/102/12/2023 15:38:13 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 15:38:13 - INFO - __main__ -     Num examples = 401
02/12/2023 15:38:13 - INFO - __main__ -     Batch size 02/102/12/2023 15:38:16 - INFO - __main__ -     eval_ppl = 1.01757
02/12/2023 15:38:16 - INFO - __main__ -     global_step = 10610
02/12/2023 15:38:16 - INFO - __main__ -     train_loss = 0.0025
02/12/2023 15:38:16 - INFO - __main__ -     ****************02/1202/12/2023 15:38:22 - INFO - __main__ -   Epoch 102, the accuracy is 0.86034912718202/1202/12/2023 15:38:51 - INFO - __main__ -   Epoch 103, step 99, train loss 0.02/1202/12/2023 15:38:53 - INFO - __main__ -   
***** Running evaluation *02/1202/12/2023 15:38:53 - INFO - __main__ -     Num examples =02/1202/12/2023 15:38:53 - INFO - __main__ -     Batch size02/1202/12/2023 15:38:56 - INFO - __main__ -     eval_ppl = 1.01758
02/12/2023 15:38:56 - INFO - __main__ -     global_step = 10713
02/12/2023 15:38:56 - INFO - __main__ -     train_loss = 0.0024
02/12/2023 15:38:56 - INFO - __main__ -     ****************02/12/2023 15:39:02 - INFO - __main__ -   Epoch 103, the accuracy is 0.8603491271820449
02/12/2023 15:39:32 - INFO - __main__ -   Epoch 104, step 99, train loss 0.0015
02/12/2023 15:39:33 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 15:39:33 - INFO - __main__ -     Num examples = 401
02/12/2023 15:39:33 - INFO - __main__ -     Batch size = 8
02/12/2023 15:39:37 - INFO - __main__ -     eval_ppl = 1.0174
02/12/2023 15:39:37 - INFO - __main__ -     global_step = 10816
02/12/2023 15:39:37 - INFO - __main__ -     train_loss = 0.0018
02/12/2023 15:39:37 - INFO - __main__ -     ********************
02/102/12/2023 15:39:43 - INFO - __main__ -   Epoch 104, the accuracy is 0.860349127182002/102/12/2023 15:40:12 - INFO - __main__ -   Epoch 105, step 99, train loss 0.002/102/12/2023 15:40:13 - INFO - __main__ -   
***** Running evaluation **02/102/12/2023 15:40:13 - INFO - __main__ -     Num examples = 02/102/12/2023 15:40:13 - INFO - __main__ -     Batch size 02/102/12/2023 15:40:17 - INFO - __main__ -     eval_ppl = 1.01755
02/12/2023 15:40:17 - INFO - __main__ -     global_step = 10919
02/12/2023 15:40:17 - INFO - __main__ -     train_loss = 0.0022
02/12/2023 15:40:17 - INFO - __main__ -     ****************02/12/2023 15:40:23 - INFO - __main__ -   Epoch 105, the accuracy is 0.8603491271820449
02/12/2023 15:40:53 - INFO - __main__ -   Epoch 106, step 99, train loss 0.0019
02/12/2023 15:40:54 - INFO - __main__ -   
***** Running evaluation *****
02/1202/12/2023 15:40:54 - INFO - __main__ -     Num examples =02/1202/12/2023 15:40:54 - INFO - __main__ -     Batch size02/1202/12/2023 15:40:57 - INFO - __main__ -     eval_ppl = 1.01776
02/12/2023 15:40:57 - INFO - __main__ -     global_step = 11022
02/12/2023 15:40:57 - INFO - __main__ -     train_loss = 0.0023
02/12/2023 15:40:57 - INFO - __main__ -     ****************02/12/2023 15:41:03 - INFO - __main__ -   Epoch 106, the accuracy is 0.8603491271820449
02/1202/12/2023 15:41:33 - INFO - __main__ -   Epoch 107, step 99, train loss 0.02/1202/12/2023 15:41:34 - INFO - __main__ -   
***** Running evaluation *02/1202/12/2023 15:41:34 - INFO - __main__ -     Num examples =02/1202/12/2023 15:41:34 - INFO - __main__ -     Batch size02/1202/12/2023 15:41:37 - INFO - __main__ -     eval_ppl = 1.01772
02/12/2023 15:41:37 - INFO - __main__ -     global_step = 11125
02/12/2023 15:41:37 - INFO - __main__ -     train_loss = 0.0023
02/12/2023 15:41:37 - INFO - __main__ -     ****************02/12/2023 15:41:43 - INFO - __main__ -   Epoch 107, the accuracy is 0.8603491271820449
02/1202/12/2023 15:42:13 - INFO - __main__ -   Epoch 108, step 99, train loss 0.02/1202/12/2023 15:42:14 - INFO - __main__ -   
***** Running evaluation *02/1202/12/2023 15:42:14 - INFO - __main__ -     Num examples =02/1202/12/2023 15:42:14 - INFO - __main__ -     Batch size02/1202/12/2023 15:42:18 - INFO - __main__ -     eval_ppl = 1.01776
02/12/2023 15:42:18 - INFO - __main__ -     global_step = 11228
02/12/2023 15:42:18 - INFO - __main__ -     train_loss = 0.0023
02/12/2023 15:42:18 - INFO - __main__ -     ****************02/12/2023 15:42:24 - INFO - __main__ -   Epoch 108, the accuracy is 0.8603491271820449
02/1202/12/2023 15:42:53 - INFO - __main__ -   Epoch 109, step 99, train loss 0.02/1202/12/2023 15:42:54 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 15:42:54 - INFO - __main__ -     Num examples = 401
02/12/2023 15:42:54 - INFO - __main__ -     Batch size02/12/2023 15:42:58 - INFO - __main__ -     eval_ppl = 1.01781
02/12/2023 15:42:58 - INFO - __main__ -     global_step = 11331
02/12/2023 15:42:58 - INFO - __main__ -     train_loss = 0.0019
02/12/2023 15:42:58 - INFO - __main__ -     ********************
02/1202/12/2023 15:43:04 - INFO - __main__ -   Epoch 109, the accuracy is 0.86034912718202/1202/12/2023 15:43:34 - INFO - __main__ -   Epoch 110, step 99, train loss 0.02/1202/12/2023 15:43:35 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 15:43:35 - INFO - __main__ -     Num examples = 401
02/12/2023 15:43:35 - INFO - __main__ -     Batch size02/1202/12/2023 15:43:39 - INFO - __main__ -     eval_ppl = 1.01779
02/12/2023 15:43:39 - INFO - __main__ -     global_step = 11434
02/12/2023 15:43:39 - INFO - __main__ -     train_loss = 0.0025
02/12/2023 15:43:39 - INFO - __main__ -     ****************02/12/2023 15:43:45 - INFO - __main__ -   Epoch 110, the accuracy is 0.8628428927680798
02/1202/12/2023 15:44:14 - INFO - __main__ -   Epoch 111, step 99, train loss 0.02/1202/12/2023 15:44:16 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 15:44:16 - INFO - __main__ -     Num examples = 401
02/12/2023 15:44:16 - INFO - __main__ -     Batch size02/1202/12/2023 15:44:19 - INFO - __main__ -     eval_ppl = 1.0178
02/12/2023 15:44:19 - INFO - __main__ -     global_step = 11537
02/12/2023 15:44:19 - INFO - __main__ -     train_loss = 0.0022
02/12/2023 15:44:19 - INFO - __main__ -     ****************02/1202/12/2023 15:44:25 - INFO - __main__ -   Epoch 111, the accuracy is 0.86284289276802/12/2023 15:44:55 - INFO - __main__ -   Epoch 112, step 99, train loss 0.0016
02/12/2023 15:44:56 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 15:44:56 - INFO - __main__ -     Num examples = 401
02/12/2023 15:44:56 - INFO - __main__ -     Batch size = 8
02/12/2023 15:45:00 - INFO - __main__ -     eval_ppl = 1.01784
02/12/2023 15:45:00 - INFO - __main__ -     global_step = 11640
02/12/2023 15:45:00 - INFO - __main__ -     train_loss = 0.0018
02/12/2023 15:45:00 - INFO - __main__ -     ********************
02/1202/12/2023 15:45:05 - INFO - __main__ -   Epoch 112, the accuracy is 0.86284289276802/12/2023 15:45:35 - INFO - __main__ -   Epoch 113, step 99, train loss 0.0016
02/1202/12/2023 15:45:36 - INFO - __main__ -   
***** Running evaluation *02/1202/12/2023 15:45:36 - INFO - __main__ -     Num examples =02/12/2023 15:45:36 - INFO - __main__ -     Batch size = 8
02/1202/12/2023 15:45:40 - INFO - __main__ -     eval_ppl = 1.01787
02/12/2023 15:45:40 - INFO - __main__ -     global_step = 11743
02/12/2023 15:45:40 - INFO - __main__ -     train_loss = 0.0023
02/12/2023 15:45:40 - INFO - __main__ -     ****************02/12/2023 15:45:45 - INFO - __main__ -   Epoch 113, the accuracy is 0.8653366583541147
02/12/2023 15:46:15 - INFO - __main__ -   Epoch 114, step 99, train loss 0.0016
02/1202/12/2023 15:46:16 - INFO - __main__ -   
***** Running evaluation *02/1202/12/2023 15:46:16 - INFO - __main__ -     Num examples = 401
02/12/2023 15:46:16 - INFO - __main__ -     Batch size02/12/2023 15:46:20 - INFO - __main__ -     eval_ppl = 1.01792
02/12/2023 15:46:20 - INFO - __main__ -     global_step = 11846
02/12/2023 15:46:20 - INFO - __main__ -     train_loss = 0.0018
02/12/2023 15:46:20 - INFO - __main__ -     ********************
02/1202/12/2023 15:46:26 - INFO - __main__ -   Epoch 114, the accuracy is 0.86533665835402/1202/12/2023 15:46:55 - INFO - __main__ -   Epoch 115, step 99, train loss 0.02/1202/12/2023 15:46:57 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 15:46:57 - INFO - __main__ -     Num examples = 401
02/12/2023 15:46:57 - INFO - __main__ -     Batch size02/1202/12/2023 15:47:00 - INFO - __main__ -     eval_ppl = 1.01786
02/12/2023 15:47:00 - INFO - __main__ -     global_step = 11949
02/12/2023 15:47:00 - INFO - __main__ -     train_loss = 0.0023
02/12/2023 15:47:00 - INFO - __main__ -     ****************02/1202/12/2023 15:47:06 - INFO - __main__ -   Epoch 115, the accuracy is 0.86533665835402/1202/12/2023 15:47:36 - INFO - __main__ -   Epoch 116, step 99, train loss 0.02/1202/12/2023 15:47:37 - INFO - __main__ -   
***** Running evaluation *02/1202/12/2023 15:47:37 - INFO - __main__ -     Num examples = 401
02/12/2023 15:47:37 - INFO - __main__ -     Batch size02/1202/12/2023 15:47:41 - INFO - __main__ -     eval_ppl = 1.01793
02/12/2023 15:47:41 - INFO - __main__ -     global_step = 12052
02/12/2023 15:47:41 - INFO - __main__ -     train_loss = 0.0022
02/12/2023 15:47:41 - INFO - __main__ -     ****************02/1202/12/2023 15:47:47 - INFO - __main__ -   Epoch 116, the accuracy is 0.86034912718202/12/2023 15:48:17 - INFO - __main__ -   Epoch 117, step 99, train loss 0.0018
02/1202/12/2023 15:48:18 - INFO - __main__ -   
***** Running evaluation *02/12/2023 15:48:18 - INFO - __main__ -     Num examples = 401
02/12/2023 15:48:18 - INFO - __main__ -     Batch size = 8
02/1202/12/2023 15:48:21 - INFO - __main__ -     eval_ppl = 1.01806
02/12/2023 15:48:21 - INFO - __main__ -     global_step = 12155
02/12/2023 15:48:21 - INFO - __main__ -     train_loss = 0.0022
02/12/2023 15:48:21 - INFO - __main__ -     ***************02/12/02/12/2023 15:48:28 - INFO - __main__ -   Epoch 117, the accuracy is 0.8603491271802/12/02/12/2023 15:48:57 - INFO - __main__ -   Epoch 118, step 99, train loss 002/12/02/12/2023 15:48:59 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 15:48:59 - INFO - __main__ -     Num examples = 401
02/12/2023 15:48:59 - INFO - __main__ -     Batch siz02/12/02/12/2023 15:49:02 - INFO - __main__ -     eval_ppl = 1.01808
02/12/2023 15:49:02 - INFO - __main__ -     global_step = 12258
02/12/2023 15:49:02 - INFO - __main__ -     train_loss = 0.0023
02/12/2023 15:49:02 - INFO - __main__ -     ***************02/12/02/12/2023 15:49:08 - INFO - __main__ -   Epoch 118, the accuracy is 0.8628428927602/12/2023 15:49:37 - INFO - __main__ -   Epoch 119, step 99, train loss 0.0016
02/12/02/12/2023 15:49:39 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 15:49:39 - INFO - __main__ -     Num examples = 401
02/12/2023 15:49:39 - INFO - __main__ -     Batch siz02/12/02/12/2023 15:49:42 - INFO - __main__ -     eval_ppl = 1.01808
02/12/2023 15:49:42 - INFO - __main__ -     global_step = 12361
02/12/2023 15:49:42 - INFO - __main__ -     train_loss = 0.0023
02/12/2023 15:49:42 - INFO - __main__ -     ***************02/12/2023 15:49:48 - INFO - __main__ -   Epoch 119, the accuracy is 0.8628428927680798
02/12/2023 15:49:48 - INFO - __main__ -   Test file: final_final_dataset/python/val_data_of_Expand.jsonl
02/12/02/12/2023 15:49:52 - INFO - __main__ -   gold_info:{'all_count': 401, 'Positive': 78, 'Negative': 323}
02/12/2023 15:49:52 - INFO - __main__ -   pre_info:{'TP': 50, 'FP': 27, 'TN': 296, 'FN': 28}
02/12/2023 15:49:52 - INFO - __main__ -   Epoch 119, the accuracy is 0.8628428927680798, the precision is 0.6493506493506493, the recall is 0.6410256410256411, the fscore is 0.6451612903225807
02/12/2023 15:49:52 - INFO - __main__ -   Test file: final_final_dataset/python/test_data_of_Expand.02/12/02/12/2023 15:49:59 - INFO - __main__ -   gold_info:{'all_count': 516, 'Positive': 102, 'Negative': 414}
02/12/2023 15:49:59 - INFO - __main__ -   pre_info:{'TP': 50, 'FP': 40, 'TN': 374, 'FN': 52}
02/12/2023 15:49:59 - INFO - __main__ -   Epoch 119, the accuracy is 0.8217054263565892, the precision is 0.5555555555555556, the recall is 0.49019607843137253, the fscore is 0.5208333333333333
