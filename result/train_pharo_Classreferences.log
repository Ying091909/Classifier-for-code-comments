02/12/2023 22:24:02 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, beam_size=10, config_name='', dev_filename='final_final_dataset/pharo/val_data_of_Classreferences.jsonl', do_eval=True, do_lower_case=False, do_test=True, do_train=True, eval_batch_size=8, eval_steps=-1, gradient_accumulation_steps=1, learning_rate=5e-05, load_model_path=None, local_rank=1, max_grad_norm=1.0, max_source_length=256, max_steps=-1, max_target_length=32, model_name_or_path=None, model_type=None, no_cuda=False, num_train_epochs=120, output_dir='pharo_Classreferences_output', seed=42, test_filename='final_final_dataset/pharo/test_data_of_Classreferences.jsonl', tokenizer_name='', train_batch_size=8, train_filename='final_final_dataset/pharo/train_data_of_Classreferences.jsonl', train_log_filename='pharo_Classreferences', train_steps=-1, visible_gpu='0, 1', warmup_steps=0, weight_decay=0.0)
02/12/2023 22:24:02 - INFO - torch.distributed.distributed_c10d -   Added key: store_based_barrier_key:1 to store for rank: 0
02/12/2023 22:24:02 - INFO - torch.distributed.distributed_c10d -   Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 2 nodes.
02/12/2023 22:24:02 - WARNING - __main__ -   Process rank: 1, device: cuda:1, n_gpu: 1, distributed training: True
02/12/2023 22:24:08 - INFO - __main__ -   model loaded!
02/12/2023 22:24:08 - INFO - __main__ -   *** Example ***
02/12/2023 22:24:08 - INFO - __main__ -   idx: 0
02/12/2023 22:24:08 - INFO - __main__ -   source_tokens: ['<s>', 'Classification', ':', '_if', '_possible', '_i', '_will', '_use', '_a', '_compiled', '_version', '_of', '_pr', 'p', 'ill', 'arp', '<s>', 'ars', '</s>', 'er', '</s>']
02/12/2023 22:24:08 - INFO - __main__ -   source_ids: 1 19168 30 309 3323 277 903 999 279 7743 1177 434 846 84 737 11441 1 5913 2 264 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/12/2023 22:24:08 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/12/2023 22:24:08 - INFO - __main__ -   target_tokens: ['<s>', 'true', '</s>']
02/12/2023 22:24:08 - INFO - __main__ -   target_ids: 1 3767 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/12/2023 22:24:08 - INFO - __main__ -   target_mask: 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/12/2023 22:24:08 - INFO - __main__ -   *** Example ***
02/12/2023 22:24:08 - INFO - __main__ -   idx: 1
02/12/2023 22:24:08 - INFO - __main__ -   source_tokens: ['<s>', 'Classification', ':', '_i', '_hold', '_information', '_about', '_a', '_smooth', '_scroll', '_request', '_by', '_a', '_smooth', 'sc', 'roller', '</s>']
02/12/2023 22:24:08 - INFO - __main__ -   source_ids: 1 19168 30 277 6887 1779 2973 279 11957 5532 590 635 279 11957 1017 1539 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/12/2023 22:24:08 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/12/2023 22:24:08 - INFO - __main__ -   target_tokens: ['<s>', 'true', '</s>']
02/12/2023 22:24:08 - INFO - __main__ -   target_ids: 1 3767 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/12/2023 22:24:08 - INFO - __main__ -   target_mask: 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/12/2023 22:24:08 - INFO - __main__ -   *** Example ***
02/12/2023 22:24:08 - INFO - __main__ -   idx: 2
02/12/2023 22:24:08 - INFO - __main__ -   source_tokens: ['<s>', 'Classification', ':', '_handle', 'error', '</s>']
02/12/2023 22:24:08 - INFO - __main__ -   source_ids: 1 19168 30 1640 1636 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/12/2023 22:24:08 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/12/2023 22:24:08 - INFO - __main__ -   target_tokens: ['<s>', 'true', '</s>']
02/12/2023 22:24:08 - INFO - __main__ -   target_ids: 1 3767 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/12/2023 22:24:08 - INFO - __main__ -   target_mask: 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/12/2023 22:24:08 - INFO - __main__ -   *** Example ***
02/12/2023 22:24:08 - INFO - __main__ -   idx: 3
02/12/2023 22:24:08 - INFO - __main__ -   source_tokens: ['<s>', 'Classification', ':', '_i', '_am', '_intended', '_to', '_be', '_used', '_in', '_gem', 'stone', '_s', '_instead', '_of', '_wa', '<s>', 'has', '</s>', 'h', 'cache', '</s>']
02/12/2023 22:24:08 - INFO - __main__ -   source_ids: 1 19168 30 277 2125 12613 358 506 1399 316 17474 13925 272 3560 434 27098 1 5332 2 76 2493 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/12/2023 22:24:08 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/12/2023 22:24:08 - INFO - __main__ -   target_tokens: ['<s>', 'true', '</s>']
02/12/2023 22:24:08 - INFO - __main__ -   target_ids: 1 3767 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/12/2023 22:24:08 - INFO - __main__ -   target_mask: 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/12/2023 22:24:08 - INFO - __main__ -   *** Example ***
02/12/2023 22:24:08 - INFO - __main__ -   idx: 4
02/12/2023 22:24:08 - INFO - __main__ -   source_tokens: ['<s>', 'Classification', ':', '_fam', 'ix', 'namespace', 'group', '_is', '_a', '_mo', 'ose', 'group', '_containing', '_only', '_fam', 'ix', '_en', 'ities', '_of', '_type', '_fam', 'ix', 'namespace', '</s>']
02/12/2023 22:24:08 - INFO - __main__ -   source_ids: 1 19168 30 26688 697 4937 1655 353 279 7344 2584 1655 4191 1338 26688 697 570 1961 434 618 26688 697 4937 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/12/2023 22:24:08 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/12/2023 22:24:08 - INFO - __main__ -   target_tokens: ['<s>', 'true', '</s>']
02/12/2023 22:24:08 - INFO - __main__ -   target_ids: 1 3767 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/12/2023 22:24:08 - INFO - __main__ -   target_mask: 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
02/12/2023 22:24:08 - INFO - __main__ -   ***** Running training *****
02/12/2023 22:24:08 - INFO - __main__ -     Num examples = 1349
02/12/2023 22:24:08 - INFO - __main__ -     Batch size = 8
02/12/2023 22:24:08 - INFO - __main__ -     Num epoch = 120
02/12/2023 22:24:09 - INFO - torch.nn.parallel.distributed -   Reducer buckets have been rebuilt in this iteration.
02/12/2023 22:24:35 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 22:24:35 - INFO - __main__ -     Num examples = 59
02/12/2023 22:24:35 - INFO - __main__ -     Batch size = 8
02/12/2023 22:24:35 - INFO - __main__ -     eval_ppl = 1.4497
02/12/2023 22:24:35 - INFO - __main__ -     global_step = 86
02/12/2023 22:24:35 - INFO - __main__ -     train_loss = 9.7695
02/12/2023 22:24:35 - INFO - __main__ -     ********************
02/12/2023 22:24:37 - INFO - __main__ -     Best ppl:1.4497
02/12/2023 22:24:37 - INFO - __main__ -     ********************
02/12/2023 22:24:39 - INFO - __main__ -   Epoch 0, the accuracy is 0.0
02/12/2023 22:25:05 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 22:25:05 - INFO - __main__ -     Num examples = 59
02/12/2023 22:25:05 - INFO - __main__ -     Batch size = 8
02/12/2023 22:25:05 - INFO - __main__ -     eval_ppl = 1.00218
02/12/2023 22:25:05 - INFO - __main__ -     global_step = 171
02/12/2023 22:25:05 - INFO - __main__ -     train_loss = 1.5631
02/12/2023 22:25:05 - INFO - __main__ -     ********************
02/12/2023 22:25:07 - INFO - __main__ -     Best ppl:1.00218
02/12/2023 22:25:07 - INFO - __main__ -     ********************
02/12/2023 22:25:09 - INFO - __main__ -   Epoch 1, the accuracy is 0.9661016949152542
02/12/2023 22:25:34 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 22:25:34 - INFO - __main__ -     Num examples = 59
02/12/2023 22:25:34 - INFO - __main__ -     Batch size = 8
02/12/2023 22:25:35 - INFO - __main__ -     eval_ppl = 1.00206
02/12/2023 22:25:35 - INFO - __main__ -     global_step = 256
02/12/2023 22:25:35 - INFO - __main__ -     train_loss = 0.0693
02/12/2023 22:25:35 - INFO - __main__ -     ********************
02/12/2023 22:25:36 - INFO - __main__ -     Best ppl:1.00206
02/12/2023 22:25:36 - INFO - __main__ -     ********************
02/12/2023 22:25:38 - INFO - __main__ -   Epoch 2, the accuracy is 0.9661016949152542
02/12/2023 22:26:04 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 22:26:04 - INFO - __main__ -     Num examples = 59
02/12/2023 22:26:04 - INFO - __main__ -     Batch size = 8
02/12/2023 22:26:04 - INFO - __main__ -     eval_ppl = 1.00203
02/12/2023 22:26:04 - INFO - __main__ -     global_step = 341
02/12/2023 22:26:04 - INFO - __main__ -     train_loss = 0.0657
02/12/2023 22:26:04 - INFO - __main__ -     ********************02/12/2023 22:26:06 - INFO - __main__ -     Best ppl:1.00203
02/12/2023 22:26:06 - INFO - __main__ -     ********************
002/12/2023 22:26:08 - INFO - __main__ -   Epoch 3, the accuracy is 0.966101694915254202/12/2023 22:26:34 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 22:26:34 - INFO - __main__ -     Num examples = 59
02/12/2023 22:26:34 - INFO - __main__ -     Batch size = 8
02/12/2023 22:26:34 - INFO - __main__ -     eval_ppl = 1.00201
02/12/2023 22:26:34 - INFO - __main__ -     global_step = 426
02/12/2023 22:26:34 - INFO - __main__ -     train_loss = 0.0568
02/12/2023 22:26:34 - INFO - __main__ -     ********************
02/12/2023 22:26:35 - INFO - __main__ -     Best ppl:1.00201
02/12/2023 22:26:35 - INFO - __main__ -     ********************
02/12/2023 22:26:38 - INFO - __main__ -   Epoch 4, the accuracy is 0.9661016949152542
02/12/2023 22:27:03 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 22:27:03 - INFO - __main__ -     Num examples = 59
02/12/2023 22:27:03 - INFO - __main__ -     Batch size = 8
02/12/2023 22:27:04 - INFO - __main__ -     eval_ppl = 1.00199
02/12/2023 22:27:04 - INFO - __main__ -     global_step = 511
02/12/2023 22:27:04 - INFO - __main__ -     train_loss = 0.0494
02/12/2023 22:27:04 - INFO - __main__ -     ********************
02/12/2023 22:27:05 - INFO - __main__ -     Best ppl:1.00199
02/12/2023 22:27:05 - INFO - __main__ -     ********************
02/12/2023 22:27:07 - INFO - __main__ -   Epoch 5, the accuracy is 0.9661016949152542
02/12/2023 22:27:33 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 22:27:33 - INFO - __main__ -     Num examples = 59
02/12/2023 22:27:33 - INFO - __main__ -     Batch size = 8
02/12/2023 22:27:33 - INFO - __main__ -     eval_ppl = 1.00227
02/12/2023 22:27:33 - INFO - __main__ -     global_step = 596
02/12/2023 22:27:33 - INFO - __main__ -     train_loss = 0.0352
02/12/2023 22:27:33 - INFO - __main__ -     ********************
02/12/2023 22:27:35 - INFO - __main__ -   Epoch 6, the accuracy is 0.9661016949152542
02/12/2023 22:28:01 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 22:28:01 - INFO - __main__ -     Num examples = 59
02/12/2023 22:28:01 - INFO - __main__ -     Batch size = 8
02/12/2023 22:28:01 - INFO - __main__ -     eval_ppl = 1.00223
02/12/2023 22:28:01 - INFO - __main__ -     global_step = 681
02/12/2023 22:28:01 - INFO - __main__ -     train_loss = 0.0295
02/12/2023 22:28:01 - INFO - __main__ -     ********************
02/12/2023 22:28:03 - INFO - __main__ -   Epoch 7, the accuracy is 0.9661016949152542
02/12/2023 22:28:29 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 22:28:29 - INFO - __main__ -     Num examples = 59
02/12/2023 22:28:29 - INFO - __main__ -     Batch size = 8
02/12/2023 22:28:29 - INFO - __main__ -     eval_ppl = 1.00275
02/12/2023 22:28:29 - INFO - __main__ -     global_step = 766
02/12/2023 22:28:29 - INFO - __main__ -     train_loss = 0.0203
02/12/2023 22:28:29 - INFO - __main__ -     ********************
02/12/2023 22:28:31 - INFO - __main__ -   Epoch 8, the accuracy is 0.9661016949152542
02/12/2023 22:28:57 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 22:28:57 - INFO - __main__ -     Num examples = 59
02/12/2023 22:28:57 - INFO - __main__ -     Batch size = 8
02/12/2023 22:28:57 - INFO - __main__ -     eval_ppl = 1.00257
02/12/2023 22:28:57 - INFO - __main__ -     global_step = 851
02/12/2023 22:28:57 - INFO - __main__ -     train_loss = 0.0268
02/12/2023 22:28:57 - INFO - __main__ -     ********************
02/12/2023 22:28:59 - INFO - __main__ -   Epoch 9, the accuracy is 0.9661016949152542
02/12/2023 22:29:25 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 22:29:25 - INFO - __main__ -     Num examples = 59
02/12/2023 22:29:25 - INFO - __main__ -     Batch size = 8
02/12/2023 22:29:25 - INFO - __main__ -     eval_ppl = 1.00342
02/12/2023 22:29:25 - INFO - __main__ -     global_step = 936
02/12/2023 22:29:25 - INFO - __main__ -     train_loss = 0.0089
02/12/2023 22:29:25 - INFO - __main__ -     ********************002/12/2023 22:29:27 - INFO - __main__ -   Epoch 10, the accuracy is 0.949152542372881402/12/2023 22:29:53 - INFO - __main__ -   
***** Running evaluation *****
002/12/2023 22:29:53 - INFO - __main__ -     Num examples = 59002/12/2023 22:29:53 - INFO - __main__ -     Batch size = 8002/12/2023 22:29:53 - INFO - __main__ -     eval_ppl = 1.0035
02/12/2023 22:29:53 - INFO - __main__ -     global_step = 1021
02/12/2023 22:29:53 - INFO - __main__ -     train_loss = 0.0072
02/12/2023 22:29:53 - INFO - __main__ -     ********************02/12/2023 22:29:55 - INFO - __main__ -   Epoch 11, the accuracy is 0.9661016949152542
02/12/2023 22:30:21 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 22:30:21 - INFO - __main__ -     Num examples = 59
02/12/2023 22:30:21 - INFO - __main__ -     Batch size = 8
002/12/2023 22:30:21 - INFO - __main__ -     eval_ppl = 1.00212
02/12/2023 22:30:21 - INFO - __main__ -     global_step = 1106
02/12/2023 22:30:21 - INFO - __main__ -     train_loss = 0.0126
02/12/2023 22:30:21 - INFO - __main__ -     ********************002/12/2023 22:30:23 - INFO - __main__ -   Epoch 12, the accuracy is 0.9830508474576272002/12/2023 22:30:49 - INFO - __main__ -   
***** Running evaluation *****02/12/2023 22:30:49 - INFO - __main__ -     Num examples = 59
02/12/2023 22:30:49 - INFO - __main__ -     Batch size = 8
02/12/2023 22:30:49 - INFO - __main__ -     eval_ppl = 1.00397
02/12/2023 22:30:49 - INFO - __main__ -     global_step = 1191
02/12/2023 22:30:49 - INFO - __main__ -     train_loss = 0.0083
02/12/2023 22:30:49 - INFO - __main__ -     ********************
02/12/2023 22:30:51 - INFO - __main__ -   Epoch 13, the accuracy is 0.9152542372881356
002/12/2023 22:31:17 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 22:31:17 - INFO - __main__ -     Num examples = 59
02/12/2023 22:31:17 - INFO - __main__ -     Batch size = 8002/12/2023 22:31:17 - INFO - __main__ -     eval_ppl = 1.0039
02/12/2023 22:31:17 - INFO - __main__ -     global_step = 1276
02/12/2023 22:31:17 - INFO - __main__ -     train_loss = 0.0025
02/12/2023 22:31:17 - INFO - __main__ -     ********************02/12/2023 22:31:20 - INFO - __main__ -   Epoch 14, the accuracy is 0.9152542372881356
02/12/2023 22:31:45 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 22:31:45 - INFO - __main__ -     Num examples = 59
02/12/2023 22:31:45 - INFO - __main__ -     Batch size = 8
002/12/2023 22:31:45 - INFO - __main__ -     eval_ppl = 1.0033
02/12/2023 22:31:45 - INFO - __main__ -     global_step = 1361
02/12/2023 22:31:45 - INFO - __main__ -     train_loss = 0.0049
02/12/2023 22:31:45 - INFO - __main__ -     ********************002/12/2023 22:31:47 - INFO - __main__ -   Epoch 15, the accuracy is 0.966101694915254202/12/2023 22:32:13 - INFO - __main__ -   
***** Running evaluation *****
002/12/2023 22:32:13 - INFO - __main__ -     Num examples = 59002/12/2023 22:32:13 - INFO - __main__ -     Batch size = 802/12/2023 22:32:13 - INFO - __main__ -     eval_ppl = 1.00421
02/12/2023 22:32:13 - INFO - __main__ -     global_step = 1446
02/12/2023 22:32:13 - INFO - __main__ -     train_loss = 0.003
02/12/2023 22:32:13 - INFO - __main__ -     ********************
0202/12/2023 22:32:15 - INFO - __main__ -   Epoch 16, the accuracy is 0.9661016949152540202/12/2023 22:32:41 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 22:32:41 - INFO - __main__ -     Num examples = 59
02/12/2023 22:32:41 - INFO - __main__ -     Batch size = 0202/12/2023 22:32:41 - INFO - __main__ -     eval_ppl = 1.00536
02/12/2023 22:32:41 - INFO - __main__ -     global_step = 1531
02/12/2023 22:32:41 - INFO - __main__ -     train_loss = 0.0005
02/12/2023 22:32:41 - INFO - __main__ -     *******************02/12/2023 22:32:44 - INFO - __main__ -   Epoch 17, the accuracy is 0.9661016949152542
02/12/2023 22:33:09 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 22:33:09 - INFO - __main__ -     Num examples = 59
02/12/2023 22:33:09 - INFO - __main__ -     Batch size = 8
02/12/2023 22:33:10 - INFO - __main__ -     eval_ppl = 1.00444
02/12/2023 22:33:10 - INFO - __main__ -     global_step = 1616
02/12/2023 22:33:10 - INFO - __main__ -     train_loss = 0.0004
02/12/2023 22:33:10 - INFO - __main__ -     ********************
0202/12/2023 22:33:12 - INFO - __main__ -   Epoch 18, the accuracy is 0.9661016949152540202/12/2023 22:33:37 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 22:33:37 - INFO - __main__ -     Num examples = 59
02/12/2023 22:33:37 - INFO - __main__ -     Batch size = 0202/12/2023 22:33:38 - INFO - __main__ -     eval_ppl = 1.00462
02/12/2023 22:33:38 - INFO - __main__ -     global_step = 1701
02/12/2023 22:33:38 - INFO - __main__ -     train_loss = 0.0004
02/12/2023 22:33:38 - INFO - __main__ -     *******************02/12/2023 22:33:40 - INFO - __main__ -   Epoch 19, the accuracy is 0.9661016949152542
0202/12/2023 22:34:05 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 22:34:05 - INFO - __main__ -     Num examples = 59
02/12/2023 22:34:05 - INFO - __main__ -     Batch size = 0202/12/2023 22:34:06 - INFO - __main__ -     eval_ppl = 1.005
02/12/2023 22:34:06 - INFO - __main__ -     global_step = 1786
02/12/2023 22:34:06 - INFO - __main__ -     train_loss = 0.0001
02/12/2023 22:34:06 - INFO - __main__ -     *******************02/12/2023 22:34:08 - INFO - __main__ -   Epoch 20, the accuracy is 0.9661016949152542
0202/12/2023 22:34:33 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 22:34:33 - INFO - __main__ -     Num examples = 59
02/12/2023 22:34:33 - INFO - __main__ -     Batch size = 0202/12/2023 22:34:34 - INFO - __main__ -     eval_ppl = 1.00535
02/12/2023 22:34:34 - INFO - __main__ -     global_step = 1871
02/12/2023 22:34:34 - INFO - __main__ -     train_loss = 0.0
02/12/2023 22:34:34 - INFO - __main__ -     ********************
002/12/2023 22:34:36 - INFO - __main__ -   Epoch 21, the accuracy is 0.966101694915254202/12/2023 22:35:01 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 22:35:01 - INFO - __main__ -     Num examples = 59
02/12/2023 22:35:01 - INFO - __main__ -     Batch size = 8
02/12/2023 22:35:02 - INFO - __main__ -     eval_ppl = 1.00608
02/12/2023 22:35:02 - INFO - __main__ -     global_step = 1956
02/12/2023 22:35:02 - INFO - __main__ -     train_loss = 0.0003
02/12/2023 22:35:02 - INFO - __main__ -     ********************
02/12/2023 22:35:04 - INFO - __main__ -   Epoch 22, the accuracy is 0.9661016949152542
02/12/2023 22:35:29 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 22:35:29 - INFO - __main__ -     Num examples = 59
02/12/2023 22:35:29 - INFO - __main__ -     Batch size = 8
002/12/2023 22:35:30 - INFO - __main__ -     eval_ppl = 1.00438
02/12/2023 22:35:30 - INFO - __main__ -     global_step = 2041
02/12/2023 22:35:30 - INFO - __main__ -     train_loss = 0.0002
02/12/2023 22:35:30 - INFO - __main__ -     *****************02/102/12/2023 22:35:32 - INFO - __main__ -   Epoch 23, the accuracy is 0.983050847457602/102/12/2023 22:35:58 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 22:35:58 - INFO - __main__ -     Num examples = 59
02/12/2023 22:35:58 - INFO - __main__ -     Batch size 02/102/12/2023 22:35:58 - INFO - __main__ -     eval_ppl = 1.00429
02/12/2023 22:35:58 - INFO - __main__ -     global_step = 2126
02/12/2023 22:35:58 - INFO - __main__ -     train_loss = 0.0
02/12/2023 22:35:58 - INFO - __main__ -     *****************02/102/12/2023 22:36:00 - INFO - __main__ -   Epoch 24, the accuracy is 0.983050847457602/102/12/2023 22:36:26 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 22:36:26 - INFO - __main__ -     Num examples = 59
02/12/2023 22:36:26 - INFO - __main__ -     Batch size 02/12/2023 22:36:26 - INFO - __main__ -     eval_ppl = 1.00425
02/12/2023 22:36:26 - INFO - __main__ -     global_step = 2211
02/12/2023 22:36:26 - INFO - __main__ -     train_loss = 0.0
02/12/2023 22:36:26 - INFO - __main__ -     ********************
02/12/2023 22:36:28 - INFO - __main__ -   Epoch 25, the accuracy is 0.9830508474576272
02/102/12/2023 22:36:54 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 22:36:54 - INFO - __main__ -     Num examples = 59
02/12/2023 22:36:54 - INFO - __main__ -     Batch size 02/12/2023 22:36:54 - INFO - __main__ -     eval_ppl = 1.00399
02/12/2023 22:36:54 - INFO - __main__ -     global_step = 2296
02/12/2023 22:36:54 - INFO - __main__ -     train_loss = 0.0
02/12/2023 22:36:54 - INFO - __main__ -     ********************
02/12/202/12/2023 22:36:56 - INFO - __main__ -   Epoch 26, the accuracy is 0.983050847402/12/2023 22:37:22 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 22:37:22 - INFO - __main__ -     Num examples = 59
02/12/2023 22:37:22 - INFO - __main__ -     Batch size = 8
02/12/2023 22:37:22 - INFO - __main__ -     eval_ppl = 1.00626
02/12/2023 22:37:22 - INFO - __main__ -     global_step = 2381
02/12/2023 22:37:22 - INFO - __main__ -     train_loss = 0.0011
02/12/2023 22:37:22 - INFO - __main__ -     ********************
02/12/202/12/2023 22:37:24 - INFO - __main__ -   Epoch 27, the accuracy is 0.898305084702/12/202/12/2023 22:37:50 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 22:37:50 - INFO - __main__ -     Num examples = 59
02/12/2023 22:37:50 - INFO - __main__ -     Batch si02/12/202/12/2023 22:37:50 - INFO - __main__ -     eval_ppl = 1.00281
02/12/2023 22:37:50 - INFO - __main__ -     global_step = 2466
02/12/2023 22:37:50 - INFO - __main__ -     train_loss = 0.0178
02/12/2023 22:37:50 - INFO - __main__ -     **************02/12/2023 22:37:52 - INFO - __main__ -   Epoch 28, the accuracy is 0.9830508474576272
02/12/2023 22:38:18 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 22:38:18 - INFO - __main__ -     Num examples = 59
02/12/2023 22:38:18 - INFO - __main__ -     Batch size = 8
02/12/2023 22:38:18 - INFO - __main__ -     eval_ppl = 1.0034
02/12/2023 22:38:18 - INFO - __main__ -     global_step = 2551
02/12/2023 22:38:18 - INFO - __main__ -     train_loss = 0.0023
02/12/2023 22:38:18 - INFO - __main__ -     ********************
02/12/202/12/2023 22:38:20 - INFO - __main__ -   Epoch 29, the accuracy is 0.983050847402/12/202/12/2023 22:38:46 - INFO - __main__ -   
***** Running evaluation02/12/202/12/2023 22:38:46 - INFO - __main__ -     Num examples = 59
02/12/2023 22:38:46 - INFO - __main__ -     Batch si02/12/2023 22:38:46 - INFO - __main__ -     eval_ppl = 1.00362
02/12/2023 22:38:46 - INFO - __main__ -     global_step = 2636
02/12/2023 22:38:46 - INFO - __main__ -     train_loss = 0.0002
02/12/2023 22:38:46 - INFO - __main__ -     ********************
02/12/2023 22:38:48 - INFO - __main__ -   Epoch 30, the accuracy is 0.9661016949152542
02/12/2023 22:39:14 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 22:39:14 - INFO - __main__ -     Num examples = 59
02/12/2023 22:39:14 - INFO - __main__ -     Batch size = 8
02/12/202/12/2023 22:39:14 - INFO - __main__ -     eval_ppl = 1.00325
02/12/2023 22:39:14 - INFO - __main__ -     global_step = 2721
02/12/2023 22:39:14 - INFO - __main__ -     train_loss = 0.0001
02/12/2023 22:39:14 - INFO - __main__ -     **************02/12/202/12/2023 22:39:16 - INFO - __main__ -   Epoch 31, the accuracy is 0.983050847402/12/202/12/2023 22:39:42 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 22:39:42 - INFO - __main__ -     Num examples = 59
02/12/2023 22:39:42 - INFO - __main__ -     Batch si02/12/2023 22:39:42 - INFO - __main__ -     eval_ppl = 1.00333
02/12/2023 22:39:42 - INFO - __main__ -     global_step = 2806
02/12/2023 22:39:42 - INFO - __main__ -     train_loss = 0.0001
02/12/2023 22:39:42 - INFO - __main__ -     ********************
02/12/202/12/2023 22:39:45 - INFO - __main__ -   Epoch 32, the accuracy is 0.983050847402/12/2023 22:40:10 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 22:40:10 - INFO - __main__ -     Num examples = 59
02/12/2023 22:40:10 - INFO - __main__ -     Batch size = 8
02/12/2023 22:40:10 - INFO - __main__ -     eval_ppl = 1.00351
02/12/2023 22:40:10 - INFO - __main__ -     global_step = 2891
02/12/2023 22:40:10 - INFO - __main__ -     train_loss = 0.0001
02/12/2023 22:40:10 - INFO - __main__ -     ********************
02/12/2023 22:40:13 - INFO - __main__ -   Epoch 33, the accuracy is 0.9830508474576272
02/12/2023 22:40:38 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 22:40:38 - INFO - __main__ -     Num examples = 59
02/12/2023 22:40:38 - INFO - __main__ -     Batch size = 8
02/12/2023 22:40:39 - INFO - __main__ -     eval_ppl = 1.00363
02/12/2023 22:40:39 - INFO - __main__ -     global_step = 2976
02/12/2023 22:40:39 - INFO - __main__ -     train_loss = 0.0
02/12/2023 22:40:39 - INFO - __main__ -     ********************
02/12/2023 22:40:40 - INFO - __main__ -   Epoch 34, the accuracy is 0.9830508474576272
02/12/2023 22:41:06 - INFO - __main__ -   
***** Running evaluation *****
02/12/202302/12/2023 22:41:06 - INFO - __main__ -     Num exam02/12/202302/12/2023 22:41:06 - INFO - __main__ -     Batch02/12/2023 22:41:06 - INFO - __main__ -     eval_ppl = 1.00365
02/12/2023 22:41:06 - INFO - __main__ -     global_step = 3061
02/12/2023 22:41:06 - INFO - __main__ -     train_loss = 0.0
02/12/2023 22:41:06 - INFO - __main__ -     ********************
02/12/202302/12/2023 22:41:08 - INFO - __main__ -   Epoch 35, the accuracy is 0.983050802/12/2023 22:41:34 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 22:41:34 - INFO - __main__ -     Num examples = 59
02/12/2023 22:41:34 - INFO - __main__ -     Batch size = 8
02/12/2023 22:41:34 - INFO - __main__ -     eval_ppl = 1.00374
02/12/2023 22:41:34 - INFO - __main__ -     global_step = 3146
02/12/2023 22:41:34 - INFO - __main__ -     train_loss = 0.0
02/12/2023 22:41:34 - INFO - __main__ -     ********************
02/12/2023 22:41:36 - INFO - __main__ -   Epoch 36, the accuracy is 0.9830508474576272
02/12/2023 22:42:02 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 22:42:02 - INFO - __main__ -     Num examples = 59
02/12/2023 22:42:02 - INFO - __main__ -     Batch size = 8
02/12/2023 22:42:02 - INFO - __main__ -     eval_ppl = 1.00367
02/12/2023 22:42:02 - INFO - __main__ -     global_step = 3231
02/12/2023 22:42:02 - INFO - __main__ -     train_loss = 0.0
02/12/2023 22:42:02 - INFO - __main__ -     ********************
02/12/2023 22:4202/12/2023 22:42:04 - INFO - __main__ -   Epoch 37, the accuracy is 0.902/12/2023 22:42:30 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 22:42:30 - INFO - __main__ -     Num examples = 59
02/12/2023 22:42:30 - INFO - __main__ -     Batch size = 8
02/12/2023 22:42:30 - INFO - __main__ -     eval_ppl = 1.00375
02/12/2023 22:42:30 - INFO - __main__ -     global_step = 3316
02/12/2023 22:42:30 - INFO - __main__ -     train_loss = 0.0
02/12/2023 22:42:30 - INFO - __main__ -     ********************
02/12/2023 22:42:32 - INFO - __main__ -   Epoch 38, the accuracy is 0.9830508474576272
02/12/2023 22:42:58 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 22:42:58 - INFO - __main__ -     Num examples = 59
02/12/2023 22:42:58 - INFO - __main__ -     Batch size = 8
02/12/2023 22:42:58 - INFO - __main__ -     eval_ppl = 1.00378
02/12/2023 22:42:58 - INFO - __main__ -     global_step = 3401
02/12/2023 22:42:58 - INFO - __main__ -     train_loss = 0.0
02/12/2023 22:42:58 - INFO - __main__ -     ********************
02/12/2023 22:4302/12/2023 22:43:00 - INFO - __main__ -   Epoch 39, the accuracy is 0.902/12/2023 22:43:26 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 22:43:26 - INFO - __main__ -     Num examples = 59
02/12/2023 22:43:26 - INFO - __main__ -     Batch size = 8
02/12/2023 22:43:26 - INFO - __main__ -     eval_ppl = 1.00368
02/12/2023 22:43:26 - INFO - __main__ -     global_step = 3486
02/12/2023 22:43:26 - INFO - __main__ -     train_loss = 0.0
02/12/2023 22:43:26 - INFO - __main__ -     ********************
02/12/2023 22:4302/12/2023 22:43:29 - INFO - __main__ -   Epoch 40, the accuracy is 0.902/12/2023 22:43:54 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 22:43:54 - INFO - __main__ -     Num examples = 59
02/12/2023 22:43:54 - INFO - __main__ -     Batch size = 8
02/12/2023 22:43:54 - INFO - __main__ -     eval_ppl = 1.00373
02/12/2023 22:43:54 - INFO - __main__ -     global_step = 3571
02/12/2023 22:43:54 - INFO - __main__ -     train_loss = 0.0153
02/12/2023 22:43:54 - INFO - __main__ -     ********************
02/12/2023 22:4302/12/2023 22:43:57 - INFO - __main__ -   Epoch 41, the accuracy is 0.902/12/2023 22:4402/12/2023 22:44:22 - INFO - __main__ -   
***** Running e02/12/2023 22:4402/12/2023 22:44:22 - INFO - __main__ -     Num examples = 59
02/12/2023 22:44:22 - INFO - __main__ -    02/12/2023 22:4402/12/2023 22:44:23 - INFO - __main__ -     eval_ppl = 1.00388
02/12/2023 22:44:23 - INFO - __main__ -     global_step = 3656
02/12/2023 22:44:23 - INFO - __main__ -     train_loss = 0.0001
02/12/2023 22:44:23 - INFO - __main__ -     **02/12/2023 22:44:25 - INFO - __main__ -   Epoch 42, the accuracy is 0.9661016949152542
02/12/2023 22:44:50 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 22:44:50 - INFO - __main__ -     Num examples = 59
02/12/2023 22:44:50 - INFO - __main__ -     Batch size = 8
02/12/2023 22:44:51 - INFO - __main__ -     eval_ppl = 1.00322
02/12/2023 22:44:51 - INFO - __main__ -     global_step = 3741
02/12/2023 22:44:51 - INFO - __main__ -     train_loss = 0.0009
02/12/2023 22:44:51 - INFO - __main__ -     ********************
02/12/2023 22:44:5302/12/2023 22:44:53 - INFO - __main__ -   Epoch 43, the accuracy is 02/12/2023 22:45:18 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 22:45:18 - INFO - __main__ -     Num examples = 59
02/12/2023 22:45:18 - INFO - __main__ -     Batch size = 8
02/12/2023 22:45:19 - INFO - __main__ -     eval_ppl = 1.00322
02/12/2023 22:45:19 - INFO - __main__ -     global_step = 3826
02/12/2023 22:45:19 - INFO - __main__ -     train_loss = 0.0009
02/12/2023 22:45:19 - INFO - __main__ -     ********************
02/12/2023 22:45:2102/12/2023 22:45:21 - INFO - __main__ -   Epoch 44, the accuracy is 02/12/2023 22:45:4602/12/2023 22:45:46 - INFO - __main__ -   
***** Runnin02/12/2023 22:45:4602/12/2023 22:45:46 - INFO - __main__ -    02/12/2023 22:45:4602/12/2023 22:45:46 - INFO - __main__ - 02/12/2023 22:45:47 - INFO - __main__ -     eval_ppl = 1.00346
02/12/2023 22:45:47 - INFO - __main__ -     global_step = 3911
02/12/2023 22:45:47 - INFO - __main__ -     train_loss = 0.0001
02/12/2023 22:45:47 - INFO - __main__ -     ********************
02/12/2023 22:45:49 - INFO - __main__ -   Epoch 45, the accuracy is 0.9661016949152542
02/12/2023 22:46:14 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 22:46:14 - INFO - __main__ -     Num examples = 59
02/12/2023 22:46:14 - INFO - __main__ -     Batch size = 8
02/12/2023 22:46:15 - INFO - __main__ -     eval_ppl = 1.00633
02/12/2023 22:46:15 - INFO - __main__ -     global_step = 3996
02/12/2023 22:46:15 - INFO - __main__ -     train_loss = 0.0001
02/12/2023 22:46:15 - INFO - __main__ -     ********************
02/12/2023 22:46:1702/12/2023 22:46:17 - INFO - __main__ -   Epoch 46, the accuracy is 02/12/2023 22:46:43 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 22:46:43 - INFO - __main__ -     Num examples = 59
02/12/2023 22:46:43 - INFO - __main__ -     Batch size = 8
02/12/2023 22:46:43 - INFO - __main__ -     eval_ppl = 1.00378
02/12/2023 22:46:43 - INFO - __main__ -     global_step = 4081
02/12/2023 22:46:43 - INFO - __main__ -     train_loss = 0.0008
02/12/2023 22:46:43 - INFO - __main__ -     ********************
02/12/2023 22:46:4502/12/2023 22:46:45 - INFO - __main__ -   Epoch 47, the accuracy is 02/12/2023 22:47:11 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 22:47:11 - INFO - __main__ -     Num examples = 59
02/12/2023 22:47:11 - INFO - __main__ -     Batch size = 8
02/12/2023 22:47:11 - INFO - __main__ -     eval_ppl = 1.00385
02/12/2023 22:47:11 - INFO - __main__ -     global_step = 4166
02/12/2023 22:47:11 - INFO - __main__ -     train_loss = 0.0001
02/12/2023 22:47:11 - INFO - __main__ -     ********************
02/12/2023 22:47:13 - INFO - __main__ -   Epoch 48, the accuracy is 0.9661016949152542
02/12/2023 22:4702/12/2023 22:47:39 - INFO - __main__ -   
***** Running e02/12/2023 22:4702/12/2023 22:47:39 - INFO - __main__ -     Nu02/12/2023 22:4702/12/2023 22:47:39 - INFO - __main__ -    02/12/2023 22:47:39 - INFO - __main__ -     eval_ppl = 1.00386
02/12/2023 22:47:39 - INFO - __main__ -     global_step = 4251
02/12/2023 22:47:39 - INFO - __main__ -     train_loss = 0.0
02/12/2023 22:47:39 - INFO - __main__ -     ********************
02/12/2023 22:47:41 - INFO - __main__ -   Epoch 49, the accuracy is 0.9661016949152542
02/12/2023 22:48:07 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 22:48:07 - INFO - __main__ -     Num examples = 59
02/12/2023 22:48:07 - INFO - __main__ -     Batch size = 8
02/12/2023 22:48:07 - INFO - __main__ -     eval_ppl = 1.00359
02/12/2023 22:48:07 - INFO - __main__ -     global_step = 4336
02/12/2023 22:48:07 - INFO - __main__ -     train_loss = 0.0001
02/12/2023 22:48:07 - INFO - __main__ -     ********************
02/12/2023 22:4802/12/2023 22:48:09 - INFO - __main__ -   Epoch 50, the accuracy is 0.902/12/2023 22:4802/12/2023 22:48:35 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 22:48:35 - INFO - __main__ -     Num examples = 59
02/12/2023 22:48:35 - INFO - __main__ -    02/12/2023 22:48:35 - INFO - __main__ -     eval_ppl = 1.00366
02/12/2023 22:48:35 - INFO - __main__ -     global_step = 4421
02/12/2023 22:48:35 - INFO - __main__ -     train_loss = 0.0
02/12/2023 22:48:35 - INFO - __main__ -     ********************
02/12/2023 22:48:37 - INFO - __main__ -   Epoch 51, the accuracy is 0.9830508474576272
02/12/2023 22:49:03 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 22:49:03 - INFO - __main__ -     Num examples = 59
02/12/2023 22:49:03 - INFO - __main__ -     Batch size = 8
02/12/2023 22:4902/12/2023 22:49:03 - INFO - __main__ -     eval_ppl = 1.00395
02/12/2023 22:49:03 - INFO - __main__ -     global_step = 4506
02/12/2023 22:49:03 - INFO - __main__ -     train_loss = 0.0047
02/12/2023 22:49:03 - INFO - __main__ -     *****02/12/2023 22:49:05 - INFO - __main__ -   Epoch 52, the accuracy is 0.9661016949152542
02/12/2023 22:49:31 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 22:49:31 - INFO - __main__ -     Num examples = 59
02/12/2023 22:49:31 - INFO - __main__ -     Batch size = 8
02/12/2023 22:49:31 - INFO - __main__ -     eval_ppl = 1.00412
02/12/2023 22:49:31 - INFO - __main__ -     global_step = 4591
02/12/2023 22:49:31 - INFO - __main__ -     train_loss = 0.0029
02/12/2023 22:49:31 - INFO - __main__ -     ********************
02/12/2023 22:4902/12/2023 22:49:33 - INFO - __main__ -   Epoch 53, the accuracy is 0.902/12/2023 22:49:59 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 22:49:59 - INFO - __main__ -     Num examples = 59
02/12/2023 22:49:59 - INFO - __main__ -     Batch size = 8
02/12/2023 22:4902/12/2023 22:49:59 - INFO - __main__ -     eval_ppl = 1.00503
02/12/2023 22:49:59 - INFO - __main__ -     global_step = 4676
02/12/2023 22:49:59 - INFO - __main__ -     train_loss = 0.0002
02/12/2023 22:49:59 - INFO - __main__ -     *****02/12/2023 22:50:01 - INFO - __main__ -   Epoch 54, the accuracy is 0.9661016949152542
02/12/2023 22:50:27 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 22:50:27 - INFO - __main__ -     Num examples = 59
02/12/2023 22:50:27 - INFO - __main__ -     Batch size = 8
02/12/2023 22:50:27 - INFO - __main__ -     eval_ppl = 1.00438
02/12/2023 22:50:27 - INFO - __main__ -     global_step = 4761
02/12/2023 22:50:27 - INFO - __main__ -     train_loss = 0.0001
02/12/2023 22:50:27 - INFO - __main__ -     ********************
02/12/2023 22:5002/12/2023 22:50:29 - INFO - __main__ -   Epoch 55, the accuracy is 0.902/12/2023 22:50:55 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 22:50:55 - INFO - __main__ -     Num examples = 59
02/12/2023 22:50:55 - INFO - __main__ -     Batch size = 8
02/12/2023 22:5002/12/2023 22:50:56 - INFO - __main__ -     eval_ppl = 1.00411
02/12/2023 22:50:56 - INFO - __main__ -     global_step = 4846
02/12/2023 22:50:56 - INFO - __main__ -     train_loss = 0.0001
02/12/2023 22:50:56 - INFO - __main__ -     **02/12/2023 22:50:58 - INFO - __main__ -   Epoch 56, the accuracy is 0.9661016949152542
02/12/2023 22:51:23 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 22:51:23 - INFO - __main__ -     Num examples = 59
02/12/2023 22:51:23 - INFO - __main__ -     Batch size = 8
02/12/2023 22:51:24 - INFO - __main__ -     eval_ppl = 1.00525
02/12/2023 22:51:24 - INFO - __main__ -     global_step = 4931
02/12/2023 22:51:24 - INFO - __main__ -     train_loss = 0.0003
02/12/2023 22:51:24 - INFO - __main__ -     ********************
02/12/2023 22:5102/12/2023 22:51:26 - INFO - __main__ -   Epoch 57, the accuracy is 0.902/12/2023 22:51:51 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 22:51:51 - INFO - __main__ -     Num examples = 59
02/12/2023 22:51:51 - INFO - __main__ -     Batch size = 8
02/12/2023 22:51:52 - INFO - __main__ -     eval_ppl = 1.00508
02/12/2023 22:51:52 - INFO - __main__ -     global_step = 5016
02/12/2023 22:51:52 - INFO - __main__ -     train_loss = 0.0019
02/12/2023 22:51:52 - INFO - __main__ -     ********************
02/12/2023 22:5102/12/2023 22:51:54 - INFO - __main__ -   Epoch 58, the accuracy is 0.902/12/2023 22:5202/12/2023 22:52:19 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 22:52:19 - INFO - __main__ -     Num examples = 59
02/12/2023 22:52:19 - INFO - __main__ -    02/12/2023 22:52:20 - INFO - __main__ -     eval_ppl = 1.00321
02/12/2023 22:52:20 - INFO - __main__ -     global_step = 5101
02/12/2023 22:52:20 - INFO - __main__ -     train_loss = 0.0019
02/12/2023 22:52:20 - INFO - __main__ -     ********************
02/12/2023 22:5202/12/2023 22:52:22 - INFO - __main__ -   Epoch 59, the accuracy is 0.902/12/2023 22:52:47 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 22:52:47 - INFO - __main__ -     Num examples = 59
02/12/2023 22:52:47 - INFO - __main__ -     Batch size = 8
02/12/2023 22:52:48 - INFO - __main__ -     eval_ppl = 1.0041
02/12/2023 22:52:48 - INFO - __main__ -     global_step = 5186
02/12/2023 22:52:48 - INFO - __main__ -     train_loss = 0.0
02/12/2023 22:52:48 - INFO - __main__ -     ********************
02/12/2023 22:52:50 - INFO - __main__ -   Epoch 60, the accuracy is 0.9661016949152542
02/12/2023 22:53:15 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 22:53:15 - INFO - __main__ -     Num examples = 59
02/12/2023 22:53:15 - INFO - __main__ -     Batch size = 8
02/12/2023 22:53:16 - INFO - __main__ -     eval_ppl = 1.00409
02/12/2023 22:53:16 - INFO - __main__ -     global_step = 5271
02/12/2023 22:53:16 - INFO - __main__ -     train_loss = 0.0
02/12/2023 22:53:16 - INFO - __main__ -     ********************
02/12/2023 22:53:18 - INFO - __main__ -   Epoch 61, the accuracy is 0.9661016949152542
02/12/2023 22:53:43 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 22:53:43 - INFO - __main__ -     Num examples = 59
02/12/2023 22:53:43 - INFO - __main__ -     Batch size = 8
02/12/2023 22:53:44 - INFO - __main__ -     eval_ppl = 1.00405
02/12/2023 22:53:44 - INFO - __main__ -     global_step = 5356
02/12/2023 22:53:44 - INFO - __main__ -     train_loss = 0.0
02/12/2023 22:53:44 - INFO - __main__ -     ********************
02/12/2023 22:53:46 - INFO - __main__ -   Epoch 62, the accuracy is 0.9661016949152542
02/12/2023 22:54:11 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 22:54:11 - INFO - __main__ -     Num examples = 59
02/12/2023 22:54:11 - INFO - __main__ -     Batch size = 8
02/12/2023 22:54:1202/12/2023 22:54:12 - INFO - __main__ -     eval_ppl = 1.00398
02/12/2023 22:54:12 - INFO - __main__ -     global_step = 5441
02/12/2023 22:54:12 - INFO - __main__ -     train_loss = 0.0
02/12/2023 22:54:12 - INFO - __main__ -     **02/12/2023 22:54:1402/12/2023 22:54:14 - INFO - __main__ -   Epoch 63, the accuracy is 02/12/2023 22:54:39 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 22:54:39 - INFO - __main__ -     Num examples = 59
02/12/2023 22:54:39 - INFO - __main__ -     Batch size = 8
02/12/2023 22:54:40 - INFO - __main__ -     eval_ppl = 1.00404
02/12/2023 22:54:40 - INFO - __main__ -     global_step = 5526
02/12/2023 22:54:40 - INFO - __main__ -     train_loss = 0.0
02/12/2023 22:54:40 - INFO - __main__ -     ********************
02/12/2023 22:54:4202/12/2023 22:54:42 - INFO - __main__ -   Epoch 64, the accuracy is 02/12/2023 22:55:07 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 22:55:0702/12/2023 22:55:07 - INFO - __main__ -    02/12/2023 22:55:0702/12/2023 22:55:07 - INFO - __main__ - 02/12/2023 22:55:08 - INFO - __main__ -     eval_ppl = 1.00404
02/12/2023 22:55:08 - INFO - __main__ -     global_step = 5611
02/12/2023 22:55:08 - INFO - __main__ -     train_loss = 0.0
02/12/2023 22:55:08 - INFO - __main__ -     ********************
02/12/2023 22:55:10 - INFO - __main__ -   Epoch 65, the accuracy is 0.9661016949152542
02/12/2023 22:55:35 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 22:55:35 - INFO - __main__ -     Num examples = 59
02/12/2023 22:55:35 - INFO - __main__ -     Batch size = 8
02/12/2023 22:55:36 - 02/12/2023 22:55:36 - INFO - __main__ -     eval_ppl = 1.00406
02/12/2023 22:55:36 - INFO - __main__ -     global_step = 5696
02/12/2023 22:55:36 - INFO - __main__ -     train_loss = 0.0
02/12/2023 22:55:36 - INFO - __main__ -    02/12/2023 22:55:38 - INFO - __main__ -   Epoch 66, the accuracy is 0.9661016949152542
02/12/2023 22:56:04 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 22:56:04 - INFO - __main__ -     Num examples = 59
02/12/2023 22:56:04 - INFO - __main__ -     Batch size = 8
02/12/2023 22:56:04 - INFO - __main__ -     eval_ppl = 1.00415
02/12/2023 22:56:04 - INFO - __main__ -     global_step = 5781
02/12/2023 22:56:04 - INFO - __main__ -     train_loss = 0.0
02/12/2023 22:56:04 - INFO - __main__ -     ********************
02/12/2023 22:56:06 - INFO - __main__ -   Epoch 67, the accuracy is 0.9661016949152542
02/12/2023 22:56:31 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 22:56:31 - INFO - __main__ -     Num examples = 59
02/12/2023 22:56:31 - INFO - __main__ -     Batch size = 8
02/12/2023 22:56:32 - INFO - __main__ -     eval_ppl = 1.00416
02/12/2023 22:56:32 - INFO - __main__ -     global_step = 5866
02/12/2023 22:56:32 - INFO - __main__ -     train_loss = 0.0
02/12/2023 22:56:32 - INFO - __main__ -     ********************
02/12/2023 22:56:34 - 02/12/2023 22:56:34 - INFO - __main__ -   Epoch 68, the accuracy 02/12/2023 22:56:59 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 22:56:59 - INFO - __main__ -     Num examples = 59
02/12/2023 22:56:59 - INFO - __main__ -     Batch size = 8
02/12/2023 22:57:00 - INFO - __main__ -     eval_ppl = 1.00417
02/12/2023 22:57:00 - INFO - __main__ -     global_step = 5951
02/12/2023 22:57:00 - INFO - __main__ -     train_loss = 0.0
02/12/2023 22:57:00 - INFO - __main__ -     ********************
02/12/2023 22:57:02 - 02/12/2023 22:57:02 - INFO - __main__ -   Epoch 69, the accuracy 02/12/2023 22:57:28 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 22:57:28 - INFO - __main__ -     Num examples = 59
02/12/2023 22:57:28 - INFO - __main__ -     Batch size = 8
02/12/2023 22:57:28 - 02/12/2023 22:57:28 - INFO - __main__ -     eval_ppl = 1.00417
02/12/2023 22:57:28 - INFO - __main__ -     global_step = 6036
02/12/2023 22:57:28 - INFO - __main__ -     train_loss = 0.0
02/12/2023 22:57:28 - INFO - __main__ -    02/12/2023 22:57:30 - INFO - __main__ -   Epoch 70, the accuracy is 0.9661016949152542
02/12/2023 22:57:55 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 22:57:55 - INFO - __main__ -     Num examples = 59
02/12/2023 22:57:55 - INFO - __main__ -     Batch size = 8
02/12/2023 22:57:56 - 02/12/2023 22:57:56 - INFO - __main__ -     eval_ppl = 1.00421
02/12/2023 22:57:56 - INFO - __main__ -     global_step = 6121
02/12/2023 22:57:56 - INFO - __main__ -     train_loss = 0.0
02/12/2023 22:57:56 - INFO - __main__ -    02/12/2023 22:57:58 - INFO - __main__ -   Epoch 71, the accuracy is 0.9661016949152542
02/12/2023 22:58:23 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 22:58:23 - INFO - __main__ -     Num examples = 59
02/12/2023 22:58:23 - INFO - __main__ -     Batch size = 8
02/12/2023 22:58:24 - INFO - __main__ -     eval_ppl = 1.00421
02/12/2023 22:58:24 - INFO - __main__ -     global_step = 6206
02/12/2023 22:58:24 - INFO - __main__ -     train_loss = 0.0
02/12/2023 22:58:24 - INFO - __main__ -     ********************
02/12/2023 22:58:26 - 02/12/2023 22:58:26 - INFO - __main__ -   Epoch 72, the accuracy 02/12/2023 22:58:52 - 02/12/2023 22:58:52 - INFO - __main__ -   
***** Run02/12/2023 22:58:52 - 02/12/2023 22:58:52 - INFO - __main__ -     Num examples = 59
02/12/2023 22:58:52 - INFO - __main__02/12/2023 22:58:52 - 02/12/2023 22:58:52 - INFO - __main__ -     eval_ppl = 1.00419
02/12/2023 22:58:52 - INFO - __main__ -     global_step = 6291
02/12/2023 22:58:52 - INFO - __main__ -     train_loss = 0.0
02/12/2023 22:58:52 - INFO - __main__ -    02/12/2023 22:58:54 - 02/12/2023 22:58:54 - INFO - __main__ -   Epoch 73, the accuracy 02/12/2023 22:59:20 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 22:59:20 - 02/12/2023 22:59:20 - INFO - __main__ - 02/12/2023 22:59:20 - 02/12/2023 22:59:20 - INFO - __main__02/12/2023 22:59:20 - INFO - __main__ -     eval_ppl = 1.00421
02/12/2023 22:59:20 - INFO - __main__ -     global_step = 6376
02/12/2023 22:59:20 - INFO - __main__ -     train_loss = 0.0
02/12/2023 22:59:20 - INFO - __main__ -     ********************
02/12/2023 22:59:22 - 02/12/2023 22:59:22 - INFO - __main__ -   Epoch 74, the accuracy 02/12/2023 22:59:48 - 02/12/2023 22:59:48 - INFO - __main__ -   
***** Run02/12/2023 22:59:48 - 02/12/2023 22:59:48 - INFO - __main__ -     Num examples = 59
02/12/2023 22:59:48 - INFO - __main__02/12/2023 22:59:48 - INFO - __main__ -     eval_ppl = 1.00439
02/12/2023 22:59:48 - INFO - __main__ -     global_step = 6461
02/12/2023 22:59:48 - INFO - __main__ -     train_loss = 0.0
02/12/2023 22:59:48 - INFO - __main__ -     ********************
02/12/2023 22:59:50 - 02/12/2023 22:59:50 - INFO - __main__ -   Epoch 75, the accuracy 02/12/2023 23:00:16 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 23:00:16 - INFO - __main__ -     Num examples = 59
02/12/2023 23:00:16 - INFO - __main__ -     Batch size = 8
02/12/2023 23:00:16 - 02/12/2023 23:00:16 - INFO - __main__ -     eval_ppl = 1.00447
02/12/2023 23:00:16 - INFO - __main__ -     global_step = 6546
02/12/2023 23:00:16 - INFO - __main__ -     train_loss = 0.0
02/12/2023 23:00:16 - INFO - __main__ -    02/12/2023 23:00:18 - 02/12/2023 23:00:19 - INFO - __main__ -   Epoch 76, the accuracy 02/12/2023 23:00:44 - 02/12/2023 23:00:44 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 23:00:44 - INFO - __main__ -     Num examples = 59
02/12/2023 23:00:44 - INFO - __main__02/12/2023 23:00:45 - 02/12/2023 23:00:45 - INFO - __main__ -     eval_ppl = 1.00447
02/12/2023 23:00:45 - INFO - __main__ -     global_step = 6631
02/12/2023 23:00:45 - INFO - __main__ -     train_loss = 0.0
02/12/2023 23:00:45 - INFO - __main__ -    02/12/2023 23:00:47 - INFO - __main__ -   Epoch 77, the accuracy is 0.9661016949152542
02/12/2023 23:01:12 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 23:01:12 - INFO - __main__ -     Num examples = 59
02/12/2023 23:01:12 - INFO - __main__ -     Batch size = 8
02/12/2023 23:01:13 - INFO - __main__ -     eval_ppl = 1.00448
02/12/2023 23:01:13 - INFO - __main__ -     global_step = 6716
02/12/2023 23:01:13 - INFO - __main__ -     train_loss = 0.0
02/12/2023 23:01:13 - INFO - __main__ -     ********************
02/12/2023 23:01:15 - 02/12/2023 23:01:15 - INFO - __main__ -   Epoch 78, the accuracy 02/12/2023 23:01:40 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 23:01:40 - INFO - __main__ -     Num examples = 59
02/12/2023 23:01:40 - INFO - __main__ -     Batch size = 8
02/12/2023 23:01:41 - INFO - __main__ -     eval_ppl = 1.0045
02/12/2023 23:01:41 - INFO - __main__ -     global_step = 6801
02/12/2023 23:01:41 - INFO - __main__ -     train_loss = 0.0
02/12/2023 23:01:41 - INFO - __main__ -     ********************
02/12/2023 23:01:43 - 02/12/2023 23:01:43 - INFO - __main__ -   Epoch 79, the accuracy 02/12/2023 23:02:08 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 23:02:08 - INFO - __main__ -     Num examples = 59
02/12/2023 23:02:08 - INFO - __main__ -     Batch size = 8
02/12/2023 23:02:09 - INFO - __main__ -     eval_ppl = 1.00452
02/12/2023 23:02:09 - INFO - __main__ -     global_step = 6886
02/12/2023 23:02:09 - INFO - __main__ -     train_loss = 0.0
02/12/2023 23:02:09 - INFO - __main__ -     ********************
02/12/2023 23:02:11 - 02/12/2023 23:02:11 - INFO - __main__ -   Epoch 80, the accuracy 02/12/2023 23:02:36 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 23:02:36 - INFO - __main__ -     Num examples = 59
02/12/2023 23:02:36 - INFO - __main__ -     Batch size = 8
02/12/2023 23:02:37 - INFO - __main__ -     eval_ppl = 1.00451
02/12/2023 23:02:37 - INFO - __main__ -     global_step = 6971
02/12/2023 23:02:37 - INFO - __main__ -     train_loss = 0.0
02/12/2023 23:02:37 - INFO - __main__ -     ********************
02/12/2023 23:02:38 - 02/12/2023 23:02:38 - INFO - __main__ -   Epoch 81, the accuracy 02/12/2023 23:03:04 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 23:03:04 - INFO - __main__ -     Num examples = 59
02/12/2023 23:03:04 - INFO - __main__ -     Batch size = 8
02/12/2023 23:03:04 - INFO - __main__ -     eval_ppl = 1.00451
02/12/2023 23:03:04 - INFO - __main__ -     global_step = 7056
02/12/2023 23:03:04 - INFO - __main__ -     train_loss = 0.0
02/12/2023 23:03:04 - INFO - __main__ -     ********************
02/12/2023 23:03:06 - 02/12/2023 23:03:06 - INFO - __main__ -   Epoch 82, the accuracy 02/12/2023 23:03:32 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 23:03:32 - INFO - __main__ -     Num examples = 59
02/12/2023 23:03:32 - INFO - __main__ -     Batch size = 8
02/12/2023 23:03:32 - 02/12/2023 23:03:32 - INFO - __main__ -     eval_ppl = 1.00451
02/12/2023 23:03:32 - INFO - __main__ -     global_step = 7141
02/12/2023 23:03:32 - INFO - __main__ -     train_loss = 0.0
02/12/2023 23:03:32 - INFO - __main__ -    02/12/2023 23:03:35 - 02/12/2023 23:03:35 - INFO - __main__ -   Epoch 83, the accuracy 02/12/2023 23:04:00 - 02/12/2023 23:04:00 - INFO - __main__ -   
***** Run02/12/2023 23:04:00 - 02/12/2023 23:04:00 - INFO - __main__ - 02/12/2023 23:04:00 - 02/12/2023 23:04:00 - INFO - __main__02/12/2023 23:04:01 - 02/12/2023 23:04:01 - INFO - __main__ -     eval_ppl = 1.00451
02/12/2023 23:04:01 - INFO - __main__ -     global_step = 7226
02/12/2023 23:04:01 - INFO - __main__ -     train_loss = 0.0
02/12/2023 23:04:01 - INFO - __main__ -    02/12/2023 23:04:03 - 02/12/2023 23:04:03 - INFO - __main__ -   Epoch 84, the accuracy 02/12/2023 23:04:28 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 23:04:28 - INFO - __main__ -     Num examples = 59
02/12/2023 23:04:28 - INFO - __main__ -     Batch size = 8
02/12/2023 23:04:29 - 02/12/2023 23:04:29 - INFO - __main__ -     eval_ppl = 1.00442
02/12/2023 23:04:29 - INFO - __main__ -     global_step = 7311
02/12/2023 23:04:29 - INFO - __main__ -     train_loss = 0.0
02/12/2023 23:04:29 - INFO - __main__ -    02/12/2023 23:04:31 - 02/12/2023 23:04:31 - INFO - __main__ -   Epoch 85, the accuracy 02/12/2023 23:04:56 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 23:04:56 - INFO - __main__ -     Num examples = 59
02/12/2023 23:04:56 - INFO - __main__ -     Batch size = 8
02/12/2023 23:04:57 - 02/12/2023 23:04:57 - INFO - __main__ -     eval_ppl = 1.00441
02/12/2023 23:04:57 - INFO - __main__ -     global_step = 7396
02/12/2023 23:04:57 - INFO - __main__ -     train_loss = 0.0
02/12/2023 23:04:57 - INFO - __main__ -    02/12/2023 23:04:59 - INFO - __main__ -   Epoch 86, the accuracy is 0.9661016949152542
02/12/2023 23:05:24 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 23:05:24 - INFO - __main__ -     Num examples = 59
02/12/2023 23:05:24 - INFO - __main__ -     Batch size = 8
02/12/2023 23:05:25 - 02/12/2023 23:05:25 - INFO - __main__ -     eval_ppl = 1.00444
02/12/2023 23:05:25 - INFO - __main__ -     global_step = 7481
02/12/2023 23:05:25 - INFO - __main__ -     train_loss = 0.0
02/12/2023 23:05:25 - INFO - __main__ -    02/12/2023 23:05:27 - INFO - __main__ -   Epoch 87, the accuracy is 0.9661016949152542
02/12/2023 23:05:52 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 23:05:52 - 02/12/2023 23:05:52 - INFO - __main__ - 02/12/2023 23:05:52 - 02/12/2023 23:05:52 - INFO - __main__02/12/2023 23:05:53 - INFO - __main__ -     eval_ppl = 1.00445
02/12/2023 23:05:53 - INFO - __main__ -     global_step = 7566
02/12/2023 23:05:53 - INFO - __main__ -     train_loss = 0.0
02/12/2023 23:05:53 - INFO - __main__ -     ********************
02/12/2023 23:05:55 - 02/12/2023 23:05:55 - INFO - __main__ -   Epoch 88, the accuracy 02/12/2023 23:06:20 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 23:06:20 - 02/12/2023 23:06:20 - INFO - __main__ - 02/12/2023 23:06:20 - 02/12/2023 23:06:20 - INFO - __main__02/12/2023 23:06:21 - INFO - __main__ -     eval_ppl = 1.00447
02/12/2023 23:06:21 - INFO - __main__ -     global_step = 7651
02/12/2023 23:06:21 - INFO - __main__ -     train_loss = 0.0
02/12/2023 23:06:21 - INFO - __main__ -     ********************
02/12/2023 23:06:23 - INFO - __main__ -   Epoch 89, the accuracy is 0.9661016949152542
02/12/2023 23:06:48 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 23:06:48 - 02/12/2023 23:06:48 - INFO - __main__ - 02/12/2023 23:06:48 - 02/12/2023 23:06:48 - INFO - __main__02/12/2023 23:06:49 - INFO - __main__ -     eval_ppl = 1.00448
02/12/2023 23:06:49 - INFO - __main__ -     global_step = 7736
02/12/2023 23:06:49 - INFO - __main__ -     train_loss = 0.0
02/12/2023 23:06:49 - INFO - __main__ -     ********************
02/12/2023 23:06:51 - INFO - __main__ -   Epoch 90, the accuracy is 0.9661016949152542
02/12/2023 23:07:16 - 02/12/2023 23:07:16 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 23:07:16 - INFO - __main__ -     Num examples = 59
02/12/2023 23:07:16 - INFO - __main__02/12/2023 23:07:17 - INFO - __main__ -     eval_ppl = 1.00448
02/12/2023 23:07:17 - INFO - __main__ -     global_step = 7821
02/12/2023 23:07:17 - INFO - __main__ -     train_loss = 0.0
02/12/2023 23:07:17 - INFO - __main__ -     ********************
02/12/2023 23:07:19 - 02/12/2023 23:07:19 - INFO - __main__ -   Epoch 91, the accuracy 02/12/2023 23:07:44 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 23:07:44 - INFO - __main__ -     Num examples = 59
02/12/2023 23:07:44 - INFO - __main__ -     Batch size = 8
02/12/2023 23:07:45 - 02/12/2023 23:07:45 - INFO - __main__ -     eval_ppl = 1.0044
02/12/2023 23:07:45 - INFO - __main__ -     global_step = 7906
02/12/2023 23:07:45 - INFO - __main__ -     train_loss = 0.0
02/12/2023 23:07:45 - INFO - __main__ -    02/12/2023 23:07:47 - INFO - __main__ -   Epoch 92, the accuracy is 0.9661016949152542
02/12/2023 23:08:12 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 23:08:12 - INFO - __main__ -     Num examples = 59
02/12/2023 23:08:12 - INFO - __main__ -     Batch size = 8
02/12/2023 23:08:13 - INFO - __main__ -     eval_ppl = 1.00441
02/12/2023 23:08:13 - INFO - __main__ -     global_step = 7991
02/12/2023 23:08:13 - INFO - __main__ -     train_loss = 0.0
02/12/2023 23:08:13 - INFO - __main__ -     ********************
02/12/2023 23:08:15 - 02/12/2023 23:08:15 - INFO - __main__ -   Epoch 93, the accuracy 02/12/2023 23:08:40 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 23:08:40 - 02/12/2023 23:08:40 - INFO - __main__ - 02/12/2023 23:08:40 - 02/12/2023 23:08:40 - INFO - __main__02/12/2023 23:08:41 - INFO - __main__ -     eval_ppl = 1.00438
02/12/2023 23:08:41 - INFO - __main__ -     global_step = 8076
02/12/2023 23:08:41 - INFO - __main__ -     train_loss = 0.0
02/12/2023 23:08:41 - INFO - __main__ -     ********************
02/12/2023 23:08:43 - INFO - __main__ -   Epoch 94, the accuracy is 0.9661016949152542
02/12/2023 23:09:08 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 23:09:08 - INFO - __main__ -     Num examples = 59
02/12/2023 23:09:08 - INFO - __main__ -     Batch size = 8
02/12/2023 23:09:09 - 02/12/2023 23:09:09 - INFO - __main__ -     eval_ppl = 1.0044
02/12/2023 23:09:09 - INFO - __main__ -     global_step = 8161
02/12/2023 23:09:09 - INFO - __main__ -     train_loss = 0.0
02/12/2023 23:09:09 - INFO - __main__ -    02/12/2023 23:09:11 - 02/12/2023 23:09:11 - INFO - __main__ -   Epoch 95, the accuracy 02/12/2023 23:09:37 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 23:09:37 - INFO - __main__ -     Num examples = 59
02/12/2023 23:09:37 - INFO - __main__ -     Batch size = 8
02/12/2023 23:09:37 - INFO - __main__ -     eval_ppl = 1.00441
02/12/2023 23:09:37 - INFO - __main__ -     global_step = 8246
02/12/2023 23:09:37 - INFO - __main__ -     train_loss = 0.0
02/12/2023 23:09:37 - INFO - __main__ -     ********************
02/12/2023 23:09:39 - 02/12/2023 23:09:39 - INFO - __main__ -   Epoch 96, the accuracy 02/12/2023 23:10:05 - 02/12/2023 23:10:05 - INFO - __main__ -   
***** Run02/12/2023 23:10:05 - 02/12/2023 23:10:05 - INFO - __main__ -     Num examples = 59
02/12/2023 23:10:05 - INFO - __main__02/12/2023 23:10:05 - INFO - __main__ -     eval_ppl = 1.00442
02/12/2023 23:10:05 - INFO - __main__ -     global_step = 8331
02/12/2023 23:10:05 - INFO - __main__ -     train_loss = 0.0
02/12/2023 23:10:05 - INFO - __main__ -     ********************
02/12/2023 23:10:07 - INFO - __main__ -   Epoch 97, the accuracy is 0.9661016949152542
02/12/2023 23:10:32 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 23:10:32 - INFO - __main__ -     Num examples = 59
02/12/2023 23:10:32 - INFO - __main__ -     Batch size = 8
02/12/2023 23:10:33 - INFO - __main__ -     eval_ppl = 1.00442
02/12/2023 23:10:33 - INFO - __main__ -     global_step = 8416
02/12/2023 23:10:33 - INFO - __main__ -     train_loss = 0.0
02/12/2023 23:10:33 - INFO - __main__ -     ********************
02/12/2023 23:10:35 - INFO - __main__ -   Epoch 98, the accuracy is 0.9661016949152542
02/12/2023 23:11:00 - 02/12/2023 23:11:00 - INFO - __main__ -   
***** Run02/12/2023 23:11:00 - 02/12/2023 23:11:00 - INFO - __main__ - 02/12/2023 23:11:00 - 02/12/2023 23:11:00 - INFO - __main__02/12/2023 23:11:01 - 02/12/2023 23:11:01 - INFO - __main__ -     eval_ppl = 1.00443
02/12/2023 23:11:01 - INFO - __main__ -     global_step = 8501
02/12/2023 23:11:01 - INFO - __main__ -     train_loss = 0.0
02/12/2023 23:11:01 - INFO - __main__ -    02/12/2023 23:11:03 - 02/12/2023 23:11:03 - INFO - __main__ -   Epoch 99, the accuracy 02/12/2023 23:11:29 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 23:11:29 - INFO - __main__ -     Num examples = 59
02/12/2023 23:11:29 - INFO - __main__ -     Batch size = 8
02/12/2023 23:11:29 - 02/12/2023 23:11:29 - INFO - __main__ -     eval_ppl = 1.00444
02/12/2023 23:11:29 - INFO - __main__ -     global_step = 8586
02/12/2023 23:11:29 - INFO - __main__ -     train_loss = 0.0
02/12/2023 23:11:29 - INFO - __main__ -    02/12/2023 23:11:31 - 02/12/2023 23:11:31 - INFO - __main__ -   Epoch 100, the accuracy 02/12/2023 23:11:57 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 23:11:57 - INFO - __main__ -     Num examples = 59
02/12/2023 23:11:57 - INFO - __main__ -     Batch size = 8
02/12/2023 23:11:57 - 02/12/2023 23:11:57 - INFO - __main__ -     eval_ppl = 1.00444
02/12/2023 23:11:57 - INFO - __main__ -     global_step = 8671
02/12/2023 23:11:57 - INFO - __main__ -     train_loss = 0.0
02/12/2023 23:11:57 - INFO - __main__ -    02/12/2023 23:12:00 - INFO - __main__ -   Epoch 101, the accuracy is 0.9661016949152542
02/12/2023 23:12:25 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 23:12:25 - INFO - __main__ -     Num examples = 59
02/12/2023 23:12:25 - INFO - __main__ -     Batch size = 8
02/12/2023 23:12:25 - INFO - __main__ -     eval_ppl = 1.00445
02/12/2023 23:12:25 - INFO - __main__ -     global_step = 8756
02/12/2023 23:12:25 - INFO - __main__ -     train_loss = 0.0
02/12/2023 23:12:25 - INFO - __main__ -     ********************
02/12/2023 23:12:27 - 02/12/2023 23:12:28 - INFO - __main__ -   Epoch 102, the accuracy 02/12/2023 23:12:53 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 23:12:53 - INFO - __main__ -     Num examples = 59
02/12/2023 23:12:53 - INFO - __main__ -     Batch size = 8
02/12/2023 23:12:53 - INFO - __main__ -     eval_ppl = 1.00445
02/12/2023 23:12:53 - INFO - __main__ -     global_step = 8841
02/12/2023 23:12:53 - INFO - __main__ -     train_loss = 0.0
02/12/2023 23:12:53 - INFO - __main__ -     ********************
02/12/2023 23:12:56 - 02/12/2023 23:12:56 - INFO - __main__ -   Epoch 103, the accuracy 02/12/2023 23:13:21 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 23:13:21 - INFO - __main__ -     Num examples = 59
02/12/2023 23:13:21 - INFO - __main__ -     Batch size = 8
02/12/2023 23:13:21 - 02/12/2023 23:13:21 - INFO - __main__ -     eval_ppl = 1.00445
02/12/2023 23:13:21 - INFO - __main__ -     global_step = 8926
02/12/2023 23:13:21 - INFO - __main__ -     train_loss = 0.0
02/12/2023 23:13:21 - INFO - __main__ -    02/12/2023 23:13:24 - INFO - __main__ -   Epoch 104, the accuracy is 0.9661016949152542
02/12/2023 23:13:49 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 23:13:49 - INFO - __main__ -     Num examples = 59
02/12/2023 23:13:49 - INFO - __main__ -     Batch size = 8
02/12/2023 23:13:50 - INFO - __main__ -     eval_ppl = 1.00445
02/12/2023 23:13:50 - INFO - __main__ -     global_step = 9011
02/12/2023 23:13:50 - INFO - __main__ -     train_loss = 0.0
02/12/2023 23:13:50 - INFO - __main__ -     ********************
02/12/2023 23:13:52 - INFO - __main__ -   Epoch 105, the accuracy is 0.9661016949152542
02/12/2023 23:14:17 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 23:14:17 - INFO - __main__ -     Num examples = 59
02/12/2023 23:14:17 - INFO - __main__ -     Batch size = 8
02/12/2023 23:14:18 - INFO - __main__ -     eval_ppl = 1.00449
02/12/2023 23:14:18 - INFO - __main__ -     global_step = 9096
02/12/2023 23:14:18 - INFO - __main__ -     train_loss = 0.0
02/12/2023 23:14:18 - INFO - __main__ -     ********************
02/12/2023 23:14:20 - 02/12/2023 23:14:20 - INFO - __main__ -   Epoch 106, the accuracy 02/12/2023 23:14:45 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 23:14:45 - INFO - __main__ -     Num examples = 59
02/12/2023 23:14:45 - INFO - __main__ -     Batch size = 8
02/12/2023 23:14:46 - INFO - __main__ -     eval_ppl = 1.0045
02/12/2023 23:14:46 - INFO - __main__ -     global_step = 9181
02/12/2023 23:14:46 - INFO - __main__ -     train_loss = 0.0
02/12/2023 23:14:46 - INFO - __main__ -     ********************
02/12/2023 23:14:48 - 02/12/2023 23:14:48 - INFO - __main__ -   Epoch 107, the accuracy 02/12/2023 23:15:13 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 23:15:13 - INFO - __main__ -     Num examples = 59
02/12/2023 23:15:13 - INFO - __main__ -     Batch size = 8
02/12/2023 23:15:14 - INFO - __main__ -     eval_ppl = 1.00449
02/12/2023 23:15:14 - INFO - __main__ -     global_step = 9266
02/12/2023 23:15:14 - INFO - __main__ -     train_loss = 0.0
02/12/2023 23:15:14 - INFO - __main__ -     ********************
02/12/2023 23:15:16 - 02/12/2023 23:15:16 - INFO - __main__ -   Epoch 108, the accuracy 02/12/2023 23:15:41 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 23:15:41 - INFO - __main__ -     Num examples = 59
02/12/2023 23:15:41 - INFO - __main__ -     Batch size = 8
02/12/2023 23:15:42 - 02/12/2023 23:15:42 - INFO - __main__ -     eval_ppl = 1.0045
02/12/2023 23:15:42 - INFO - __main__ -     global_step = 9351
02/12/2023 23:15:42 - INFO - __main__ -     train_loss = 0.0
02/12/2023 23:15:42 - INFO - __main__ -    02/12/2023 23:15:44 - 02/12/2023 23:15:44 - INFO - __main__ -   Epoch 109, the accuracy 02/12/2023 23:16:09 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 23:16:09 - INFO - __main__ -     Num examples = 59
02/12/2023 23:16:09 - INFO - __main__ -     Batch size = 8
02/12/2023 23:16:10 - 02/12/2023 23:16:10 - INFO - __main__ -     eval_ppl = 1.0045
02/12/2023 23:16:10 - INFO - __main__ -     global_step = 9436
02/12/2023 23:16:10 - INFO - __main__ -     train_loss = 0.0
02/12/2023 23:16:10 - INFO - __main__ -    02/12/2023 23:16:12 - 02/12/2023 23:16:12 - INFO - __main__ -   Epoch 110, the accuracy 02/12/2023 23:16:37 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 23:16:37 - INFO - __main__ -     Num examples = 59
02/12/2023 23:16:37 - INFO - __main__ -     Batch size = 8
02/12/2023 23:16:38 - 02/12/2023 23:16:38 - INFO - __main__ -     eval_ppl = 1.00453
02/12/2023 23:16:38 - INFO - __main__ -     global_step = 9521
02/12/2023 23:16:38 - INFO - __main__ -     train_loss = 0.0
02/12/2023 23:16:38 - INFO - __main__ -    02/12/2023 23:16:40 - INFO - __main__ -   Epoch 111, the accuracy is 0.9661016949152542
02/12/2023 23:17:05 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 23:17:05 - INFO - __main__ -     Num examples = 59
02/12/2023 23:17:05 - INFO - __main__ -     Batch size = 8
02/12/2023 23:17:06 - 02/12/2023 23:17:06 - INFO - __main__ -     eval_ppl = 1.00453
02/12/2023 23:17:06 - INFO - __main__ -     global_step = 9606
02/12/2023 23:17:06 - INFO - __main__ -     train_loss = 0.0
02/12/2023 23:17:06 - INFO - __main__ -    02/12/2023 23:17:08 - INFO - __main__ -   Epoch 112, the accuracy is 0.9661016949152542
02/12/2023 23:17:34 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 23:17:34 - INFO - __main__ -     Num examples = 59
02/12/2023 23:17:34 - INFO - __main__ -     Batch size = 8
02/12/2023 23:17:34 - INFO - __main__ -     eval_ppl = 1.00453
02/12/2023 23:17:34 - INFO - __main__ -     global_step = 9691
02/12/2023 23:17:34 - INFO - __main__ -     train_loss = 0.0
02/12/2023 23:17:34 - INFO - __main__ -     ********************
02/12/2023 23:17:36 - 02/12/2023 23:17:36 - INFO - __main__ -   Epoch 113, the accuracy 02/12/2023 23:18:02 - 02/12/2023 23:18:02 - INFO - __main__ -   
***** Run02/12/2023 23:18:02 - 02/12/2023 23:18:02 - INFO - __main__ - 02/12/2023 23:18:02 - 02/12/2023 23:18:02 - INFO - __main__02/12/2023 23:18:02 - 02/12/2023 23:18:02 - INFO - __main__ -     eval_ppl = 1.00453
02/12/2023 23:18:02 - INFO - __main__ -     global_step = 9776
02/12/2023 23:18:02 - INFO - __main__ -     train_loss = 0.0
02/12/2023 23:18:02 - INFO - __main__ -    02/12/2023 23:18:04 - INFO - __main__ -   Epoch 114, the accuracy is 0.9661016949152542
02/12/2023 23:18:30 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 23:18:30 - INFO - __main__ -     Num examples = 59
02/12/2023 23:18:30 - INFO - __main__ -     Batch size = 8
02/12/2023 23:18:30 - INFO - __main__ -     eval_ppl = 1.00454
02/12/2023 23:18:30 - INFO - __main__ -     global_step = 9861
02/12/2023 23:18:30 - INFO - __main__ -     train_loss = 0.0
02/12/2023 23:18:30 - INFO - __main__ -     ********************
02/12/2023 23:18:32 - INFO - __main__ -   Epoch 115, the accuracy is 0.9661016949152542
02/12/2023 23:18:58 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 23:18:58 - INFO - __main__ -     Num examples = 59
02/12/2023 23:18:58 - INFO - __main__ -     Batch size = 8
02/12/2023 23:18:58 - INFO - __main__ -     eval_ppl = 1.00455
02/12/2023 23:18:58 - INFO - __main__ -     global_step = 9946
02/12/2023 23:18:58 - INFO - __main__ -     train_loss = 0.0
02/12/2023 23:18:58 - INFO - __main__ -     ********************
02/12/2023 23:19:00 - 02/12/2023 23:19:00 - INFO - __main__ -   Epoch 116, the accuracy 02/12/2023 23:19:26 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 23:19:26 - INFO - __main__ -     Num examples = 59
02/12/2023 23:19:26 - INFO - __main__ -     Batch size = 8
02/12/2023 23:19:27 - 02/12/2023 23:19:27 - INFO - __main__ -     eval_ppl = 1.00454
02/12/2023 23:19:27 - INFO - __main__ -     global_step = 10031
02/12/2023 23:19:27 - INFO - __main__ -     train_loss = 0.0
02/12/2023 23:19:27 - INFO - __main__ -    02/12/2023 23:19:29 - 02/12/2023 23:19:29 - INFO - __main__ -   Epoch 117, the accuracy 02/12/2023 23:19:54 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 23:19:54 - INFO - __main__ -     Num examples = 59
02/12/2023 23:19:54 - INFO - __main__ -     Batch size = 8
02/12/2023 23:19:55 - INFO - __main__ -     eval_ppl = 1.00454
02/12/2023 23:19:55 - INFO - __main__ -     global_step = 10116
02/12/2023 23:19:55 - INFO - __main__ -     train_loss = 0.0
02/12/2023 23:19:55 - INFO - __main__ -     ********************
02/12/2023 23:19:57 - 02/12/2023 23:19:57 - INFO - __main__ -   Epoch 118, the accuracy 02/12/2023 23:20:22 - INFO - __main__ -   
***** Running evaluation *****
02/12/2023 23:20:22 - INFO - __main__ -     Num examples = 59
02/12/2023 23:20:22 - INFO - __main__ -     Batch size = 8
02/12/2023 23:20:23 - 02/12/2023 23:20:23 - INFO - __main__ -     eval_ppl = 1.00454
02/12/2023 23:20:23 - INFO - __main__ -     global_step = 10201
02/12/2023 23:20:23 - INFO - __main__ -     train_loss = 0.0
02/12/2023 23:20:23 - INFO - __main__ -    02/12/2023 23:20:25 - 02/12/2023 23:20:25 - INFO - __main__ -   Epoch 119, the accuracy is 0.9661016949152542
02/12/2023 23:20:25 - INFO - __main__ -   Test file: final_final_dataset/pharo/val_data_of_02/12/2023 23:20:26 - 02/12/2023 23:20:26 - INFO - __main__ -   gold_info:{'all_count': 59, 'Positive': 2, 'Negative': 57}
02/12/2023 23:20:26 - INFO - __main__ -   pre_info:{'TP': 0, 'FP': 0, 'TN': 57, 'FN': 2}
02/12/2023 23:20:26 - INFO - __main__ -   Epoch 119, the accuracy is 0.9661016949152542, the precision is 0, the recall is 0.0, the fscore is 0
02/12/2023 23:20:26 - INFO - __main__ -   Test file: final_final_dataset/pharo/test_data_of_02/12/2023 23:20:30 - 02/12/2023 23:20:30 - INFO - __main__ -   gold_info:{'all_count': 357, 'Positive': 17, 'Negative': 340}
02/12/2023 23:20:30 - INFO - __main__ -   pre_info:{'TP': 7, 'FP': 6, 'TN': 334, 'FN': 10}
02/12/2023 23:20:30 - INFO - __main__ -   Epoch 119, the accuracy is 0.9551820728291317, the precision is 0.5384615384615384, the recall is 0.4117647058823529, the fscore is 0.4666666666666667
